all_configs:
  kernels/add/add_scalar/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14102400541305543
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1410752058029175
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14130239486694335
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14132159948349
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14132479429244996
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1413920044898987
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14139519929885863
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14193919897079468
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1421344041824341
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14216959476470947
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14300479888916015
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14442880153656007
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14566080570220946
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14816960096359252
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14950079917907716
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15281280279159545
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15908800363540648
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18431040048599243
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20254080295562743
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2302527904510498
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.24988160133361817
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2499840021133423
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2500096082687378
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.25065600872039795
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3036384105682373
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.33384320735931394
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.381932806968689
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49627199172973635
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49643840789794924
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4965375900268555
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4965536117553711
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9899264335632324
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9899552345275879
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.990294361114502
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9776607513427735
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14056639671325682
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1408735990524292
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14089280366897583
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14099199771881105
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14105279445648194
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1412320017814636
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1413983941078186
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1422271966934204
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14257919788360596
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14294719696044922
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14311039447784424
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14378880262374877
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1454848051071167
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1473088026046753
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14784959554672242
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15224640369415282
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15879679918289186
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.1839967966079712
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20247039794921876
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.23009281158447265
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2499903917312622
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.25006399154663084
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.25027201175689695
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.25051519870758054
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30427520275115966
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.33447999954223634
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3829087972640991
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49639039039611815
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49650559425354
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49662079811096194
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49691200256347656
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9899711608886719
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9906496047973633
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.990783977508545
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9787359237670898
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27791359424591067
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27814080715179446
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27845120429992676
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2785056114196777
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27863359451293945
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2786815881729126
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2789983987808228
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2808255910873413
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2810431957244873
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28185598850250243
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28189759254455565
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.284553599357605
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.28701438903808596
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.29142398834228517
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.29528639316558836
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3011552095413208
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.31296958923339846
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.35765440464019777
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.390828800201416
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4373760223388672
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4956831932067871
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49626879692077636
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4969088077545166
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49716482162475584
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9717599868774414
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9872960090637207
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9876223564147949
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9877663612365722
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.971731185913086
  kernels/add/add_tensor/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14080640077590942
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14089280366897583
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1409343957901001
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14094719886779786
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14113919734954833
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14151040315628052
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1417888045310974
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14192320108413697
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1419551968574524
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14205440282821655
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1421663999557495
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14432320594787598
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1461024045944214
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1481503963470459
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15295039415359496
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1593119978904724
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18393280506134033
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20266239643096923
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.22994558811187743
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.24989759922027588
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2500191926956177
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.250163197517395
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.25055038928985596
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3061503887176514
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.33800640106201174
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38708479404449464
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4963871955871582
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4964735984802246
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4964735984802246
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.496614408493042
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9626560211181641
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9897503852844238
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9899904251098632
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.990345573425293
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.97772159576416
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14036159515380858
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14067519903182985
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14083839654922486
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14088319540023803
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14116159677505494
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14117759466171265
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14143040180206298
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14164479970932006
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14187840223312378
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1421471953392029
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14274560213088988
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14422080516815186
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14560320377349853
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14814720153808594
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1525823950767517
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15905920267105103
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18393919467926026
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20274240970611573
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.23036160469055175
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.24981119632720947
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.24982399940490724
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2501535892486572
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2505311965942383
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30702719688415525
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.33855040073394777
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38784959316253664
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49649600982666015
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49658880233764646
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4966271877288818
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49930238723754883
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9898591995239258
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9901023864746094
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9905440330505371
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 1.0371328353881837
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9780736923217774
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2776384115219116
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778304100036621
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27790079116821287
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27819199562072755
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2783776044845581
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2789056062698364
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2793823957443237
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2795488119125366
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28056640625
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2808160066604614
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28136320114135743
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28511359691619875
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2874720096588135
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.29225280284881594
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.30144319534301756
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.31369919776916505
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.35932800769805906
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.39317119121551514
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.439737606048584
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4968863964080811
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49747519493103026
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49764161109924315
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49862399101257326
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.987673568725586
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9886303901672363
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9933535575866699
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9717344284057616
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.001046371459961
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.094931221008301
  kernels/embedding/backward.py->_backward:
    '''weight.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.254755401611328
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 10.273990631103516
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.319446563720703
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 11.218086242675781
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 11.30181427001953
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 11.541999816894531
    '''weight.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 3.5278656005859377
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.255424118041992
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.267782211303711
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.620595169067383
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.638275146484375
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 5.813494491577148
    '''weight.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 9.80187530517578
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 9.84710693359375
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.045382690429687
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.22708511352539
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.532083129882812
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.891398620605468
  kernels/embedding/forward.py->_forward:
    '''weight.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6654623985290528
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.666860818862915
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7009856224060058
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7246719837188721
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.7802464008331299
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 0.8638239860534668
    '''weight.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6663392066955567
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.666860818862915
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7010047912597657
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7263008117675781
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.7816383838653564
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 0.8648096084594726
    '''weight.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.3729023933410645
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.422700786590576
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 1.7095840454101563
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 4.777523040771484
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.030096054077148
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.286518478393555
  kernels/rmsnorm/triton_implementation/kernels_backward.py->rmsnorm_backward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04115520119667053
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04127359986305237
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04170880019664765
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0420415997505188
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.0422111988067627
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09096959829330445
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.22960960865020752
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.0685151994228363
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0688704013824463
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0692799985408783
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07103999853134155
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.07163519859313965
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09670079946517944
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.22933440208435057
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04176000058650971
    - config:
        BLOCK_SIZE_B: 16
      time: 0.041808000206947325
    - config:
        BLOCK_SIZE_B: 4
      time: 0.042070400714874265
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04220480024814606
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04370880126953125
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07823039889335633
    - config:
        BLOCK_SIZE_B: 64
      time: 0.17985919713974
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06867200136184692
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06880639791488648
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06991040110588073
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07023680210113525
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07035840153694153
    - config:
        BLOCK_SIZE_B: 32
      time: 0.13956480026245116
    - config:
        BLOCK_SIZE_B: 64
      time: 0.42179198265075685
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04117439985275269
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04158720076084137
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04190720021724701
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04200960099697113
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04208320081233978
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042342400550842284
    - config:
        BLOCK_SIZE_B: 512
      time: 0.05009920001029968
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06926079988479614
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06928960084915162
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06949120163917541
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06976959705352784
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07026559710502625
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07337599992752075
    - config:
        BLOCK_SIZE_B: 512
      time: 0.20511999130249023
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04069119989871979
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04104639887809754
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04108160138130188
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04145280122756958
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.041494399309158325
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04191359877586365
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04457919895648956
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07025279998779296
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07031999826431275
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07043840289115906
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07092800140380859
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0717631995677948
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07198399901390076
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.15983680486679078
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07904959917068481
    - config:
        BLOCK_SIZE_B: 2
      time: 0.5479296207427978
    - config:
        BLOCK_SIZE_B: 4
      time: 0.7084864139556885
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 1.491267204284668
    - config:
        BLOCK_SIZE_B: 1
      time: 1.547856044769287
    - config:
        BLOCK_SIZE_B: 4
      time: 2.784259223937988
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04167360067367554
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04195199906826019
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04197440147399902
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04209280014038086
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.042787200212478636
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.061078399419784546
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.19288320541381837
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06856639981269837
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06931520104408265
    - config:
        BLOCK_SIZE_B: 512
      time: 0.069513601064682
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06973440051078797
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07067199945449829
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.0955136001110077
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.17647680044174194
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.041308799386024476
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04145599901676178
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04159039855003357
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04182400107383728
    - config:
        BLOCK_SIZE_B: 16
      time: 0.10841280221939087
    - config:
        BLOCK_SIZE_B: 32
      time: 0.26477439403533937
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06958720088005066
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06972479820251465
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07015039920806884
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07096959948539734
    - config:
        BLOCK_SIZE_B: 16
      time: 0.21040639877319336
    - config:
        BLOCK_SIZE_B: 32
      time: 0.5299488067626953
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04048640131950378
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04118080139160156
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04135999977588654
    - config:
        BLOCK_SIZE_B: 4
      time: 0.041388800740242
    - config:
        BLOCK_SIZE_B: 64
      time: 0.041631999611854556
    - config:
        BLOCK_SIZE_B: 128
      time: 0.041731199622154234
    - config:
        BLOCK_SIZE_B: 256
      time: 0.049209600687026976
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06904320120811462
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0698527991771698
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07040640115737914
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07049279808998107
    - config:
        BLOCK_SIZE_B: 64
      time: 0.070796799659729
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07250880002975464
    - config:
        BLOCK_SIZE_B: 256
      time: 0.20301439762115478
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.041116800904273984
    - config:
        BLOCK_SIZE_B: 32
      time: 0.041142401099205014
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04162240028381348
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0420415997505188
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04211840033531189
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04322879910469055
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04958719909191132
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06901760101318359
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06943680047988891
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06967999935150146
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06995840072631836
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07117440104484558
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07215039730072022
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.1700703978538513
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.1121536254882813
    - config:
        BLOCK_SIZE_B: 2
      time: 1.802921676635742
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 3.6108577728271483
    - config:
        BLOCK_SIZE_B: 1
      time: 4.314156723022461
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04187839925289154
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04190720021724701
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04193919897079468
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04215039908885956
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04233280122280121
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06517760157585144
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.21159679889678956
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0695360004901886
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07019839882850647
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07091519832611085
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07130879759788514
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07213119864463806
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.10228159427642822
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.18037760257720947
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04259200096130371
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0427264004945755
    - config:
        BLOCK_SIZE_B: 1
      time: 0.043459200859069826
    - config:
        BLOCK_SIZE_B: 8
      time: 0.17845439910888672
    - config:
        BLOCK_SIZE_B: 16
      time: 0.26587839126586915
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07069439888000488
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07127360105514527
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0716159999370575
    - config:
        BLOCK_SIZE_B: 8
      time: 0.4588064193725586
    - config:
        BLOCK_SIZE_B: 16
      time: 0.8213055610656739
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04105600118637085
    - config:
        BLOCK_SIZE_B: 4
      time: 0.041222399473190306
    - config:
        BLOCK_SIZE_B: 2
      time: 0.041388800740242
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04154880046844482
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04180479943752289
    - config:
        BLOCK_SIZE_B: 64
      time: 0.051545602083206174
    - config:
        BLOCK_SIZE_B: 128
      time: 0.1381600022315979
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06809920072555542
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0694208025932312
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06956480145454406
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07057920098304749
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07076799869537354
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10743680000305175
    - config:
        BLOCK_SIZE_B: 128
      time: 0.3491391897201538
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04046080112457275
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04089600145816803
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04120959937572479
    - config:
        BLOCK_SIZE_B: 16
      time: 0.041308799386024476
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04213759899139404
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04223040044307709
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.047491198778152464
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06810240149497986
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06949440240859986
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06969919800758362
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06978880167007447
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06980159878730774
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07225919961929321
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.17327359914779664
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.221788787841797
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 10.473375701904297
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.041075199842453
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04209280014038086
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0423552006483078
    - config:
        BLOCK_SIZE_B: 512
      time: 0.042556801438331605
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04359999895095825
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07680320143699645
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.21894400119781493
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06976320147514344
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07067199945449829
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0719968020915985
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07244160175323486
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07318400144577027
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.14024319648742675
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.3111104011535645
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.044819200038909913
    - config:
        BLOCK_SIZE_B: 1
      time: 0.051475197076797485
    - config:
        BLOCK_SIZE_B: 4
      time: 0.12911679744720458
    - config:
        BLOCK_SIZE_B: 8
      time: 0.6177824020385743
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07168319821357727
    - config:
        BLOCK_SIZE_B: 2
      time: 0.08184959888458251
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6520800113677978
    - config:
        BLOCK_SIZE_B: 8
      time: 1.595792007446289
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04172160029411316
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04256640076637268
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04266240000724793
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.043561598658561705
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.044073599576950076
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09126399755477906
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.2448960065841675
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06944959759712219
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06945599913597107
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07025600075721741
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.07291520237922669
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.07310720086097718
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.07610560059547425
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.16776000261306762
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04139519929885864
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04161919951438904
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04257279932498932
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04288640022277832
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04297919869422913
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06918399930000305
    - config:
        BLOCK_SIZE_B: 64
      time: 0.13738880157470704
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06882240176200867
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07018880248069763
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07018880248069763
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07110400199890136
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07211520075798035
    - config:
        BLOCK_SIZE_B: 32
      time: 0.11616959571838378
    - config:
        BLOCK_SIZE_B: 64
      time: 0.33521280288696287
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.041315200924873355
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04199999868869782
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04235199987888336
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04305599927902222
    - config:
        BLOCK_SIZE_B: 64
      time: 0.043110400438308716
    - config:
        BLOCK_SIZE_B: 128
      time: 0.043279999494552614
    - config:
        BLOCK_SIZE_B: 512
      time: 0.044784000515937804
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06867200136184692
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07023360133171082
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07037119865417481
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07106559872627258
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07129279971122741
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07144320011138916
    - config:
        BLOCK_SIZE_B: 512
      time: 0.08263040184974671
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.042089599370956424
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04281280040740967
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042828801274299624
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04285120069980621
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04316479861736298
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04345279932022095
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04461120069026947
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06905919909477234
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06944959759712219
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06989759802818299
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07072319984436035
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07125120162963867
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07131199836730957
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07542080283164979
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07858240008354186
    - config:
        BLOCK_SIZE_B: 2
      time: 0.44945921897888186
    - config:
        BLOCK_SIZE_B: 4
      time: 0.5673503875732422
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.1232159614562989
    - config:
        BLOCK_SIZE_B: 2
      time: 1.1495327949523926
    - config:
        BLOCK_SIZE_B: 4
      time: 1.9813215255737304
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04180159866809845
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04301440119743347
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04314880073070526
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04345279932022095
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04347519874572754
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.061187201738357545
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.16284799575805664
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07005760073661804
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.07063680291175842
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0713919997215271
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07167360186576843
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07278079986572265
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.11904000043869019
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.267737603187561
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04139519929885864
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04198080003261566
    - config:
        BLOCK_SIZE_B: 2
      time: 0.042124798893928526
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0435232013463974
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09525120258331299
    - config:
        BLOCK_SIZE_B: 32
      time: 0.18019200563430787
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06894720196723939
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0699455976486206
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07045120000839233
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07308160066604615
    - config:
        BLOCK_SIZE_B: 16
      time: 0.16046080589294434
    - config:
        BLOCK_SIZE_B: 32
      time: 0.3636352062225342
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04166400134563446
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04178560078144074
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04223040044307709
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043321600556373595
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04383040070533752
    - config:
        BLOCK_SIZE_B: 64
      time: 0.043961599469184875
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04604800045490265
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06843839883804322
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06976959705352784
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07029439806938172
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07076159715652466
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07189440131187438
    - config:
        BLOCK_SIZE_B: 128
      time: 0.072598397731781
    - config:
        BLOCK_SIZE_B: 256
      time: 0.10659840106964111
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.041875201463699344
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04192639887332916
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04276480078697205
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04296959936618805
    - config:
        BLOCK_SIZE_B: 32
      time: 0.043289598822593686
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04459519982337952
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04609279930591583
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07052479982376099
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07091839909553528
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0711135983467102
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07132480144500733
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07144960165023803
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07161279916763305
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.077920001745224
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.8834943771362305
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2112832069396973
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 2.978803253173828
    - config:
        BLOCK_SIZE_B: 1
      time: 3.1041183471679688
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04245119988918304
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04264320135116577
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04313920140266418
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.043647998571395875
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04398080110549927
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06488959789276123
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.17902719974517822
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07076799869537354
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07152320146560669
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07159680128097534
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07176640033721923
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07245759963989258
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.13938560485839843
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.3031487941741943
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.043331199884414674
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04347200095653534
    - config:
        BLOCK_SIZE_B: 2
      time: 0.043680000305175784
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07784000039100647
    - config:
        BLOCK_SIZE_B: 16
      time: 0.2655103921890259
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06961280107498169
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07175999879837036
    - config:
        BLOCK_SIZE_B: 1
      time: 0.072707200050354
    - config:
        BLOCK_SIZE_B: 16
      time: 0.3724031925201416
    - config:
        BLOCK_SIZE_B: 8
      time: 0.3841536045074463
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04205760061740875
    - config:
        BLOCK_SIZE_B: 8
      time: 0.042684799432754515
    - config:
        BLOCK_SIZE_B: 2
      time: 0.042991998791694644
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04338879883289337
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04496000111103058
    - config:
        BLOCK_SIZE_B: 64
      time: 0.05053439736366272
    - config:
        BLOCK_SIZE_B: 128
      time: 0.11044479608535766
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06904640197753906
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06976959705352784
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07025920152664185
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07185599803924561
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07209280133247375
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10656960010528564
    - config:
        BLOCK_SIZE_B: 128
      time: 0.20483839511871338
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04213759899139404
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04235199987888336
    - config:
        BLOCK_SIZE_B: 64
      time: 0.042710399627685545
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04277440011501312
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04340479969978332
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04374080002307892
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.047884801030159
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07043840289115906
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07099199891090394
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07169600129127503
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0719968020915985
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07249280214309692
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0731552004814148
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07584319710731506
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.8188543319702148
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 8.320972442626953
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042371198534965515
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043145599961280826
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.043619200587272644
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04413119852542877
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0446368008852005
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0772704005241394
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.21906559467315673
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06961280107498169
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06999679803848266
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07065920233726501
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0711296021938324
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07279040217399597
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.11355199813842773
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.19736640453338622
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.046387198567390445
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05023999810218811
    - config:
        BLOCK_SIZE_B: 4
      time: 0.22771520614624025
    - config:
        BLOCK_SIZE_B: 8
      time: 0.45752639770507814
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0722656011581421
    - config:
        BLOCK_SIZE_B: 2
      time: 0.4479519844055176
    - config:
        BLOCK_SIZE_B: 4
      time: 0.5833759784698487
    - config:
        BLOCK_SIZE_B: 8
      time: 0.8793631553649902
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04230400025844574
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04324159920215607
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04381760060787201
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.044921600818634035
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.047414401173591615
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.07542719841003417
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.16389119625091553
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06231039762496948
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.062377601861953735
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06479359865188598
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06502079963684082
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06571840047836304
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.0833952009677887
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.23294079303741455
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04203839898109436
    - config:
        BLOCK_SIZE_B: 1
      time: 0.042671999335289
    - config:
        BLOCK_SIZE_B: 4
      time: 0.042716801166534424
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04347839951515198
    - config:
        BLOCK_SIZE_B: 16
      time: 0.054364800453186035
    - config:
        BLOCK_SIZE_B: 32
      time: 0.11050239801406861
    - config:
        BLOCK_SIZE_B: 64
      time: 0.28751039505004883
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.062063997983932494
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06254720091819763
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06295999884605408
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06314240097999572
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0960864007472992
    - config:
        BLOCK_SIZE_B: 32
      time: 0.14944640398025513
    - config:
        BLOCK_SIZE_B: 64
      time: 0.3516319990158081
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04227199852466583
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04268800020217896
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04320319890975952
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04325760006904602
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04365760087966919
    - config:
        BLOCK_SIZE_B: 32
      time: 0.044047999382019046
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07904639840126038
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06195840239524841
    - config:
        BLOCK_SIZE_B: 64
      time: 0.062159997224807736
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06247680187225342
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06295999884605408
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0632960021495819
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07044479846954346
    - config:
        BLOCK_SIZE_B: 512
      time: 0.11991360187530517
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.042991998791694644
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04302079975605011
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04352000057697296
    - config:
        BLOCK_SIZE_B: 256
      time: 0.043932801485061644
    - config:
        BLOCK_SIZE_B: 128
      time: 0.044710400700569156
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04585919976234436
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.056918400526046756
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06175680160522461
    - config:
        BLOCK_SIZE_B: 64
      time: 0.061868798732757566
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0633247971534729
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06370559930801392
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06397119760513306
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06462720036506653
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.11711679697036743
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.14488960504531861
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2894399642944336
    - config:
        BLOCK_SIZE_B: 4
      time: 1.7351871490478517
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.659334373474121
    - config:
        BLOCK_SIZE_B: 2
      time: 1.9646528244018555
    - config:
        BLOCK_SIZE_B: 4
      time: 3.3158912658691406
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04219520092010498
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.042668798565864564
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04324159920215607
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04344640076160431
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.043881601095199584
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04574399888515472
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.26743040084838865
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0622111976146698
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06249920129776001
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.0628000020980835
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06313599944114685
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06330239772796631
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.09359359741210938
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.3325023889541626
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04262720048427582
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04264639914035797
    - config:
        BLOCK_SIZE_B: 1
      time: 0.043100801110267636
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04345600008964538
    - config:
        BLOCK_SIZE_B: 16
      time: 0.16569600105285645
    - config:
        BLOCK_SIZE_B: 32
      time: 0.24979839324951172
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0626911997795105
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0633408010005951
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06374719738960266
    - config:
        BLOCK_SIZE_B: 8
      time: 0.20921919345855713
    - config:
        BLOCK_SIZE_B: 16
      time: 0.24065279960632324
    - config:
        BLOCK_SIZE_B: 32
      time: 0.40262398719787595
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04130240082740784
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04176320135593414
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04189119935035705
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04205760061740875
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04344319999217987
    - config:
        BLOCK_SIZE_B: 128
      time: 0.052185600996017455
    - config:
        BLOCK_SIZE_B: 256
      time: 0.16274240016937255
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06180480122566223
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06212159991264343
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06304960250854492
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06355519890785218
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06359999775886535
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07601280212402343
    - config:
        BLOCK_SIZE_B: 256
      time: 0.2510528087615967
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04166400134563446
    - config:
        BLOCK_SIZE_B: 128
      time: 0.042505601048469545
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04275520145893097
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04336960017681122
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04442879855632782
    - config:
        BLOCK_SIZE_B: 512
      time: 0.044521600008010864
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06707839965820313
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.061990398168563846
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06236799955368042
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06313599944114685
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06328960061073304
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06386560201644897
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06818559765815735
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.10622719526290894
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.7398271560668945
    - config:
        BLOCK_SIZE_B: 2
      time: 3.5203937530517577
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 4.268883132934571
    - config:
        BLOCK_SIZE_B: 2
      time: 5.126566314697266
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.041552001237869264
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.041782400012016295
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04264320135116577
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04323840141296387
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04401600062847137
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04894079864025116
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.3421823978424072
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.029523199796676634
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06278719902038574
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0634335994720459
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06522240042686463
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06543359756469727
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.09734079837799073
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.2652672052383423
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04301120042800903
    - config:
        BLOCK_SIZE_B: 4
      time: 0.043721601366996765
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04524160027503967
    - config:
        BLOCK_SIZE_B: 8
      time: 0.2687040090560913
    - config:
        BLOCK_SIZE_B: 16
      time: 0.32537920475006105
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.063372802734375
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06442559957504272
    - config:
        BLOCK_SIZE_B: 4
      time: 0.38261120319366454
    - config:
        BLOCK_SIZE_B: 8
      time: 0.5588704109191894
    - config:
        BLOCK_SIZE_B: 16
      time: 0.5846271991729737
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04128639996051788
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04163840115070343
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04216960072517395
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04307839870452881
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0478879988193512
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10987520217895508
    - config:
        BLOCK_SIZE_B: 128
      time: 0.18630720376968385
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06159999966621399
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06222079992294312
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06271039843559265
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06409599781036376
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06644799709320068
    - config:
        BLOCK_SIZE_B: 64
      time: 0.1162719964981079
    - config:
        BLOCK_SIZE_B: 128
      time: 0.24890239238739015
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04171839952468872
    - config:
        BLOCK_SIZE_B: 128
      time: 0.041843199729919435
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04200960099697113
    - config:
        BLOCK_SIZE_B: 32
      time: 0.042505601048469545
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04335359930992126
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0438400000333786
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06921600103378296
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06204800009727478
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0627295970916748
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0629472017288208
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06306880116462707
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06450240015983581
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06639360189437866
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.11273599863052368
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 7.575443267822266
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 10.238384246826172
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0414112001657486
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04166719913482666
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04167680144309997
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04178560078144074
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04346559941768646
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0631168007850647
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.27087039947509767
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06218559741973877
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06255040168762208
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06275200247764587
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0640064001083374
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06433280110359192
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.10694080591201782
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.289849591255188
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07212160229682922
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07557439804077148
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6311168193817138
    - config:
        BLOCK_SIZE_B: 8
      time: 0.7874368190765381
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.08425920009613037
    - config:
        BLOCK_SIZE_B: 2
      time: 0.6539807796478272
    - config:
        BLOCK_SIZE_B: 4
      time: 0.8825632095336914
    - config:
        BLOCK_SIZE_B: 8
      time: 1.379689598083496
  kernels/rmsnorm/triton_implementation/kernels_forward.py->rmsnorm_forward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0328031986951828
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03293760120868683
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03327040076255798
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03372479975223541
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.033980798721313474
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04583359956741333
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.09554880261421203
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.035462400317192076
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03605439960956573
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.036611199378967285
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03711679875850678
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03727039992809296
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04984320104122162
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.10866559743881225
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03244799971580505
    - config:
        BLOCK_SIZE_B: 4
      time: 0.032764801383018495
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03332479894161224
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03336000144481659
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03353280127048493
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03405120074748993
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04889920055866241
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.035724800825119016
    - config:
        BLOCK_SIZE_B: 1
      time: 0.036236798763275145
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03636159896850586
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036406400799751285
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036483201384544375
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03694399893283844
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037427198886871335
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03227519989013672
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03260799944400787
    - config:
        BLOCK_SIZE_B: 128
      time: 0.032742398977279666
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03285439908504486
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03290880024433136
    - config:
        BLOCK_SIZE_B: 8
      time: 0.032918399572372435
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03312320113182068
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.035488000512123107
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036099201440811156
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03615039885044098
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03650560081005096
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03651840090751648
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03680639863014221
    - config:
        BLOCK_SIZE_B: 512
      time: 0.038083198666572574
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03240639865398407
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.032620799541473386
    - config:
        BLOCK_SIZE_B: 512
      time: 0.032864001393318173
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03312639892101288
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03328000009059906
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034227201342582704
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04589119851589203
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03630079925060272
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03650240004062653
    - config:
        BLOCK_SIZE_B: 512
      time: 0.036559998989105225
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03656960129737854
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03665600121021271
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037011200189590455
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.037785598635673524
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.047977599501609805
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05039039850234985
    - config:
        BLOCK_SIZE_B: 4
      time: 0.3049567937850952
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05299199819564819
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05927039980888367
    - config:
        BLOCK_SIZE_B: 4
      time: 0.4502528190612793
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03311359882354736
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033523198962211606
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03406080007553101
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03452160060405731
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03500480055809021
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.047331199049949646
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09921919703483581
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03564479947090149
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.035996800661087035
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03615359961986542
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03624640107154846
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03747200071811676
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04807359874248505
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.10090559720993042
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.032390400767326355
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03288959860801697
    - config:
        BLOCK_SIZE_B: 1
      time: 0.033129599690437314
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033267199993133545
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03372479975223541
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04360319972038269
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03569599986076355
    - config:
        BLOCK_SIZE_B: 16
      time: 0.036687999963760376
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03672960102558136
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03678399920463562
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03713279962539673
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04017600119113922
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03272640109062195
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03301759958267212
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03308480083942413
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03320319950580597
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03333759903907776
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03354560136795044
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034355199337005614
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036032000184059144
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03607040047645569
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03612160086631775
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036396801471710205
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03674240112304687
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03704639971256256
    - config:
        BLOCK_SIZE_B: 256
      time: 0.038915199041366574
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.032380801439285276
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03248960077762604
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03256320059299469
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03294720053672791
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03331519961357117
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03356159925460815
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04422079920768738
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03583999872207642
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03615680038928985
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03627200126647949
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0367680013179779
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03703359961509704
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03728640079498291
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.038313600420951846
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09555519819259643
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7209472179412841
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.1354464054107666
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7764256000518799
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.032416000962257385
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0327455997467041
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03361279964447021
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03367359936237335
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033923199772834776
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05358399748802185
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14648640155792236
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.035795199871063235
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03609279990196228
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03644160032272339
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03673279881477356
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037110400199890134
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05470399856567383
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.15074559450149536
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03253119885921478
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03328000009059906
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033692800998687746
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03380480110645294
    - config:
        BLOCK_SIZE_B: 16
      time: 0.044537600874900815
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03621439933776856
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03626559972763062
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036399999260902406
    - config:
        BLOCK_SIZE_B: 1
      time: 0.036723199486732486
    - config:
        BLOCK_SIZE_B: 16
      time: 0.045286399126052854
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0321727991104126
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03229120075702667
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03294720053672791
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03312639892101288
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033369600772857666
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033471998572349546
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03432640135288238
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.035571199655532834
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03590399920940399
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03597440123558045
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03686720132827759
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03698880076408386
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03699199855327606
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03870719969272614
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03270080089569092
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033103999495506284
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03311040103435516
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033344000577926636
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03350079953670502
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03370240032672882
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03377279937267304
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.035708799958229065
    - config:
        BLOCK_SIZE_B: 32
      time: 0.035811200737953186
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03590399920940399
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03626559972763062
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03633599877357483
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0368800014257431
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03933440148830414
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.5735616207122802
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.2014432907104493
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03240639865398407
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03248000144958496
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03298560082912445
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03303360044956207
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0341376006603241
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06510400176048278
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17768319845199584
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03480960130691528
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.036355200409889224
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03654719889163971
    - config:
        BLOCK_SIZE_B: 512
      time: 0.037187200784683225
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03740800023078918
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06572160124778748
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17813760042190552
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.035046398639678955
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0355648010969162
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03680959939956665
    - config:
        BLOCK_SIZE_B: 8
      time: 0.14343680143356324
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03733760118484497
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037574398517608645
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03795199990272522
    - config:
        BLOCK_SIZE_B: 8
      time: 0.13876160383224487
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03309440016746521
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03313600122928619
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03316799998283386
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033846399188041686
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03467519879341126
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.03763839900493622
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.0642527997493744
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.036723199486732486
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.037536001205444335
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.038012799620628354
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03858239948749542
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03890239894390106
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.044182398915290834
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.09347519874572754
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03315199911594391
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03331199884414673
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03348160088062287
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033692800998687746
    - config:
        BLOCK_SIZE_B: 1
      time: 0.033881598711013795
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03412480056285858
    - config:
        BLOCK_SIZE_B: 64
      time: 0.05074560046195984
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0367680013179779
    - config:
        BLOCK_SIZE_B: 2
      time: 0.036771199107170104
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03689279854297638
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03701440095901489
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03709119856357575
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03754880130290985
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03795520067214966
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.032815998792648314
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03343679904937744
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033555200695991515
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03446399867534637
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0346015989780426
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034815999865531924
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043977600336074826
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03600319921970367
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03615039885044098
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03641600012779236
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03648000061511993
    - config:
        BLOCK_SIZE_B: 8
      time: 0.037571200728416444
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03765439987182617
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04483200013637543
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03370560109615326
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03373439908027649
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033923199772834776
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03394879996776581
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03398720026016235
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0343423992395401
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.037222400307655334
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03673279881477356
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03758719861507416
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03766719996929169
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03781439960002899
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03828479945659637
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03880319893360138
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.041494399309158325
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04779199957847595
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05076799988746643
    - config:
        BLOCK_SIZE_B: 4
      time: 0.2489311933517456
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05431039929389954
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0573311984539032
    - config:
        BLOCK_SIZE_B: 4
      time: 0.3269023895263672
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.032332798838615416
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03283199965953827
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03397440016269684
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03431040048599243
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03436160087585449
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.047279998660087585
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09924160242080689
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03569599986076355
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.036083200573921205
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.036380800604820254
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03695679903030395
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03715839982032776
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04791040122509003
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.1009376049041748
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03260799944400787
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0328000009059906
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03341760039329529
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0338239997625351
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03391039967536926
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03507519960403442
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.035596799850463864
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03615680038928985
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03617919981479645
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03644160032272339
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0365119993686676
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03808639943599701
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03203200101852417
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03283199965953827
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03329919874668121
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03373759984970093
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03381440043449402
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03407680094242096
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034780800342559814
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.036399999260902406
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03649600148200989
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036508798599243164
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03655360043048859
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03665600121021271
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03694080114364624
    - config:
        BLOCK_SIZE_B: 256
      time: 0.039996799826622007
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.032815998792648314
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03298879861831665
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033580800890922545
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033657601475715636
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03374080061912536
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03463039994239807
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04077439904212952
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03611519932746887
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03665600121021271
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03668160140514374
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03683840036392212
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03697920143604279
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03765760064125061
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.038790398836135866
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09536960124969482
    - config:
        BLOCK_SIZE_B: 2
      time: 0.42285761833190916
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.13159359693527223
    - config:
        BLOCK_SIZE_B: 2
      time: 0.687065601348877
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03306559920310974
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03307200074195862
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03349440097808838
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033871999382972716
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03405120074748993
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05355200171470642
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14693440198898317
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.035785600543022156
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03624320030212402
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03636800050735474
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03640320003032684
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0364544004201889
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.054825598001480104
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.15085439682006835
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03354560136795044
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033555200695991515
    - config:
        BLOCK_SIZE_B: 1
      time: 0.033609598875045776
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03400320112705231
    - config:
        BLOCK_SIZE_B: 16
      time: 0.05181760191917419
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03612479865550995
    - config:
        BLOCK_SIZE_B: 2
      time: 0.036483201384544375
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03707520067691803
    - config:
        BLOCK_SIZE_B: 8
      time: 0.038473600149154664
    - config:
        BLOCK_SIZE_B: 16
      time: 0.046412798762321475
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03269760012626648
    - config:
        BLOCK_SIZE_B: 32
      time: 0.032790398597717284
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03319360017776489
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033308801054954526
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03352639973163605
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03431679904460907
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03456639945507049
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036822399497032164
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036847999691963194
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03691200017929077
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03697279989719391
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0372191995382309
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03761920034885406
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03831680119037628
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0321727991104126
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03296639919281006
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03344640135765076
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033590400218963624
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03378559947013855
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03409920036792755
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04074560105800629
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.035743999481201175
    - config:
        BLOCK_SIZE_B: 32
      time: 0.036406400799751285
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036559998989105225
    - config:
        BLOCK_SIZE_B: 512
      time: 0.036627200245857236
    - config:
        BLOCK_SIZE_B: 16
      time: 0.036646398901939395
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03793599903583526
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03830719888210297
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.5787392139434815
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.307100772857666
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03287039995193482
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03331199884414673
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03360320031642914
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03453760147094727
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0350816011428833
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0651423990726471
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17759040594100953
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0366784006357193
    - config:
        BLOCK_SIZE_B: 512
      time: 0.036800000071525577
    - config:
        BLOCK_SIZE_B: 128
      time: 0.037299200892448425
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03775680065155029
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03849599957466125
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06558719873428345
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17812800407409668
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03503359854221344
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03517119884490967
    - config:
        BLOCK_SIZE_B: 2
      time: 0.035305601358413694
    - config:
        BLOCK_SIZE_B: 8
      time: 0.1098688006401062
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03715839982032776
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037699198722839354
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03818880021572113
    - config:
        BLOCK_SIZE_B: 8
      time: 0.09749439954757691
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03322240114212036
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0334879994392395
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03394240140914917
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03400320112705231
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03591679930686951
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04002560079097748
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.08872960209846496
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.036620798707008365
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03741439878940582
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.037462401390075686
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03828159868717194
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03844479918479919
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.0404992014169693
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.06307200193405152
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033548799157142636
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033580800890922545
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033616000413894655
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03361920118331909
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03416639864444733
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03437120020389557
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07615360021591186
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03613759875297547
    - config:
        BLOCK_SIZE_B: 32
      time: 0.036595198512077334
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03665919899940491
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03682560026645661
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03728959858417511
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03774079978466034
    - config:
        BLOCK_SIZE_B: 64
      time: 0.08759999871253968
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.032400000095367434
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03279680013656616
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033180800080299375
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03336319923400879
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033580800890922545
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03446080088615418
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0645632028579712
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03614720106124878
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03640320003032684
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03690559864044189
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037196800112724304
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0374208003282547
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03771840035915375
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07142080068588257
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03223359882831574
    - config:
        BLOCK_SIZE_B: 256
      time: 0.032576000690460204
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03351039886474609
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03358719944953918
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03413119912147522
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.035155200958251955
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.054476797580718994
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.035545599460601804
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03620480000972748
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036575999855995175
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03740800023078918
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03776639997959137
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03904640078544617
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.052275198698043826
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09334400296211243
    - config:
        BLOCK_SIZE_B: 2
      time: 0.09981120228767396
    - config:
        BLOCK_SIZE_B: 4
      time: 0.37971200942993166
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.10015360116958619
    - config:
        BLOCK_SIZE_B: 4
      time: 0.4474912166595459
    - config:
        BLOCK_SIZE_B: 2
      time: 0.522982406616211
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.032793599367141726
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03299840092658997
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03366400003433227
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03390080034732819
    - config:
        BLOCK_SIZE_B: 512
      time: 0.034297600388526917
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04917120039463043
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.0937279999256134
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03564479947090149
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03597759902477264
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.036320000886917114
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0373663991689682
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03758719861507416
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.05050240159034729
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09674559831619263
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.032579201459884646
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03282560110092163
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033024001121521
    - config:
        BLOCK_SIZE_B: 1
      time: 0.033344000577926636
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03370879888534546
    - config:
        BLOCK_SIZE_B: 32
      time: 0.1024448037147522
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.035478401184082034
    - config:
        BLOCK_SIZE_B: 8
      time: 0.035606399178504944
    - config:
        BLOCK_SIZE_B: 2
      time: 0.035769599676132205
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03590399920940399
    - config:
        BLOCK_SIZE_B: 4
      time: 0.037049600481987
    - config:
        BLOCK_SIZE_B: 32
      time: 0.1258944034576416
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033590400218963624
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033667200803756715
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033958399295806886
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033964800834655764
    - config:
        BLOCK_SIZE_B: 64
      time: 0.035043200850486754
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03574720025062561
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0729695975780487
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0359360009431839
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03600000143051148
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03629119992256165
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036374399065971376
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03709760010242462
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03817279934883118
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0766431987285614
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03298240005970001
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03316160142421722
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03326080143451691
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03357439935207367
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033852800726890564
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.036713600158691406
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0546239972114563
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03617280125617981
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036364799737930296
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0364544004201889
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036559998989105225
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03797119855880737
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03825919926166534
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06396160125732422
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.19546560049057007
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7727776050567627
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.0764543533325195
    - config:
        BLOCK_SIZE_B: 2
      time: 1.077014446258545
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.032227200269699094
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03426240086555481
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03429439961910248
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03461439907550812
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.035308799147605895
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05322880148887634
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.10819840431213379
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0355679988861084
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03622080087661743
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03642880022525787
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03671999871730804
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03718400001525879
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05340800285339355
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.1072991967201233
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.034467199444770814
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0347104012966156
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03504000008106232
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03505600094795227
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09807680249214172
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037302398681640626
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03770880103111267
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03857280015945434
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03914560079574585
    - config:
        BLOCK_SIZE_B: 16
      time: 0.15561599731445314
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.032662400603294374
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033081600069999696
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03312000036239624
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03340800106525421
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03394879996776581
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03402239978313446
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07858560085296631
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036233600974082944
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03625600039958954
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03633599877357483
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03656319975852966
    - config:
        BLOCK_SIZE_B: 16
      time: 0.036671999096870425
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03994239866733551
    - config:
        BLOCK_SIZE_B: 128
      time: 0.059868800640106204
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03244479894638062
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03284479975700379
    - config:
        BLOCK_SIZE_B: 32
      time: 0.034140801429748534
    - config:
        BLOCK_SIZE_B: 16
      time: 0.034246399998664856
    - config:
        BLOCK_SIZE_B: 64
      time: 0.035020801424980166
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03866240084171295
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06487680077552796
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03583039939403534
    - config:
        BLOCK_SIZE_B: 256
      time: 0.036057600378990175
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03610239923000336
    - config:
        BLOCK_SIZE_B: 32
      time: 0.036111998558044436
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036348798871040346
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03809599876403809
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0631168007850647
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.60098876953125
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.0232608795166014
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03281919956207276
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03304319977760315
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033190399408340454
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03368319869041443
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03408640027046204
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06392639875411987
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.1756608009338379
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03553920090198517
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03566400110721588
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.036099201440811156
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03644480109214783
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03709119856357575
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06522240042686463
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.16692800521850587
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04724160134792328
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0486624002456665
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0522816002368927
    - config:
        BLOCK_SIZE_B: 8
      time: 0.1822559952735901
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0494271993637085
    - config:
        BLOCK_SIZE_B: 2
      time: 0.049619200825691226
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06715199947357178
    - config:
        BLOCK_SIZE_B: 8
      time: 0.24580159187316894
  kernels/swiglu/backward.py->_backward:
    '''gate.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.28021440505981443
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.28063359260559084
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.28102080821990966
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2811583995819092
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.28120639324188235
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.2812448024749756
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.2812704086303711
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2815007925033569
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.28158719539642335
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.28158719539642335
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.28170878887176515
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.281878399848938
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.28188159465789797
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.2819551944732666
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.29586238861083985
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.3029599905014038
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.3030175924301147
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.3663167953491211
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.49740800857543943
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.5974592208862305
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9897919654846191
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 3.889923095703125
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 4.075392150878907
    '''gate.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.2784640073776245
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.2785759925842285
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.2788032054901123
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.27900478839874265
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2790591955184937
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.27907519340515136
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.27911040782928465
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.27913599014282225
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.2795104026794434
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.27961599826812744
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.27969601154327395
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.27977919578552246
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.2797951936721802
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.2806272029876709
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2945823907852173
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.30081279277801515
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.30090880393981934
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.3167648077011108
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.4973599910736084
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.5335231781005859
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9899456024169921
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 3.5876190185546877
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 3.630227279663086
    '''gate.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.5528223991394043
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.5540224075317383
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.5544159889221192
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.5549439907073974
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.5568543910980225
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.5584320068359375
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.5598783969879151
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.5628831863403321
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.5757440090179443
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.58090238571167
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.5818079948425293
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.6164927959442139
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.9206944465637207
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9907999992370605
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 1.2169055938720703
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 4.750681686401367
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 4.861587142944336
  kernels/swiglu/forward.py->_forward:
    '''gate.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14094719886779786
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.1412320017814636
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.14130560159683228
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.14153920412063598
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.1415552020072937
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.14160319566726684
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.1422144055366516
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.1431712031364441
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.14408960342407226
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.14415680170059203
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.14703999757766723
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.1479583978652954
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.14834879636764525
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.1495584011077881
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.1532256007194519
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.15326399803161622
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 0.2129983901977539
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2502912044525146
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.25042879581451416
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2506239891052246
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.4961855888366699
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9897151947021484
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 1.1494303703308106
    '''gate.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.1407807946205139
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.1411520004272461
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.1412287950515747
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.1413632035255432
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.14140479564666747
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.14142719507217408
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.14252480268478393
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.14339840412139893
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.14347200393676757
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.14619840383529664
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.1466879963874817
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.14741120338439942
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.14756799936294557
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.1526368021965027
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.15285439491271974
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.15685759782791137
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 0.21044480800628662
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2504415988922119
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2505311965942383
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2506112098693848
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.49634881019592286
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9897695541381836
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 1.1539520263671874
    '''gate.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.27740800380706787
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.27758400440216063
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.277894401550293
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.27825920581817626
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.27838399410247805
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.27850239276885985
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.2813407897949219
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.2819135904312134
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.2851423978805542
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2871295928955078
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.30749120712280276
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.34983680248260496
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.496124792098999
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.4965248107910156
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9872320175170899
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 1.9812576293945312
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 2.0593311309814455
  kernels/swiglu_unchunked/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5610464096069336
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.0195135116577148
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 3.246054458618164
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.535455322265626
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.646803283691405
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.532041645050049
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.7299840927124024
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.7523519515991213
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.892985534667968
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.164495849609374
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.6102624893188477
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 3.2032192230224608
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 5.6640064239501955
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.084185791015624
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.340611267089844
  kernels/swiglu_unchunked/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9554400444030762
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9556063652038574
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.0495936393737793
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.3202560424804688
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 6.211494445800781
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9421440124511719
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9480192184448242
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.042902374267578
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.2571359634399415
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 6.155315017700195
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5743359565734862
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.6341056823730469
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.8551008224487304
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 8.701280212402343
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 8.706172943115234
best_configs:
  kernels/add/add_scalar/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14102400541305543
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14056639671325682
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27791359424591067
  kernels/add/add_tensor/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14080640077590942
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14036159515380858
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2776384115219116
  kernels/embedding/backward.py->_backward:
    '''weight.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.254755401611328
    '''weight.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 3.5278656005859377
    '''weight.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 9.80187530517578
  kernels/embedding/forward.py->_forward:
    '''weight.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6654623985290528
    '''weight.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6663392066955567
    '''weight.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.3729023933410645
  kernels/rmsnorm/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float32''':
      config:
        kernel_backend: triton
      time: 0
  kernels/rmsnorm/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float32''':
      config:
        kernel_backend: triton
      time: 0
  kernels/rmsnorm/triton_implementation/kernels_backward.py->rmsnorm_backward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.04115520119667053
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.0685151994228363
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04176000058650971
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.06867200136184692
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04117439985275269
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06926079988479614
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04069119989871979
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.07025279998779296
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07904959917068481
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 1.491267204284668
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04167360067367554
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.06856639981269837
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.041308799386024476
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.06958720088005066
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.04048640131950378
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06904320120811462
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.041116800904273984
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.06901760101318359
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.1121536254882813
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 3.6108577728271483
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.04187839925289154
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.0695360004901886
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04259200096130371
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07069439888000488
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.04105600118637085
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06809920072555542
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04046080112457275
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.06810240149497986
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.221788787841797
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 10.473375701904297
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.041075199842453
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.06976320147514344
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.044819200038909913
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07168319821357727
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16384
      time: 0.04172160029411316
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.06944959759712219
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04139519929885864
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06882240176200867
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.041315200924873355
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06867200136184692
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.042089599370956424
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.06905919909477234
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07858240008354186
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.1232159614562989
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04180159866809845
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.07005760073661804
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04139519929885864
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.06894720196723939
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04166400134563446
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06843839883804322
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.041875201463699344
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.07052479982376099
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.8834943771362305
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 2.978803253173828
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.04245119988918304
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.07076799869537354
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.043331199884414674
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06961280107498169
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04205760061740875
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06904640197753906
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.04213759899139404
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.07043840289115906
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.8188543319702148
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 8.320972442626953
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.042371198534965515
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.06961280107498169
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.046387198567390445
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.0722656011581421
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.04230400025844574
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16384
      time: 0.06231039762496948
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.04203839898109436
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.062063997983932494
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04227199852466583
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.06195840239524841
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.042991998791694644
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.06175680160522461
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.14488960504531861
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.659334373474121
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04219520092010498
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.0622111976146698
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04262720048427582
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.0626911997795105
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04130240082740784
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06180480122566223
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04166400134563446
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.061990398168563846
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.7398271560668945
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 4.268883132934571
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.041552001237869264
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.029523199796676634
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04301120042800903
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.063372802734375
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.04128639996051788
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06159999966621399
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.04171839952468872
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06204800009727478
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 7.575443267822266
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 10.238384246826172
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.0414112001657486
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.06218559741973877
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07212160229682922
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.08425920009613037
  kernels/rmsnorm/triton_implementation/kernels_forward.py->rmsnorm_forward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.0328031986951828
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.035462400317192076
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03244799971580505
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.035724800825119016
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03227519989013672
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.035488000512123107
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03240639865398407
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03630079925060272
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.047977599501609805
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.05299199819564819
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03311359882354736
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03564479947090149
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.032390400767326355
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03569599986076355
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03272640109062195
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.036032000184059144
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.032380801439285276
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03583999872207642
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09555519819259643
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.1354464054107666
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.032416000962257385
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.035795199871063235
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03253119885921478
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03621439933776856
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.0321727991104126
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.035571199655532834
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03270080089569092
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.035708799958229065
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.5735616207122802
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.2014432907104493
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03240639865398407
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03480960130691528
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.035046398639678955
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03733760118484497
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03309440016746521
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.036723199486732486
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03315199911594391
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.0367680013179779
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.032815998792648314
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03600319921970367
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03370560109615326
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03673279881477356
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04779199957847595
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.05431039929389954
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.032332798838615416
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03569599986076355
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03260799944400787
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.035596799850463864
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03203200101852417
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.036399999260902406
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.032815998792648314
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03611519932746887
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09536960124969482
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.13159359693527223
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03306559920310974
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.035785600543022156
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03354560136795044
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03612479865550995
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03269760012626648
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.036822399497032164
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.0321727991104126
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.035743999481201175
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.5787392139434815
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.307100772857666
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03287039995193482
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.0366784006357193
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03503359854221344
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03715839982032776
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03322240114212036
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.036620798707008365
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.033548799157142636
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.03613759875297547
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.032400000095367434
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03614720106124878
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03223359882831574
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.035545599460601804
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09334400296211243
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.10015360116958619
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.032793599367141726
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03564479947090149
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.032579201459884646
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.035478401184082034
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.033590400218963624
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.0359360009431839
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03298240005970001
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03617280125617981
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.19546560049057007
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.0764543533325195
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.032227200269699094
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.0355679988861084
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.034467199444770814
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.037302398681640626
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.032662400603294374
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.036233600974082944
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03244479894638062
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03583039939403534
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.60098876953125
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.0232608795166014
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03281919956207276
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03553920090198517
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04724160134792328
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.0494271993637085
  kernels/swiglu/backward.py->_backward:
    '''gate.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.28021440505981443
    '''gate.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.2784640073776245
    '''gate.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.5528223991394043
  kernels/swiglu/forward.py->_forward:
    '''gate.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14094719886779786
    '''gate.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.1407807946205139
    '''gate.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.27740800380706787
  kernels/swiglu_unchunked/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5610464096069336
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.532041645050049
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.6102624893188477
  kernels/swiglu_unchunked/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9554400444030762
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9421440124511719
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5743359565734862
