all_configs:
  kernels/add/add_scalar/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.141046404838562
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14107199907302856
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14136960506439208
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14136960506439208
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1414687991142273
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14166719913482667
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14173120260238647
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14215680360794067
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14219199419021605
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.142467200756073
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14309760332107543
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14430400133132934
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14572800397872926
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14820480346679688
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1492735981941223
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15289920568466187
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1590783953666687
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18398720026016235
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20236799716949463
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.22986240386962892
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2498784065246582
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.24998719692230226
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2500511884689331
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2507807970046997
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30271360874176023
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3328991889953613
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38096320629119873
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49628801345825196
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49657602310180665
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4966271877288818
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4966911792755127
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.989475154876709
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9900896072387695
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9901568412780761
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9778144836425782
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14085760116577148
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14092799425125122
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14093760251998902
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14131840467453002
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14132159948349
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14137279987335205
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1414528012275696
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14256319999694825
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14263360500335692
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14305280447006224
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14326399564743042
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1439296007156372
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14558080434799195
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.147433602809906
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14790719747543335
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1524448037147522
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15899200439453126
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18383680582046508
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.202239990234375
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.22976319789886473
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.25008320808410645
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2501471996307373
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.25040640830993655
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.25067839622497556
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3034336090087891
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3335360050201416
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3818655967712402
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49639358520507815
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49652800559997556
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49664959907531736
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49705281257629397
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9898431777954102
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9905887603759765
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9906559944152832
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9780960083007812
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778496026992798
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27822399139404297
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2783456087112427
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27873280048370364
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2787391901016235
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2789184093475342
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2789376020431519
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2808511972427368
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28120639324188235
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28222079277038575
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2823807954788208
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2846719980239868
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.28688640594482423
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2915168046951294
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.29586238861083985
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.30122880935668944
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.31302719116210936
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3571039915084839
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.39004480838775635
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.43677120208740233
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4958240032196045
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4958943843841553
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49653120040893556
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4970079898834229
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9716383934020996
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9874943733215332
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9877311706542968
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9878560066223144
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9719520568847657
  kernels/add/add_tensor/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1410815954208374
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14110080003738404
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1411903977394104
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14120639562606813
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1412768006324768
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1413856029510498
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14188159704208375
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14203200340270997
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14203200340270997
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1422144055366516
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14232319593429565
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1446879982948303
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14607679843902588
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14806400537490844
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15291520357131957
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15920000076293944
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18367680311203002
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20214719772338868
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.22973759174346925
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.24996159076690674
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.25017600059509276
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.25030078887939455
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2504767894744873
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30503358840942385
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3367775917053223
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38626561164855955
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49568638801574705
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4957695960998535
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4957727909088135
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49652800559997556
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9639072418212891
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9878399848937989
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9880064010620118
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9891839981079101
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9722303390502929
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1406880021095276
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14077759981155397
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1409119963645935
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14100799560546876
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14116159677505494
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14135680198669434
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14168640375137329
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14168959856033325
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1419263958930969
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14235199689865113
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14287680387496948
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14408639669418336
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14573440551757813
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14815679788589478
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15280959606170655
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1589568018913269
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.1837183952331543
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2023871898651123
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.23004159927368165
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.24979519844055176
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.24997119903564452
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.24998080730438232
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2502912044525146
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30608320236206055
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.33755519390106203
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38690240383148194
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4954527854919434
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4957632064819336
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4957791805267334
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49585280418395994
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.987609577178955
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9879199981689453
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9879263877868653
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 1.0364671707153321
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.972719955444336
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778559923171997
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2779871940612793
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2782111883163452
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2782399892807007
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2784672021865845
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2791327953338623
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27952640056610106
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2796319961547852
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2806240081787109
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2807744026184082
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2813503980636597
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2849056005477905
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.287443208694458
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2922271966934204
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3015360116958618
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3134495973587036
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.358620810508728
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.39258880615234376
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.43900160789489745
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4960991859436035
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4962207794189453
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49686079025268554
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4969791889190674
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.98787841796875
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9883071899414062
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9886912345886231
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9719871520996093
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.007379150390625
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.094166374206543
  kernels/embedding/backward.py->_backward:
    '''weight.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.250962829589843
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 10.270985412597657
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.310384368896484
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 11.17128677368164
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 11.251715087890625
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 11.489961242675781
    '''weight.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 3.520441436767578
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.234486389160156
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.248371124267578
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.594137573242188
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.611248016357422
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 5.786969757080078
    '''weight.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 9.787811279296875
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 9.808060455322266
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.033232116699219
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.207049560546874
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.478928375244141
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.840665435791015
  kernels/embedding/forward.py->_forward:
    '''weight.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6663392066955567
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6666592121124267
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7012800216674805
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7245791912078857
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.7806144237518311
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 0.8636768341064454
    '''weight.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6661375999450684
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6671520233154297
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.700438404083252
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7267327785491944
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.7810783863067627
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 0.8651391983032226
    '''weight.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.3731871604919434
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.4229951858520509
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 1.7100704193115235
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 4.774563217163086
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.028534317016602
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.281945419311524
  kernels/rmsnorm/triton_implementation/kernels_backward.py->rmsnorm_backward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.042710399627685545
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04401600062847137
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.044156798720359804
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.044809600710868834
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.045948800444602964
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.0911520004272461
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.23096001148223877
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06815999746322632
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06928319931030273
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06954879760742187
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0698848009109497
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.07064639925956726
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.093612802028656
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.22559359073638915
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.042844799160957334
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0429280012845993
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0433023989200592
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04337919950485229
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04414399862289429
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07816640138626099
    - config:
        BLOCK_SIZE_B: 64
      time: 0.18187520503997803
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06816639900207519
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0685536026954651
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06881279945373535
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06927679777145386
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06948800086975097
    - config:
        BLOCK_SIZE_B: 32
      time: 0.1370303988456726
    - config:
        BLOCK_SIZE_B: 64
      time: 0.41256961822509763
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.041833600401878356
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04246399998664856
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04347200095653534
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04391680061817169
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04412479996681214
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04443840086460114
    - config:
        BLOCK_SIZE_B: 512
      time: 0.05274559855461121
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06850240230560303
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06881600022315978
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06919999718666077
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06929600238800049
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0695360004901886
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06980800032615661
    - config:
        BLOCK_SIZE_B: 512
      time: 0.2008671998977661
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.043635201454162595
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04411199986934662
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04419200122356415
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04420480132102966
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04493120014667511
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0455487996339798
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04660800099372864
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06833919882774353
    - config:
        BLOCK_SIZE_B: 128
      time: 0.068367999792099
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06846719980239868
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06896960139274597
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0700543999671936
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07124159932136535
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.15991679430007935
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07871360182762147
    - config:
        BLOCK_SIZE_B: 2
      time: 0.5496479988098144
    - config:
        BLOCK_SIZE_B: 4
      time: 0.714188814163208
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 1.5544575691223144
    - config:
        BLOCK_SIZE_B: 1
      time: 1.6186080932617188
    - config:
        BLOCK_SIZE_B: 4
      time: 2.793270492553711
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04285120069980621
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04371519982814789
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.043721601366996765
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04451520144939423
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04462080001831055
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06423680186271667
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.19258559942245485
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06821439862251281
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06851840019226074
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06903679966926575
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06978240013122558
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07000960111618042
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.09364479780197144
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.17467520236968995
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04368320107460022
    - config:
        BLOCK_SIZE_B: 2
      time: 0.043705600500106814
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04376319944858551
    - config:
        BLOCK_SIZE_B: 8
      time: 0.044460800290107724
    - config:
        BLOCK_SIZE_B: 16
      time: 0.10926719903945922
    - config:
        BLOCK_SIZE_B: 32
      time: 0.26038079261779784
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06914560198783874
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06916159987449647
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06921600103378296
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06954560279846192
    - config:
        BLOCK_SIZE_B: 16
      time: 0.21446080207824708
    - config:
        BLOCK_SIZE_B: 32
      time: 0.5257599830627442
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0430400013923645
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04317440092563629
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04341759979724884
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04361599981784821
    - config:
        BLOCK_SIZE_B: 16
      time: 0.043808001279830935
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04407039880752563
    - config:
        BLOCK_SIZE_B: 256
      time: 0.05135999917984009
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06629440188407898
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06789119839668274
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06795200109481811
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06929600238800049
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06989759802818299
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07083200216293335
    - config:
        BLOCK_SIZE_B: 256
      time: 0.19603519439697265
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04236479997634888
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04248960018157959
    - config:
        BLOCK_SIZE_B: 128
      time: 0.042931199073791504
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04418880045413971
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04437119960784912
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.046351999044418335
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.05273280143737793
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06740480065345764
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06834239959716797
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06839680075645446
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06900479793548583
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06958079934120179
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07259520292282104
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.16667840480804444
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.112377643585205
    - config:
        BLOCK_SIZE_B: 2
      time: 1.8148223876953125
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 3.699203109741211
    - config:
        BLOCK_SIZE_B: 1
      time: 4.292243194580078
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04430719912052154
    - config:
        BLOCK_SIZE_B: 256
      time: 0.044352000951766966
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.044377601146698
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04442239999771118
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04476479887962341
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.0657151997089386
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.21223680973052977
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06665599942207337
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06705600023269653
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06716480255126953
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06869120001792908
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07002239823341369
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.10115519762039185
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.17313599586486816
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.044537600874900815
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04498879909515381
    - config:
        BLOCK_SIZE_B: 4
      time: 0.045731198787689206
    - config:
        BLOCK_SIZE_B: 8
      time: 0.1785312056541443
    - config:
        BLOCK_SIZE_B: 16
      time: 0.26829121112823484
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07079359889030457
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07171199917793274
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07250880002975464
    - config:
        BLOCK_SIZE_B: 8
      time: 0.4686880111694336
    - config:
        BLOCK_SIZE_B: 16
      time: 0.8325728416442871
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.043382400274276735
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04349119961261749
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0435263991355896
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04360640048980713
    - config:
        BLOCK_SIZE_B: 2
      time: 0.044547200202941895
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0536191999912262
    - config:
        BLOCK_SIZE_B: 128
      time: 0.140067195892334
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06705600023269653
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06720960140228271
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06736639738082886
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06779519915580749
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06816319823265075
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10560959577560425
    - config:
        BLOCK_SIZE_B: 128
      time: 0.34846398830413816
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04180479943752289
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04342080056667328
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0435232013463974
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04360640048980713
    - config:
        BLOCK_SIZE_B: 16
      time: 0.043654400110244754
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04579519927501678
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04956479966640472
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06654400229454041
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06828479766845703
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06879040002822875
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06944959759712219
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06977919936180114
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0719327986240387
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.1679487943649292
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.244460868835449
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 10.36596450805664
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0435808002948761
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04406079947948456
    - config:
        BLOCK_SIZE_B: 256
      time: 0.044099199771881106
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04470399916172028
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04695999920368195
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07765439748764039
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.21889920234680177
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06755520105361938
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06849279999732971
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06880639791488648
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06950719952583313
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07755200266838073
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.13704639673233032
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.3080064058303833
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.046387198567390445
    - config:
        BLOCK_SIZE_B: 1
      time: 0.052112001180648806
    - config:
        BLOCK_SIZE_B: 4
      time: 0.13050880432128906
    - config:
        BLOCK_SIZE_B: 8
      time: 0.6207968235015869
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09535679817199708
    - config:
        BLOCK_SIZE_B: 2
      time: 0.1078112006187439
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6811872005462647
    - config:
        BLOCK_SIZE_B: 8
      time: 1.5876832008361816
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04259839951992035
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04309119880199432
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0438400000333786
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.044064000248909
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.045023998618125914
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.090447998046875
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.24453439712524414
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06732159852981567
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06817600131034851
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06895359754562377
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07049279808998107
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.0714847981929779
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.07491520047187805
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.16726080179214478
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04223040044307709
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04316479861736298
    - config:
        BLOCK_SIZE_B: 2
      time: 0.043424001336097716
    - config:
        BLOCK_SIZE_B: 16
      time: 0.043484801054000856
    - config:
        BLOCK_SIZE_B: 4
      time: 0.045132800936698914
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07083839774131775
    - config:
        BLOCK_SIZE_B: 64
      time: 0.14340800046920776
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06660159826278686
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06747519969940186
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06920959949493408
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0700160026550293
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07089599967002869
    - config:
        BLOCK_SIZE_B: 32
      time: 0.1143072009086609
    - config:
        BLOCK_SIZE_B: 64
      time: 0.3114943981170654
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.042473599314689636
    - config:
        BLOCK_SIZE_B: 32
      time: 0.042761600017547606
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04453440010547638
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04453440010547638
    - config:
        BLOCK_SIZE_B: 256
      time: 0.044835200905799864
    - config:
        BLOCK_SIZE_B: 16
      time: 0.044863998889923096
    - config:
        BLOCK_SIZE_B: 512
      time: 0.048783999681472776
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06807360053062439
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06822400093078614
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06869760155677795
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06919360160827637
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06997759938240052
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07085760235786438
    - config:
        BLOCK_SIZE_B: 512
      time: 0.08239359855651855
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04307200014591217
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043808001279830935
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04406079947948456
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04420160055160523
    - config:
        BLOCK_SIZE_B: 256
      time: 0.044435200095176694
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04575360119342804
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04864639937877655
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06768959760665894
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06865919828414917
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06876479983329772
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06898559927940369
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.069760000705719
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07287999987602234
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07491840124130249
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0782368004322052
    - config:
        BLOCK_SIZE_B: 2
      time: 0.44883198738098146
    - config:
        BLOCK_SIZE_B: 4
      time: 0.5714975833892822
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.0602815628051758
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2151007652282715
    - config:
        BLOCK_SIZE_B: 4
      time: 2.035763168334961
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04257920086383819
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0434112012386322
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04375360012054443
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04493440091609955
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04525440037250519
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06317759752273559
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.16315200328826904
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0673919975757599
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06802560091018676
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06824319958686828
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06840320229530335
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06863679885864257
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.11542079448699952
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.2632319927215576
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043673598766326906
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04423680007457733
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0443231999874115
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04464319944381714
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09536319971084595
    - config:
        BLOCK_SIZE_B: 32
      time: 0.17977279424667358
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06835520267486572
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06943359971046448
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07018240094184876
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07056000232696533
    - config:
        BLOCK_SIZE_B: 16
      time: 0.16378560066223144
    - config:
        BLOCK_SIZE_B: 32
      time: 0.36592960357666016
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0423007994890213
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04301440119743347
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04314880073070526
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04330880045890808
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04387199878692627
    - config:
        BLOCK_SIZE_B: 32
      time: 0.043942400813102724
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04583359956741333
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06645119786262513
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06675840020179749
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06700159907341004
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06712639927864075
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06804800033569336
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07061439752578735
    - config:
        BLOCK_SIZE_B: 256
      time: 0.10352959632873535
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04287680089473724
    - config:
        BLOCK_SIZE_B: 32
      time: 0.043408000469207765
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04359039962291718
    - config:
        BLOCK_SIZE_B: 64
      time: 0.043731200695037845
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04376640021800995
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04503999948501587
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04709759950637817
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06717119812965393
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06728000044822693
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06815360188484192
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06963199973106385
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06988160014152527
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06988160014152527
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07799040079116822
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.8872703552246094
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2194016456604004
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 3.101523208618164
    - config:
        BLOCK_SIZE_B: 1
      time: 3.1877023696899416
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04323840141296387
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0435808002948761
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04363200068473816
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04405440092086792
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04425599873065948
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06816319823265075
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.17920320034027098
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06716480255126953
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06813120245933532
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06859840154647827
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06864320039749146
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06934400200843811
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.14094719886779786
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.30052480697631834
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0438400000333786
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04493120014667511
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04564799964427948
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07895680069923401
    - config:
        BLOCK_SIZE_B: 16
      time: 0.2661823987960815
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06951680183410644
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07016639709472657
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07037439942359924
    - config:
        BLOCK_SIZE_B: 16
      time: 0.38679680824279783
    - config:
        BLOCK_SIZE_B: 8
      time: 0.3901535987854004
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.043673598766326906
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04408319890499115
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04436799883842468
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04464319944381714
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04520959854125976
    - config:
        BLOCK_SIZE_B: 64
      time: 0.05443199872970581
    - config:
        BLOCK_SIZE_B: 128
      time: 0.11316800117492676
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06716480255126953
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06798400282859803
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06811519861221313
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06819199919700622
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07021120190620422
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10329279899597169
    - config:
        BLOCK_SIZE_B: 128
      time: 0.2233344078063965
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04266240000724793
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04279040098190308
    - config:
        BLOCK_SIZE_B: 32
      time: 0.043075200915336606
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04362559914588928
    - config:
        BLOCK_SIZE_B: 128
      time: 0.043696001172065735
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04410879909992218
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.05044159889221191
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06738240122795106
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06800000071525573
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06852480173110961
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06926400065422059
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06941120028495788
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06941120028495788
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07699519991874695
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.8261215209960937
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 8.192931365966796
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04387840032577515
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04393920004367828
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04430400133132935
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04439679980278015
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.047712001204490664
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07744320034980774
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.21860480308532715
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06716480255126953
    - config:
        BLOCK_SIZE_B: 512
      time: 0.068476802110672
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06858559846878051
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06896640062332153
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07037119865417481
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.11151679754257202
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.1942304015159607
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04814079999923706
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05119680166244507
    - config:
        BLOCK_SIZE_B: 4
      time: 0.22912321090698243
    - config:
        BLOCK_SIZE_B: 8
      time: 0.4607391834259033
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09411200284957885
    - config:
        BLOCK_SIZE_B: 2
      time: 0.4704160213470459
    - config:
        BLOCK_SIZE_B: 4
      time: 0.614358377456665
    - config:
        BLOCK_SIZE_B: 8
      time: 0.9022527694702148
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04351679980754852
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04480000138282776
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04535999894142151
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.045423999428749084
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04630720019340515
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.0741919994354248
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.16314879655838013
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.059910398721694944
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06141759753227234
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06173440217971802
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06255679726600646
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06466559767723083
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.0847487986087799
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.22860479354858398
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04336319863796234
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043756800889968875
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04464319944381714
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04516479969024658
    - config:
        BLOCK_SIZE_B: 16
      time: 0.05585920214653015
    - config:
        BLOCK_SIZE_B: 32
      time: 0.11131199598312377
    - config:
        BLOCK_SIZE_B: 64
      time: 0.28612480163574217
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.061401599645614625
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06218559741973877
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06231039762496948
    - config:
        BLOCK_SIZE_B: 1
      time: 0.062457597255706786
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09329919815063477
    - config:
        BLOCK_SIZE_B: 32
      time: 0.1478592038154602
    - config:
        BLOCK_SIZE_B: 64
      time: 0.33166720867156985
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04439359903335571
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04441600143909454
    - config:
        BLOCK_SIZE_B: 16
      time: 0.044809600710868834
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04485760033130646
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04657920002937317
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04791040122509003
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07793920040130616
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06068159937858582
    - config:
        BLOCK_SIZE_B: 32
      time: 0.061504000425338747
    - config:
        BLOCK_SIZE_B: 16
      time: 0.061887997388839724
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06245120167732239
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06291199922561645
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06960319876670837
    - config:
        BLOCK_SIZE_B: 512
      time: 0.11616319417953491
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04383040070533752
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04386560022830963
    - config:
        BLOCK_SIZE_B: 64
      time: 0.044512000679969785
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0446368008852005
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04861119985580444
    - config:
        BLOCK_SIZE_B: 256
      time: 0.05251839756965637
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.05887680053710938
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06058239936828613
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06101440191268921
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06111360192298889
    - config:
        BLOCK_SIZE_B: 128
      time: 0.061267197132110596
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06254400014877319
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0642911970615387
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.11464320421218872
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.1458624005317688
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2964544296264648
    - config:
        BLOCK_SIZE_B: 4
      time: 1.7294687271118163
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.7027008056640625
    - config:
        BLOCK_SIZE_B: 2
      time: 2.0050655364990235
    - config:
        BLOCK_SIZE_B: 4
      time: 3.3727390289306642
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.042796799540519716
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043568000197410583
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04410879909992218
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04411520063877106
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.044627198576927186
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04875519871711731
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.2652928113937378
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.05974400043487549
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.060524797439575194
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06069440245628357
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06137920022010803
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06386560201644897
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.09036800265312195
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.33302080631256104
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.044819200038909913
    - config:
        BLOCK_SIZE_B: 1
      time: 0.045263999700546266
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04578559994697571
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04615359902381897
    - config:
        BLOCK_SIZE_B: 16
      time: 0.1658687949180603
    - config:
        BLOCK_SIZE_B: 32
      time: 0.24924800395965577
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06156799793243408
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06315199732780456
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06320319771766662
    - config:
        BLOCK_SIZE_B: 8
      time: 0.2127135992050171
    - config:
        BLOCK_SIZE_B: 16
      time: 0.24232640266418456
    - config:
        BLOCK_SIZE_B: 32
      time: 0.40294718742370605
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.043075200915336606
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04310399889945984
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043507200479507444
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04359999895095825
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04534400105476379
    - config:
        BLOCK_SIZE_B: 128
      time: 0.05389760136604309
    - config:
        BLOCK_SIZE_B: 256
      time: 0.1592576026916504
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.05904319882392883
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0605567991733551
    - config:
        BLOCK_SIZE_B: 16
      time: 0.060838401317596436
    - config:
        BLOCK_SIZE_B: 64
      time: 0.061766397953033444
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06260480284690857
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0756767988204956
    - config:
        BLOCK_SIZE_B: 256
      time: 0.2466752052307129
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04363200068473816
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04384639859199524
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04395520091056824
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043996798992156985
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04812160134315491
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04845759868621826
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06701760292053223
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.05947520136833191
    - config:
        BLOCK_SIZE_B: 64
      time: 0.061289602518081666
    - config:
        BLOCK_SIZE_B: 32
      time: 0.061596798896789554
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06204479932785034
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06223999857902527
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06783040165901184
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.10409599542617798
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.756972885131836
    - config:
        BLOCK_SIZE_B: 2
      time: 3.533894348144531
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 4.382896041870117
    - config:
        BLOCK_SIZE_B: 2
      time: 5.235878372192383
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.043059200048446655
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04334399998188019
    - config:
        BLOCK_SIZE_B: 256
      time: 0.043375998735427856
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04391359984874725
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04657280147075653
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05199360251426697
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.3422911882400513
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.060835200548172
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06110720038414001
    - config:
        BLOCK_SIZE_B: 256
      time: 0.062428802251815796
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.062454402446746826
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06364480257034302
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.09660159945487976
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.26344320774078367
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04592320024967193
    - config:
        BLOCK_SIZE_B: 4
      time: 0.046140798926353456
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0469215989112854
    - config:
        BLOCK_SIZE_B: 8
      time: 0.26696960926055907
    - config:
        BLOCK_SIZE_B: 16
      time: 0.3253887891769409
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06822720170021057
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07457280158996582
    - config:
        BLOCK_SIZE_B: 4
      time: 0.3887936115264893
    - config:
        BLOCK_SIZE_B: 8
      time: 0.5674848079681396
    - config:
        BLOCK_SIZE_B: 16
      time: 0.5912576198577881
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04364160001277924
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04368639886379242
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0442656010389328
    - config:
        BLOCK_SIZE_B: 16
      time: 0.044566398859024046
    - config:
        BLOCK_SIZE_B: 32
      time: 0.050809597969055174
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10094720125198364
    - config:
        BLOCK_SIZE_B: 128
      time: 0.17464959621429443
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.061286401748657224
    - config:
        BLOCK_SIZE_B: 8
      time: 0.061363202333450315
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06144319772720337
    - config:
        BLOCK_SIZE_B: 2
      time: 0.061868798732757566
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07101439833641052
    - config:
        BLOCK_SIZE_B: 64
      time: 0.11616640090942383
    - config:
        BLOCK_SIZE_B: 128
      time: 0.23136320114135742
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04227519929409027
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04361599981784821
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04399999976158142
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04472000002861023
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04488320052623749
    - config:
        BLOCK_SIZE_B: 512
      time: 0.046982398629188536
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07071359753608704
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.05950719714164734
    - config:
        BLOCK_SIZE_B: 16
      time: 0.059935998916625974
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06068800091743469
    - config:
        BLOCK_SIZE_B: 128
      time: 0.061129599809646606
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06388480067253113
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06457279920578003
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.10931839942932128
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 7.536089324951172
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 10.488249969482421
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043171200156211856
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0435808002948761
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04485119879245758
    - config:
        BLOCK_SIZE_B: 256
      time: 0.044886401295661925
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04636479914188385
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06848000288009644
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.2698080062866211
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.05902400016784668
    - config:
        BLOCK_SIZE_B: 512
      time: 0.060048002004623416
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06021760106086731
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06077119708061218
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06272640228271484
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.10532480478286743
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.2880064010620117
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07261760234832763
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07504640221595764
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6360544204711914
    - config:
        BLOCK_SIZE_B: 8
      time: 0.7892735958099365
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.11234879493713379
    - config:
        BLOCK_SIZE_B: 2
      time: 0.6670303821563721
    - config:
        BLOCK_SIZE_B: 4
      time: 0.9027327537536621
    - config:
        BLOCK_SIZE_B: 8
      time: 1.398799991607666
  kernels/rmsnorm/triton_implementation/kernels_forward.py->rmsnorm_forward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.034230399131774905
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03437120020389557
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.035043200850486754
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03516800105571747
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.035504001379013064
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04597119987010956
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.09439679980278015
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.036985599994659425
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.037283200025558474
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0379584014415741
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03825600147247314
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03853760063648224
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04958080053329468
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.10896960496902466
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03308480083942413
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03366079926490784
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03449600040912628
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03468799889087677
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03492160141468048
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0354559987783432
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04659200012683869
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03701440095901489
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03719359934329987
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037484800815582274
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03760640025138855
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03770880103111267
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03858560025691986
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03874559998512268
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03278079926967621
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03400320112705231
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0340256005525589
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03420799970626831
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03460800051689148
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03496319949626923
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03563840091228485
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036671999096870425
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037590399384498596
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03768959939479828
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037894400954246524
    - config:
        BLOCK_SIZE_B: 8
      time: 0.038313600420951846
    - config:
        BLOCK_SIZE_B: 512
      time: 0.038678398728370665
    - config:
        BLOCK_SIZE_B: 16
      time: 0.041152000427246094
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03365119993686676
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033657601475715636
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033904001116752625
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03413119912147522
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03447999954223633
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03491199910640717
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.046463999152183535
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03727999925613403
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03746559917926788
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03749760091304779
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03808639943599701
    - config:
        BLOCK_SIZE_B: 64
      time: 0.038236799836158755
    - config:
        BLOCK_SIZE_B: 128
      time: 0.038515201210975646
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03860479891300202
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.048665601015090945
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05003839731216431
    - config:
        BLOCK_SIZE_B: 4
      time: 0.30423679351806643
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05348160266876221
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05935360193252563
    - config:
        BLOCK_SIZE_B: 4
      time: 0.44533438682556153
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03419840037822723
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03455359935760498
    - config:
        BLOCK_SIZE_B: 512
      time: 0.034806400537490845
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.035046398639678955
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03616639971733093
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.047440001368522645
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09946240186691284
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03736959993839264
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03739840090274811
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03752320110797882
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.037913599610328676
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.038073599338531494
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04850879907608032
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.10077760219573975
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03340800106525421
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03372479975223541
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03436160087585449
    - config:
        BLOCK_SIZE_B: 8
      time: 0.034867200255393985
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03492160141468048
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04395839869976044
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0367935985326767
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03690559864044189
    - config:
        BLOCK_SIZE_B: 2
      time: 0.037231999635696414
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03790079951286316
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03808639943599701
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03817920088768005
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033190399408340454
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033590400218963624
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03373759984970093
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03383040130138397
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03384000062942505
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03403519988059998
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034944000840187076
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03684160113334656
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03709760010242462
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03717760145664215
    - config:
        BLOCK_SIZE_B: 16
      time: 0.038185599446296695
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03865599930286408
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03953920006752014
    - config:
        BLOCK_SIZE_B: 256
      time: 0.039680001139640805
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033379200100898745
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03404799997806549
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03405120074748993
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.034457600116729735
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03471679985523224
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034755200147628784
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04442879855632782
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.036847999691963194
    - config:
        BLOCK_SIZE_B: 512
      time: 0.037257599830627444
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037747201323509214
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03792960047721863
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03812159895896912
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03871999979019165
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03912639915943146
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09548159837722778
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7239295959472656
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.13482880592346191
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7786399841308593
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033471998572349546
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033827200531959534
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03423359990119934
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0344895988702774
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03516480028629303
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05354560017585754
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14607679843902588
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.037567999958992
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03760319948196411
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03778240084648132
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0377920001745224
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.039059200882911684
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05502399802207947
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14994560480117797
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03400320112705231
    - config:
        BLOCK_SIZE_B: 8
      time: 0.034780800342559814
    - config:
        BLOCK_SIZE_B: 2
      time: 0.034832000732421875
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0349151998758316
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04492799937725067
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03713279962539673
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03722560107707977
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03830719888210297
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03927040100097656
    - config:
        BLOCK_SIZE_B: 16
      time: 0.047539201378822324
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0335999995470047
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03377279937267304
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03412800133228302
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03437120020389557
    - config:
        BLOCK_SIZE_B: 2
      time: 0.034406399726867674
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03463039994239807
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0347104012966156
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0360287994146347
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03705280125141144
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0372512012720108
    - config:
        BLOCK_SIZE_B: 8
      time: 0.037462401390075686
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03767040073871612
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03785600066184998
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0389631986618042
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03289600014686585
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03362880051136017
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03384000062942505
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0343968003988266
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03500480055809021
    - config:
        BLOCK_SIZE_B: 16
      time: 0.035392001271247864
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03547520041465759
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03698239922523498
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037334400415420535
    - config:
        BLOCK_SIZE_B: 128
      time: 0.037673598527908324
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03790720105171204
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03792319893836975
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03826560080051422
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03915840089321136
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.5834496021270752
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.211846351623535
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03322240114212036
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03375039994716644
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0339711993932724
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.034534400701522826
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03468480110168457
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06482880115509033
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.1769503951072693
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.036976000666618346
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03699199855327606
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03727999925613403
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037939199805259706
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03844479918479919
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06550400257110596
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17739520072937012
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03529280126094818
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03547520041465759
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03645119965076447
    - config:
        BLOCK_SIZE_B: 8
      time: 0.14319360256195068
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0387935996055603
    - config:
        BLOCK_SIZE_B: 2
      time: 0.039094400405883786
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04037120044231415
    - config:
        BLOCK_SIZE_B: 8
      time: 0.13761279582977295
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.033641600608825685
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03452480137348175
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03476159870624542
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03492479920387268
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03497920036315918
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.03835520148277283
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.06345279812812805
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03657920062541962
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.037487998604774475
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.038700801134109494
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03892160058021545
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03978559970855713
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04416959881782532
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.09296640157699584
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033199998736381534
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03320319950580597
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03367359936237335
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033881598711013795
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033913600444793704
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03516480028629303
    - config:
        BLOCK_SIZE_B: 64
      time: 0.048054400086402896
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036899200081825255
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03699840009212494
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03733119964599609
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03764480054378509
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03843519985675812
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03856000006198883
    - config:
        BLOCK_SIZE_B: 64
      time: 0.039155200123786926
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03377279937267304
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033939200639724734
    - config:
        BLOCK_SIZE_B: 8
      time: 0.034185600280761716
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03441280126571655
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034544000029563905
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0351967990398407
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043007999658584595
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03738240003585815
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03745599985122681
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0375328004360199
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03810240030288696
    - config:
        BLOCK_SIZE_B: 64
      time: 0.038108798861503604
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0383296012878418
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04384320080280304
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033523198962211606
    - config:
        BLOCK_SIZE_B: 512
      time: 0.034755200147628784
    - config:
        BLOCK_SIZE_B: 64
      time: 0.035104000568389894
    - config:
        BLOCK_SIZE_B: 256
      time: 0.035158398747444156
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03519040048122406
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0356799989938736
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03831680119037628
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.037478399276733396
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037599998712539676
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037811198830604555
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03792960047721863
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03839040100574494
    - config:
        BLOCK_SIZE_B: 256
      time: 0.039468801021575926
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04272319972515106
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04871360063552856
    - config:
        BLOCK_SIZE_B: 2
      time: 0.050425601005554196
    - config:
        BLOCK_SIZE_B: 4
      time: 0.25051519870758054
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05419520139694214
    - config:
        BLOCK_SIZE_B: 2
      time: 0.056822401285171506
    - config:
        BLOCK_SIZE_B: 4
      time: 0.3263711929321289
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0336544007062912
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03386240005493164
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03463680148124695
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0347680002450943
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.035206401348114015
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04772160053253174
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.0995743989944458
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03690559864044189
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03701440095901489
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03715519905090332
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03825919926166534
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03901439905166626
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04865919947624207
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.10100159645080567
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03312000036239624
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0335999995470047
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03384959995746613
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03436160087585449
    - config:
        BLOCK_SIZE_B: 1
      time: 0.034569600224494935
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03607040047645569
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03652159869670868
    - config:
        BLOCK_SIZE_B: 16
      time: 0.037478399276733396
    - config:
        BLOCK_SIZE_B: 8
      time: 0.037615999579429626
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03816959857940674
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03828479945659637
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03940480053424835
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033958399295806886
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03402239978313446
    - config:
        BLOCK_SIZE_B: 128
      time: 0.034457600116729735
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03483839929103851
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03488959968090057
    - config:
        BLOCK_SIZE_B: 4
      time: 0.035046398639678955
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03584960103034973
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036643201112747194
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03696959912776947
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03749440014362335
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0378464013338089
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037894400954246524
    - config:
        BLOCK_SIZE_B: 8
      time: 0.038627201318740846
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03873279988765717
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03324800133705139
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033766400814056394
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0341376006603241
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03454079926013946
    - config:
        BLOCK_SIZE_B: 512
      time: 0.034944000840187076
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03523840010166168
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.041305598616600034
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03718400001525879
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.037254399061203
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037452799081802365
    - config:
        BLOCK_SIZE_B: 128
      time: 0.037801599502563475
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03817920088768005
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03831999897956848
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0385888010263443
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09527680277824402
    - config:
        BLOCK_SIZE_B: 2
      time: 0.4302783966064453
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.1311743974685669
    - config:
        BLOCK_SIZE_B: 2
      time: 0.6920896053314209
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03275200128555298
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.032841598987579344
    - config:
        BLOCK_SIZE_B: 512
      time: 0.034560000896453856
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03463360071182251
    - config:
        BLOCK_SIZE_B: 256
      time: 0.036268800497055054
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.053465598821640016
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14615679979324342
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03681280016899109
    - config:
        BLOCK_SIZE_B: 256
      time: 0.036950400471687316
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03776639997959137
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03800320029258728
    - config:
        BLOCK_SIZE_B: 512
      time: 0.038515201210975646
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05485759973526001
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.15009280443191528
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03394240140914917
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033958399295806886
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03453119993209839
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03455039858818054
    - config:
        BLOCK_SIZE_B: 16
      time: 0.052198398113250735
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0365119993686676
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03718079924583435
    - config:
        BLOCK_SIZE_B: 8
      time: 0.037536001205444335
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03909119963645935
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04628799855709076
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0329120010137558
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03304319977760315
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033452799916267394
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03430080115795135
    - config:
        BLOCK_SIZE_B: 2
      time: 0.034694400429725644
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03523840010166168
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03576639890670776
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.037136000394821164
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03728959858417511
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037561601400375365
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03759360015392303
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03771199882030487
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0384768009185791
    - config:
        BLOCK_SIZE_B: 4
      time: 0.038889598846435544
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033292800188064575
    - config:
        BLOCK_SIZE_B: 128
      time: 0.033542400598526
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03394240140914917
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034255999326705935
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03432320058345795
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03595199882984161
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04019840061664581
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037945601344108584
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03804160058498383
    - config:
        BLOCK_SIZE_B: 128
      time: 0.038335999846458434
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03897280097007751
    - config:
        BLOCK_SIZE_B: 32
      time: 0.039129599928855896
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03951680064201355
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04043520092964172
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.5848671913146972
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.3153023719787598
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033843201398849485
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.034118399024009705
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03437759876251221
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03450239896774292
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03471679985523224
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06500480175018311
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17675199508666992
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03695679903030395
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.037222400307655334
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03726719915866852
    - config:
        BLOCK_SIZE_B: 512
      time: 0.037555199861526486
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03806079924106598
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06550719738006591
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17721279859542846
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.034748798608779906
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03535040020942688
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03549120128154755
    - config:
        BLOCK_SIZE_B: 8
      time: 0.10960320234298707
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.039052799344062805
    - config:
        BLOCK_SIZE_B: 2
      time: 0.039315199851989745
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03975360095500946
    - config:
        BLOCK_SIZE_B: 8
      time: 0.09842240214347839
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.035011199116706845
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03505280017852783
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.0360287994146347
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.037027201056480406
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04037440121173859
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04132800102233887
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.08727999925613403
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03701440095901489
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03863039910793305
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.039263999462127684
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03930880129337311
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.0401311993598938
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04152320027351379
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.06240000128746033
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03362880051136017
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033955198526382444
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0341728001832962
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03466559946537018
    - config:
        BLOCK_SIZE_B: 4
      time: 0.034694400429725644
    - config:
        BLOCK_SIZE_B: 1
      time: 0.034825599193573
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07491840124130249
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03709760010242462
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03842880129814148
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03849599957466125
    - config:
        BLOCK_SIZE_B: 16
      time: 0.038991999626159665
    - config:
        BLOCK_SIZE_B: 4
      time: 0.039001598954200745
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03979839980602264
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0861952006816864
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033609598875045776
    - config:
        BLOCK_SIZE_B: 8
      time: 0.034508800506591795
    - config:
        BLOCK_SIZE_B: 64
      time: 0.034569600224494935
    - config:
        BLOCK_SIZE_B: 128
      time: 0.035174399614334106
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03612160086631775
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03697279989719391
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06344959735870362
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03739840090274811
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03786559998989105
    - config:
        BLOCK_SIZE_B: 32
      time: 0.038150399923324585
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03824320137500763
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03835200071334839
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03951039910316467
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07057600021362305
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033180800080299375
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03467519879341126
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03480319976806641
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03551360070705414
    - config:
        BLOCK_SIZE_B: 64
      time: 0.035894399881362914
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03687680065631867
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.05464640259742737
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03690559864044189
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03691520094871521
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0372191995382309
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03733119964599609
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03840959966182709
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03869760036468506
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.05235520005226135
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09356480240821838
    - config:
        BLOCK_SIZE_B: 2
      time: 0.09976320266723633
    - config:
        BLOCK_SIZE_B: 4
      time: 0.37739200592041017
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0997439980506897
    - config:
        BLOCK_SIZE_B: 4
      time: 0.44307842254638674
    - config:
        BLOCK_SIZE_B: 2
      time: 0.5250592231750488
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03419840037822723
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03444480001926422
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03472320139408112
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.034867200255393985
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.036908799409866334
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04917759895324707
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09321920275688171
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03789120018482208
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.038652798533439635
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.039059200882911684
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.039129599928855896
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03914240002632141
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.05042240023612976
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09587519764900207
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033817601203918454
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03405120074748993
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03443840146064758
    - config:
        BLOCK_SIZE_B: 1
      time: 0.035231998562812804
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03549120128154755
    - config:
        BLOCK_SIZE_B: 32
      time: 0.10195200443267823
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03783040046691895
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03814719915390015
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03832319974899292
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03851200044155121
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03872320055961609
    - config:
        BLOCK_SIZE_B: 32
      time: 0.12640639543533325
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03361920118331909
    - config:
        BLOCK_SIZE_B: 16
      time: 0.034031999111175534
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03428800106048584
    - config:
        BLOCK_SIZE_B: 8
      time: 0.034441599249839784
    - config:
        BLOCK_SIZE_B: 4
      time: 0.035417601466178894
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03681600093841553
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07251840233802795
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037299200892448425
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037536001205444335
    - config:
        BLOCK_SIZE_B: 8
      time: 0.038515201210975646
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03852159976959228
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03988800048828125
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03991360068321228
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07618240118026734
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0336896002292633
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03383359909057617
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03529919981956482
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0357151985168457
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03575679957866669
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03706879913806915
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.054713600873947145
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03722879886627197
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03748160004615784
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0376800000667572
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03887999951839447
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03967039883136749
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04026559889316559
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06354879736900329
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.19365439414978028
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7756192207336425
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 1.0774239540100097
    - config:
        BLOCK_SIZE_B: 1
      time: 1.0780159950256347
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03379839956760407
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03442240059375763
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03451200127601624
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03498879969120026
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03513599932193756
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05341119766235351
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.10808000564575196
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037747201323509214
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03787519931793213
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03840320110321045
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03854399919509888
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04000000059604645
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.053686398267745974
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.10730559825897217
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036006399989128114
    - config:
        BLOCK_SIZE_B: 1
      time: 0.036048001050949095
    - config:
        BLOCK_SIZE_B: 2
      time: 0.036582401394844054
    - config:
        BLOCK_SIZE_B: 8
      time: 0.037775999307632445
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09908159971237182
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03874880075454712
    - config:
        BLOCK_SIZE_B: 2
      time: 0.038806399703025816
    - config:
        BLOCK_SIZE_B: 8
      time: 0.039743998646736146
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0397599995136261
    - config:
        BLOCK_SIZE_B: 16
      time: 0.15565119981765746
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03363839983940124
    - config:
        BLOCK_SIZE_B: 32
      time: 0.034118399024009705
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03440319895744324
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03448640108108521
    - config:
        BLOCK_SIZE_B: 4
      time: 0.034841600060462954
    - config:
        BLOCK_SIZE_B: 2
      time: 0.035017600655555724
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07358400225639343
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037376001477241516
    - config:
        BLOCK_SIZE_B: 8
      time: 0.038192000985145566
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03850559890270233
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03856959939002991
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03861120045185089
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04112319946289063
    - config:
        BLOCK_SIZE_B: 128
      time: 0.058083200454711915
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03331199884414673
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03424319922924042
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03443520069122315
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03494080007076263
    - config:
        BLOCK_SIZE_B: 16
      time: 0.035955199599266054
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03898879885673523
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0637503981590271
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.036620798707008365
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03673279881477356
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03686079978942871
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03728640079498291
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03739520013332367
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0376800000667572
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06183040142059326
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.6018335342407226
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.0244928359985352
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03376320004463196
    - config:
        BLOCK_SIZE_B: 512
      time: 0.035020801424980166
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.035094401240348815
    - config:
        BLOCK_SIZE_B: 128
      time: 0.035183998942375186
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03544960021972656
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06388480067253113
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17682559490203859
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.036425599455833436
    - config:
        BLOCK_SIZE_B: 512
      time: 0.036524799466133115
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03675200045108795
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03864319920539856
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03880000114440918
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06533759832382202
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.1682144045829773
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.048368000984191896
    - config:
        BLOCK_SIZE_B: 2
      time: 0.048547199368476866
    - config:
        BLOCK_SIZE_B: 4
      time: 0.05190399885177612
    - config:
        BLOCK_SIZE_B: 8
      time: 0.18133120536804198
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04952960014343262
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05084159970283508
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06701120138168334
    - config:
        BLOCK_SIZE_B: 8
      time: 0.24539520740509033
  kernels/swiglu/backward.py->_backward:
    '''gate.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.28034560680389403
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.2815135955810547
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.2819391965866089
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.2820703983306885
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.28229761123657227
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.28230719566345214
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.28239998817443845
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.28255040645599366
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.2825952053070068
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.2827167987823486
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.282806396484375
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.28330240249633787
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.2897536039352417
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.28990399837493896
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.29589760303497314
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.30731520652770994
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.3075263977050781
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.36580801010131836
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.49738240242004395
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.5961599826812745
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9898655891418457
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 3.881999969482422
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 4.079804611206055
    '''gate.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.2787359952926636
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.2793247938156128
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.27949440479278564
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.2796992063522339
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.27978880405426027
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.27984640598297117
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.2800800085067749
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.28034238815307616
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.28051199913024905
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.28055360317230227
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.28073279857635497
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.28075199127197265
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.28738880157470703
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.28761279582977295
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2946367979049683
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.3064095973968506
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.30656321048736573
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.3159327983856201
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.4976223945617676
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.5331488132476807
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9897120475769043
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 3.5832801818847657
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 3.642268753051758
    '''gate.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.5529600143432617
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.5541632175445557
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.5542208194732666
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.5548448085784912
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.5549183845520019
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.5559743881225586
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.5561728000640869
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.558899211883545
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.5606048107147217
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.581008005142212
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.5815680027008057
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.5980031967163086
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.9185952186584473
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9912832260131836
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 1.2147135734558105
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 4.752572631835937
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 4.866841506958008
  kernels/swiglu/forward.py->_forward:
    '''gate.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14126399755477906
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.14133440256118773
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.14251840114593506
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.14309439659118653
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.14718400239944457
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.14977279901504517
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.2024384021759033
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.20252161026000975
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.20257279872894288
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.20263679027557374
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.202726411819458
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.2029184103012085
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.20469119548797607
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.20478720664978028
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 0.21323199272155763
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.2246623992919922
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.22550079822540284
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2503391981124878
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2529695987701416
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.25303359031677247
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.49630398750305177
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9896160125732422
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 1.1497568130493163
    '''gate.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14078400135040284
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.14167360067367554
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.14262720346450805
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.1465407967567444
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.14691840410232543
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.15683200359344482
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.19918400049209595
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.1992192029953003
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.1992799997329712
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.19935359954833984
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.1994879961013794
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.19971200227737426
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.201580810546875
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.20186879634857177
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 0.20824000835418702
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.22218561172485352
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.22260479927062987
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2505343914031982
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2531327962875366
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2532416105270386
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.49661760330200194
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9898112297058106
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 1.1516863822937011
    '''gate.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.2779167890548706
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.27859199047088623
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.27876160144805906
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.2787775993347168
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.2816672086715698
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.2821408033370972
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.2841984033584595
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.28710079193115234
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.29342079162597656
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.30304000377655027
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.31179521083831785
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.34960958957672117
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.4966752052307129
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.4967679977416992
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9874752044677735
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 1.9832319259643554
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 2.0554943084716797
  kernels/swiglu_unchunked/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.561075210571289
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.0189535140991213
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 3.2409694671630858
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.517330932617188
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.648626708984374
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5323007583618165
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.7296928405761718
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.752761650085449
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.87407989501953
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.160185241699217
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.6104768753051757
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 3.2013534545898437
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 5.669740676879883
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.077183532714844
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.318392944335937
  kernels/swiglu_unchunked/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.955782413482666
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9560895919799804
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.049516773223877
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.3192735671997071
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 6.211980819702148
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9418335914611816
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9480511665344238
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.0424799919128418
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.2554783821105957
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 6.156911849975586
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5741567611694336
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.6337087631225586
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.8542976379394531
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 8.69925765991211
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 8.706393432617187
best_configs:
  kernels/add/add_scalar/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.141046404838562
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14085760116577148
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778496026992798
  kernels/add/add_tensor/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1410815954208374
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1406880021095276
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778559923171997
  kernels/embedding/backward.py->_backward:
    '''weight.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.250962829589843
    '''weight.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 3.520441436767578
    '''weight.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 9.787811279296875
  kernels/embedding/forward.py->_forward:
    '''weight.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6663392066955567
    '''weight.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6661375999450684
    '''weight.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.3731871604919434
  kernels/rmsnorm/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float32''':
      config:
        kernel_backend: triton
      time: 0
  kernels/rmsnorm/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float32''':
      config:
        kernel_backend: triton
      time: 0
  kernels/rmsnorm/triton_implementation/kernels_backward.py->rmsnorm_backward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.042710399627685545
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.06815999746322632
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.042844799160957334
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.06816639900207519
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.041833600401878356
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.06850240230560303
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.043635201454162595
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.06833919882774353
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07871360182762147
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 1.5544575691223144
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.04285120069980621
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.06821439862251281
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04368320107460022
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.06914560198783874
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.0430400013923645
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06629440188407898
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.04236479997634888
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06740480065345764
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.112377643585205
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 3.699203109741211
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04430719912052154
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.06665599942207337
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.044537600874900815
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07079359889030457
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.043382400274276735
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.06705600023269653
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04180479943752289
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06654400229454041
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.244460868835449
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 10.36596450805664
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.0435808002948761
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.06755520105361938
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.046387198567390445
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09535679817199708
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.04259839951992035
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.06732159852981567
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.04223040044307709
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.06660159826278686
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.042473599314689636
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06807360053062439
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04307200014591217
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.06768959760665894
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.0782368004322052
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.0602815628051758
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04257920086383819
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.0673919975757599
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.043673598766326906
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.06835520267486572
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.0423007994890213
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06645119786262513
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.04287680089473724
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06717119812965393
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.8872703552246094
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 3.101523208618164
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04323840141296387
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.06716480255126953
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.0438400000333786
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06951680183410644
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.043673598766326906
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06716480255126953
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04266240000724793
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06738240122795106
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.8261215209960937
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 8.192931365966796
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04387840032577515
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.06716480255126953
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04814079999923706
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09411200284957885
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.04351679980754852
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.059910398721694944
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04336319863796234
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.061401599645614625
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.04439359903335571
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.06068159937858582
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04383040070533752
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.06058239936828613
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.1458624005317688
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.7027008056640625
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.042796799540519716
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.05974400043487549
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.044819200038909913
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.06156799793243408
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.043075200915336606
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.05904319882392883
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04363200068473816
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.05947520136833191
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.756972885131836
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 4.382896041870117
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.043059200048446655
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.060835200548172
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04592320024967193
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06822720170021057
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.04364160001277924
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.061286401748657224
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04227519929409027
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.05950719714164734
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 7.536089324951172
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 10.488249969482421
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.043171200156211856
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.05902400016784668
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07261760234832763
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.11234879493713379
  kernels/rmsnorm/triton_implementation/kernels_forward.py->rmsnorm_forward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.034230399131774905
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.036985599994659425
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03308480083942413
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03701440095901489
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03278079926967621
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.036671999096870425
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03365119993686676
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03727999925613403
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.048665601015090945
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.05348160266876221
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03419840037822723
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03736959993839264
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03340800106525421
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.0367935985326767
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.033190399408340454
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03684160113334656
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.033379200100898745
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.036847999691963194
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09548159837722778
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.13482880592346191
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.033471998572349546
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.037567999958992
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03400320112705231
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03713279962539673
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.0335999995470047
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.0360287994146347
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03289600014686585
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03698239922523498
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.5834496021270752
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.211846351623535
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03322240114212036
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.036976000666618346
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03529280126094818
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.0387935996055603
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16384
      time: 0.033641600608825685
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03657920062541962
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.033199998736381534
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.036899200081825255
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03377279937267304
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03738240003585815
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.033523198962211606
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.037478399276733396
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04871360063552856
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.05419520139694214
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.0336544007062912
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03690559864044189
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03312000036239624
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03652159869670868
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.033958399295806886
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.036643201112747194
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03324800133705139
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03718400001525879
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09527680277824402
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.1311743974685669
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03275200128555298
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03681280016899109
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03394240140914917
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.0365119993686676
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.0329120010137558
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.037136000394821164
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.033292800188064575
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.037945601344108584
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.5848671913146972
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.3153023719787598
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.033843201398849485
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03695679903030395
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.034748798608779906
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.039052799344062805
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.035011199116706845
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03701440095901489
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03362880051136017
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03709760010242462
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.033609598875045776
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03739840090274811
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.033180800080299375
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03690559864044189
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09356480240821838
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.0997439980506897
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03419840037822723
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03789120018482208
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.033817601203918454
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03783040046691895
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03361920118331909
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.037299200892448425
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.0336896002292633
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03722879886627197
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.19365439414978028
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 1.0774239540100097
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03379839956760407
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.037747201323509214
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.036006399989128114
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03874880075454712
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03363839983940124
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.037376001477241516
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03331199884414673
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.036620798707008365
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.6018335342407226
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.0244928359985352
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03376320004463196
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.036425599455833436
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.048368000984191896
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04952960014343262
  kernels/swiglu/backward.py->_backward:
    '''gate.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.28034560680389403
    '''gate.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.2787359952926636
    '''gate.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.5529600143432617
  kernels/swiglu/forward.py->_forward:
    '''gate.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14126399755477906
    '''gate.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14078400135040284
    '''gate.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.2779167890548706
  kernels/swiglu_unchunked/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.561075210571289
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5323007583618165
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.6104768753051757
  kernels/swiglu_unchunked/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.955782413482666
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9418335914611816
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5741567611694336
