all_configs:
  kernels/add/add_scalar/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.141046404838562
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14107199907302856
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14136960506439208
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14136960506439208
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1414687991142273
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14166719913482667
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14173120260238647
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14215680360794067
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14219199419021605
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.142467200756073
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14309760332107543
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14430400133132934
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14572800397872926
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14820480346679688
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1492735981941223
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15289920568466187
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1590783953666687
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18398720026016235
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20236799716949463
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.22986240386962892
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2498784065246582
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.24998719692230226
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2500511884689331
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2507807970046997
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30271360874176023
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3328991889953613
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38096320629119873
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49628801345825196
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49657602310180665
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4966271877288818
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4966911792755127
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.989475154876709
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9900896072387695
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9901568412780761
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9778144836425782
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14085760116577148
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14092799425125122
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14093760251998902
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14131840467453002
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14132159948349
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14137279987335205
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1414528012275696
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14256319999694825
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14263360500335692
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14305280447006224
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14326399564743042
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1439296007156372
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14558080434799195
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.147433602809906
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14790719747543335
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1524448037147522
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15899200439453126
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18383680582046508
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.202239990234375
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.22976319789886473
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.25008320808410645
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2501471996307373
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.25040640830993655
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.25067839622497556
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3034336090087891
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3335360050201416
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3818655967712402
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49639358520507815
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49652800559997556
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49664959907531736
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49705281257629397
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9898431777954102
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9905887603759765
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9906559944152832
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9780960083007812
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778496026992798
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27822399139404297
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2783456087112427
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27873280048370364
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2787391901016235
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2789184093475342
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2789376020431519
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2808511972427368
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28120639324188235
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28222079277038575
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2823807954788208
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2846719980239868
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.28688640594482423
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2915168046951294
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.29586238861083985
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.30122880935668944
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.31302719116210936
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3571039915084839
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.39004480838775635
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.43677120208740233
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4958240032196045
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4958943843841553
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49653120040893556
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4970079898834229
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9716383934020996
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9874943733215332
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9877311706542968
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9878560066223144
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9719520568847657
  kernels/add/add_tensor/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1410815954208374
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14110080003738404
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1411903977394104
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14120639562606813
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1412768006324768
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1413856029510498
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14188159704208375
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14203200340270997
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14203200340270997
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1422144055366516
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14232319593429565
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1446879982948303
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14607679843902588
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14806400537490844
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15291520357131957
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15920000076293944
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18367680311203002
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20214719772338868
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.22973759174346925
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.24996159076690674
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.25017600059509276
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.25030078887939455
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2504767894744873
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30503358840942385
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3367775917053223
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38626561164855955
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49568638801574705
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4957695960998535
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4957727909088135
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49652800559997556
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9639072418212891
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9878399848937989
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9880064010620118
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9891839981079101
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9722303390502929
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1406880021095276
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14077759981155397
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1409119963645935
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14100799560546876
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14116159677505494
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14135680198669434
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14168640375137329
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14168959856033325
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1419263958930969
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14235199689865113
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14287680387496948
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14408639669418336
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14573440551757813
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14815679788589478
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15280959606170655
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1589568018913269
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.1837183952331543
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2023871898651123
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.23004159927368165
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.24979519844055176
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.24997119903564452
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.24998080730438232
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2502912044525146
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30608320236206055
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.33755519390106203
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38690240383148194
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4954527854919434
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4957632064819336
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4957791805267334
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49585280418395994
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.987609577178955
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9879199981689453
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9879263877868653
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 1.0364671707153321
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.972719955444336
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778559923171997
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2779871940612793
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2782111883163452
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2782399892807007
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2784672021865845
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2791327953338623
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27952640056610106
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2796319961547852
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2806240081787109
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2807744026184082
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2813503980636597
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2849056005477905
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.287443208694458
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2922271966934204
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3015360116958618
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3134495973587036
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.358620810508728
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.39258880615234376
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.43900160789489745
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4960991859436035
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4962207794189453
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49686079025268554
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4969791889190674
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.98787841796875
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9883071899414062
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9886912345886231
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9719871520996093
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.007379150390625
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.094166374206543
  kernels/embedding/backward.py->_backward:
    '''weight.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.250962829589843
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 10.270985412597657
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.310384368896484
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 11.17128677368164
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 11.251715087890625
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 11.489961242675781
    '''weight.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 3.520441436767578
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.234486389160156
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.248371124267578
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.594137573242188
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.611248016357422
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 5.786969757080078
    '''weight.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 9.787811279296875
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 9.808060455322266
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.033232116699219
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.207049560546874
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.478928375244141
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.840665435791015
  kernels/embedding/forward.py->_forward:
    '''weight.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6663392066955567
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6666592121124267
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7012800216674805
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7245791912078857
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.7806144237518311
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 0.8636768341064454
    '''weight.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6661375999450684
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6671520233154297
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.700438404083252
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7267327785491944
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.7810783863067627
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 0.8651391983032226
    '''weight.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.3731871604919434
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.4229951858520509
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 1.7100704193115235
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 4.774563217163086
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.028534317016602
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.281945419311524
  kernels/rmsnorm/triton_implementation/kernels_backward.py->rmsnorm_backward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04222719967365265
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04246079921722412
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0426144003868103
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04333760142326355
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04348799884319306
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09165440201759338
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.2307904005050659
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06968320012092591
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06968320012092591
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07018240094184876
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07085440158843995
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.07165759801864624
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.0957472026348114
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.22887680530548096
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.041808000206947325
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04226559996604919
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04285120069980621
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04338879883289337
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043484801054000856
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07710080146789551
    - config:
        BLOCK_SIZE_B: 64
      time: 0.17669440507888795
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06932479739189149
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06992319822311402
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07047359943389893
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07067520022392274
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0710528016090393
    - config:
        BLOCK_SIZE_B: 32
      time: 0.1383136034011841
    - config:
        BLOCK_SIZE_B: 64
      time: 0.4169439792633057
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04176000058650971
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04239999949932098
    - config:
        BLOCK_SIZE_B: 32
      time: 0.042691200971603394
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04278079867362976
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04343039989471435
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04377599954605103
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04948480129241943
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06958400011062622
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06958720088005066
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06978560090065003
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07083839774131775
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07175359725952149
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07357439994812012
    - config:
        BLOCK_SIZE_B: 512
      time: 0.20185279846191406
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.041417598724365234
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04167360067367554
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04181120097637177
    - config:
        BLOCK_SIZE_B: 128
      time: 0.042342400550842284
    - config:
        BLOCK_SIZE_B: 256
      time: 0.043244799971580504
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0433023989200592
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04429439902305603
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07006400227546691
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07012479901313781
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07021120190620422
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07079039812088013
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07149119973182679
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07395520210266113
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.16197760105133058
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.078847998380661
    - config:
        BLOCK_SIZE_B: 2
      time: 0.5449471950531006
    - config:
        BLOCK_SIZE_B: 4
      time: 0.705014419555664
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 1.48372802734375
    - config:
        BLOCK_SIZE_B: 1
      time: 1.5496159553527833
    - config:
        BLOCK_SIZE_B: 4
      time: 2.768921661376953
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04129279851913452
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04166080057621002
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04166719913482666
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04235199987888336
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04326080083847046
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06234239935874939
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.19323840141296386
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06810560226440429
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06845120191574097
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06857600212097167
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06957119703292847
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06999359726905822
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.09591040015220642
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.17666239738464357
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04147520065307617
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04210239946842194
    - config:
        BLOCK_SIZE_B: 4
      time: 0.042473599314689636
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04249280095100403
    - config:
        BLOCK_SIZE_B: 16
      time: 0.10853760242462158
    - config:
        BLOCK_SIZE_B: 32
      time: 0.2643712043762207
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06977279782295227
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07019519805908203
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0709119975566864
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07145919799804687
    - config:
        BLOCK_SIZE_B: 16
      time: 0.21001920700073243
    - config:
        BLOCK_SIZE_B: 32
      time: 0.5226912021636962
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.042710399627685545
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04272960126399994
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04278079867362976
    - config:
        BLOCK_SIZE_B: 16
      time: 0.042847999930381776
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043033599853515625
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04342080056667328
    - config:
        BLOCK_SIZE_B: 256
      time: 0.049184000492095946
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06893119812011719
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06954560279846192
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07059839963912964
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07103679776191711
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07150400280952454
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07233920097351074
    - config:
        BLOCK_SIZE_B: 256
      time: 0.20006721019744872
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04251520037651062
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04269759953022003
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04325760006904602
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04347200095653534
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04441600143909454
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.044860801100730895
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.049641600251197814
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07067199945449829
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07080640196800232
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07117440104484558
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07120320200920105
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07128639817237854
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0732703983783722
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.16875840425491334
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.1058015823364258
    - config:
        BLOCK_SIZE_B: 2
      time: 1.794976043701172
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 3.603667068481445
    - config:
        BLOCK_SIZE_B: 1
      time: 4.349663925170899
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04133439958095551
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04167360067367554
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042412799596786496
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04245119988918304
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04290240108966827
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06500160098075866
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.21237120628356934
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06880639791488648
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06955199837684631
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07058240175247192
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.070796799659729
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07138879895210266
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.10250879526138305
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.1812127947807312
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.042582398653030394
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04278079867362976
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04324159920215607
    - config:
        BLOCK_SIZE_B: 8
      time: 0.17889280319213868
    - config:
        BLOCK_SIZE_B: 16
      time: 0.26574718952178955
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07095680236816407
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07280960083007812
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07334719896316529
    - config:
        BLOCK_SIZE_B: 8
      time: 0.45685439109802245
    - config:
        BLOCK_SIZE_B: 16
      time: 0.8207872390747071
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04182719886302948
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04211840033531189
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04309119880199432
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04344319999217987
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04403199851512909
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04965119957923889
    - config:
        BLOCK_SIZE_B: 128
      time: 0.13563840389251708
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06887680292129517
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0694432020187378
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07028160095214844
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07046080231666565
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07227519750595093
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10901119709014892
    - config:
        BLOCK_SIZE_B: 128
      time: 0.34236481189727785
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04103679955005646
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04126079976558685
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04138559997081757
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04186240136623383
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04189760088920593
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042656001448631284
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.047516798973083495
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07031679749488831
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07033920288085938
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0708191990852356
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07155519723892212
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0717024028301239
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0741216003894806
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.1696992039680481
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.2166559219360353
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 10.403075408935546
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.042412799596786496
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04290240108966827
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04297600090503693
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04412800073623657
    - config:
        BLOCK_SIZE_B: 256
      time: 0.044486400485038755
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07647039890289306
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.21905601024627686
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06907839775085449
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07007359862327575
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07013440132141113
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07044159770011901
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07232319712638854
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.14072959423065184
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.3125663995742798
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04464640021324158
    - config:
        BLOCK_SIZE_B: 1
      time: 0.050444799661636355
    - config:
        BLOCK_SIZE_B: 4
      time: 0.1295359969139099
    - config:
        BLOCK_SIZE_B: 8
      time: 0.6144447803497315
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07262719869613647
    - config:
        BLOCK_SIZE_B: 2
      time: 0.08427199721336365
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6493599891662598
    - config:
        BLOCK_SIZE_B: 8
      time: 1.5714495658874512
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.041065600514411923
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.041791999340057374
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.042294400930404666
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.042499199509620667
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0425024002790451
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09142079949378967
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.24549760818481445
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06951040029525757
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07061759829521179
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.07144320011138916
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0717408001422882
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.07272639870643616
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.0759168028831482
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.16680320501327514
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.041116800904273984
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04178560078144074
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04186240136623383
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04195199906826019
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04331839978694916
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06952639818191528
    - config:
        BLOCK_SIZE_B: 64
      time: 0.1343008041381836
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06926400065422059
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06929280161857605
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06954240202903747
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07060800194740295
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0718176007270813
    - config:
        BLOCK_SIZE_B: 32
      time: 0.11471999883651733
    - config:
        BLOCK_SIZE_B: 64
      time: 0.3297600030899048
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04102079868316651
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04104000031948089
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04153279960155487
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04156799912452698
    - config:
        BLOCK_SIZE_B: 32
      time: 0.042054399847984314
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04258559942245484
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04471679925918579
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06922879815101624
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06948800086975097
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06980800032615661
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07023360133171082
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07081279754638672
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07248960137367248
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0837343990802765
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04213759899139404
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04239040017127991
    - config:
        BLOCK_SIZE_B: 512
      time: 0.042630401253700254
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0429280012845993
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04323199987411499
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04345279932022095
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04581120014190674
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07090240120887756
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07098559737205505
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07114880084991455
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07232000231742859
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0724511981010437
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0726527988910675
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07402560114860535
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07907519936561584
    - config:
        BLOCK_SIZE_B: 2
      time: 0.44577598571777344
    - config:
        BLOCK_SIZE_B: 4
      time: 0.5634687900543213
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.1145888328552247
    - config:
        BLOCK_SIZE_B: 2
      time: 1.1419103622436524
    - config:
        BLOCK_SIZE_B: 4
      time: 1.9675296783447265
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04303039908409119
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04339199960231781
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0434688001871109
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04356479942798615
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04357759952545166
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06229119896888733
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.1632256031036377
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.071670401096344
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07197440266609192
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07263360023498536
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07277119755744935
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.07307839989662171
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.11871999502182007
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.2659104108810425
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.041407999396324155
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04214400053024292
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04268159866333008
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04315199851989746
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09547839760780334
    - config:
        BLOCK_SIZE_B: 32
      time: 0.17912640571594238
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06929600238800049
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06931520104408265
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07032639980316162
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07106559872627258
    - config:
        BLOCK_SIZE_B: 16
      time: 0.159660804271698
    - config:
        BLOCK_SIZE_B: 32
      time: 0.36112959384918214
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.041126400232315063
    - config:
        BLOCK_SIZE_B: 16
      time: 0.041875201463699344
    - config:
        BLOCK_SIZE_B: 64
      time: 0.041894400119781496
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04206080138683319
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0425247997045517
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04377920031547546
    - config:
        BLOCK_SIZE_B: 256
      time: 0.045638400316238406
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06865599751472473
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06936320066452026
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06966720223426819
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07015039920806884
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07079359889030457
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07261760234832763
    - config:
        BLOCK_SIZE_B: 256
      time: 0.1053056001663208
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04200960099697113
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04247680008411407
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04247680008411407
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04254400134086609
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04262720048427582
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04320000112056732
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.045337599515914914
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06967039704322815
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07014080286026
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07031360268592834
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07039999961853027
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07055360078811646
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07165759801864624
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07704319953918456
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.8838335990905761
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2052607536315918
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 2.9421823501586912
    - config:
        BLOCK_SIZE_B: 1
      time: 3.107107162475586
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04227199852466583
    - config:
        BLOCK_SIZE_B: 512
      time: 0.042371198534965515
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04270719885826111
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04323840141296387
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.044582399725914004
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06467199921607972
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.17957119941711425
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07141759991645813
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07237120270729065
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07326080203056336
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07330560088157653
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07550399899482726
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.140774405002594
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.30582079887390134
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04311360120773315
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04364160001277924
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04370880126953125
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07871999740600585
    - config:
        BLOCK_SIZE_B: 16
      time: 0.26370561122894287
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07088320255279541
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07197120189666747
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07249280214309692
    - config:
        BLOCK_SIZE_B: 16
      time: 0.3717855930328369
    - config:
        BLOCK_SIZE_B: 8
      time: 0.38032960891723633
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04107199907302857
    - config:
        BLOCK_SIZE_B: 2
      time: 0.042156800627708435
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04225600063800812
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04261119961738587
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04308800101280212
    - config:
        BLOCK_SIZE_B: 64
      time: 0.048419201374053956
    - config:
        BLOCK_SIZE_B: 128
      time: 0.11050560474395751
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06903359889984131
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06918079853057861
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0702239990234375
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07067199945449829
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07077760100364686
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10264639854431153
    - config:
        BLOCK_SIZE_B: 128
      time: 0.2016223907470703
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04194880127906799
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04259519875049591
    - config:
        BLOCK_SIZE_B: 16
      time: 0.042716801166534424
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042956799268722534
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04303039908409119
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0431551992893219
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04573439955711365
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.067958402633667
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06936960220336914
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07003840208053588
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07064319849014282
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07079359889030457
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07209280133247375
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07535679936408997
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.8113439559936524
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 8.28420181274414
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04241600036621094
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04253759980201721
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04316479861736298
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.044147199392318724
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04433920085430145
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07632960081100464
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.21894400119781493
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06870399713516236
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0698751986026764
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07028800249099731
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07118399739265442
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07275840044021606
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.11391359567642212
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.19720640182495117
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04750399887561798
    - config:
        BLOCK_SIZE_B: 1
      time: 0.050704002380371094
    - config:
        BLOCK_SIZE_B: 4
      time: 0.22873280048370362
    - config:
        BLOCK_SIZE_B: 8
      time: 0.4564671993255615
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07155200242996215
    - config:
        BLOCK_SIZE_B: 2
      time: 0.4422016143798828
    - config:
        BLOCK_SIZE_B: 4
      time: 0.5821152210235596
    - config:
        BLOCK_SIZE_B: 8
      time: 0.8752191543579102
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.041945600509643556
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04222399890422821
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.043017598986625674
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04407680034637451
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.046393600106239316
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.07470719814300537
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.16396479606628417
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.0643775999546051
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06438720226287842
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06472640037536621
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06511679887771607
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06536960005760192
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.08358079791069031
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.23363840579986572
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.041177600622177124
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04177280068397522
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04223679900169373
    - config:
        BLOCK_SIZE_B: 8
      time: 0.042320001125335696
    - config:
        BLOCK_SIZE_B: 16
      time: 0.05433599948883057
    - config:
        BLOCK_SIZE_B: 32
      time: 0.1099776029586792
    - config:
        BLOCK_SIZE_B: 64
      time: 0.2853087902069092
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.061977601051330565
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06322879791259765
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06355519890785218
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06402559876441956
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0948639988899231
    - config:
        BLOCK_SIZE_B: 32
      time: 0.15026559829711914
    - config:
        BLOCK_SIZE_B: 64
      time: 0.3391616106033325
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.040940800309181215
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04156799912452698
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04195199906826019
    - config:
        BLOCK_SIZE_B: 16
      time: 0.042080000042915344
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04276480078697205
    - config:
        BLOCK_SIZE_B: 32
      time: 0.043823999166488645
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07813760042190551
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.061612802743911746
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06251839995384216
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0625823974609375
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06317120194435119
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06326079964637757
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07034559845924378
    - config:
        BLOCK_SIZE_B: 512
      time: 0.11881920099258422
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.043075200915336606
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04377920031547546
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04380159974098206
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04436799883842468
    - config:
        BLOCK_SIZE_B: 512
      time: 0.044736000895500186
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.045612800121307376
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.05721920132637024
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06419839859008789
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06482880115509033
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06550719738006591
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06572160124778748
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06600639820098878
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06675519943237304
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.11775039434432984
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.14540159702301025
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2878144264221192
    - config:
        BLOCK_SIZE_B: 4
      time: 1.7170303344726563
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.6495328903198243
    - config:
        BLOCK_SIZE_B: 2
      time: 1.952467155456543
    - config:
        BLOCK_SIZE_B: 4
      time: 3.2827999114990236
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04359680116176605
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04392960071563721
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04410560131072998
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.044172799587249754
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0445279985666275
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.046828800439834596
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.2680896043777466
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06268799901008607
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06347839832305908
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06470400094985962
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06471679806709289
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06587200164794922
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.09440320134162902
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.3336031913757324
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04208639860153198
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04332799911499023
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04336000084877014
    - config:
        BLOCK_SIZE_B: 2
      time: 0.043823999166488645
    - config:
        BLOCK_SIZE_B: 16
      time: 0.16479040384292604
    - config:
        BLOCK_SIZE_B: 32
      time: 0.24866878986358643
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06423680186271667
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06559039950370789
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06596480011940002
    - config:
        BLOCK_SIZE_B: 8
      time: 0.2082047939300537
    - config:
        BLOCK_SIZE_B: 16
      time: 0.24001600742340087
    - config:
        BLOCK_SIZE_B: 32
      time: 0.40038719177246096
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04057919979095459
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04201599955558777
    - config:
        BLOCK_SIZE_B: 8
      time: 0.042028799653053284
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04251199960708618
    - config:
        BLOCK_SIZE_B: 64
      time: 0.043945598602294925
    - config:
        BLOCK_SIZE_B: 128
      time: 0.050944000482559204
    - config:
        BLOCK_SIZE_B: 256
      time: 0.1607807993888855
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0611519992351532
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06255360245704651
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06361920237541199
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06363199949264527
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06557440161705017
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07461119890213012
    - config:
        BLOCK_SIZE_B: 256
      time: 0.2479775905609131
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04222719967365265
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04239040017127991
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04261119961738587
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042716801166534424
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0445248007774353
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.044736000895500186
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06755840182304382
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06279360055923462
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06286079883575439
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06394879817962647
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06512960195541381
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0652671992778778
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06861439943313599
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.10714240074157715
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.7255071640014648
    - config:
        BLOCK_SIZE_B: 2
      time: 3.517539215087891
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 4.244457626342774
    - config:
        BLOCK_SIZE_B: 2
      time: 5.1101631164550785
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0418368011713028
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04259519875049591
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04359999895095825
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.043977600336074826
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0453792005777359
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05021759867668152
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.34343039989471436
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06327040195465088
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06329280138015747
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0646399974822998
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0651199996471405
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06556159853935242
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.09907519817352295
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.2656383991241455
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.044156798720359804
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04445120096206665
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04531520009040833
    - config:
        BLOCK_SIZE_B: 8
      time: 0.2674527883529663
    - config:
        BLOCK_SIZE_B: 16
      time: 0.32290239334106446
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06373760104179382
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0648352026939392
    - config:
        BLOCK_SIZE_B: 4
      time: 0.38041279315948484
    - config:
        BLOCK_SIZE_B: 8
      time: 0.5580639839172363
    - config:
        BLOCK_SIZE_B: 16
      time: 0.5809696197509766
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.042742401361465454
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04307200014591217
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04319359958171844
    - config:
        BLOCK_SIZE_B: 2
      time: 0.044147199392318724
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04789440035820007
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10588159561157226
    - config:
        BLOCK_SIZE_B: 128
      time: 0.18587199449539185
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06270400285720826
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06408960223197938
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06510080099105835
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06615999937057496
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06648640036582946
    - config:
        BLOCK_SIZE_B: 64
      time: 0.11367360353469849
    - config:
        BLOCK_SIZE_B: 128
      time: 0.24277119636535643
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04166719913482666
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04166719913482666
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04168959856033325
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04175040125846863
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042710399627685545
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043721601366996765
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06865599751472473
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.061868798732757566
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06351360082626342
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06356160044670105
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06361600160598754
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06511039733886718
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06553279757499694
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.11175040006637574
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 7.5390625
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 10.192546844482422
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042233601212501526
    - config:
        BLOCK_SIZE_B: 512
      time: 0.042316800355911253
    - config:
        BLOCK_SIZE_B: 128
      time: 0.042656001448631284
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.042691200971603394
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04430400133132935
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0633247971534729
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.2717184066772461
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06380800008773804
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06421440243721008
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06442880034446716
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06452800035476684
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06542720198631287
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.10703040361404419
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.29084799289703367
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07259520292282104
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07585279941558838
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6242527961730957
    - config:
        BLOCK_SIZE_B: 8
      time: 0.7862592220306397
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.08450880050659179
    - config:
        BLOCK_SIZE_B: 2
      time: 0.6458752155303955
    - config:
        BLOCK_SIZE_B: 4
      time: 0.8742015838623047
    - config:
        BLOCK_SIZE_B: 8
      time: 1.371401596069336
  kernels/rmsnorm/triton_implementation/kernels_forward.py->rmsnorm_forward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03299199938774109
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033843201398849485
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03396160006523132
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03425920009613037
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03430080115795135
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.045686399936676024
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.09545279741287231
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03572799861431122
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03613120019435882
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03622080087661743
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0369376003742218
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03807680010795593
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.05026879906654358
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.10966720581054687
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03163520097732544
    - config:
        BLOCK_SIZE_B: 32
      time: 0.032627201080322264
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033081600069999696
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0333407998085022
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03416639864444733
    - config:
        BLOCK_SIZE_B: 1
      time: 0.034441599249839784
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04891520142555237
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03551360070705414
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03619199991226196
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036345601081848145
    - config:
        BLOCK_SIZE_B: 8
      time: 0.037110400199890134
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03716480135917664
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037385600805282596
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03795520067214966
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03333120048046112
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033529600501060484
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03359679877758026
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03368319869041443
    - config:
        BLOCK_SIZE_B: 128
      time: 0.033795198798179625
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034255999326705935
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03440000116825104
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03646720051765442
    - config:
        BLOCK_SIZE_B: 16
      time: 0.036671999096870425
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03671999871730804
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036735999584198
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037299200892448425
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037599998712539676
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03885439932346344
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03281919956207276
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03303999900817871
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03306559920310974
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033744001388549806
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0344543993473053
    - config:
        BLOCK_SIZE_B: 64
      time: 0.034467199444770814
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04559679925441742
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03605439960956573
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03610239923000336
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03650240004062653
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03692800104618073
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037011200189590455
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03734399974346161
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03764480054378509
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04799680113792419
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05064319968223572
    - config:
        BLOCK_SIZE_B: 4
      time: 0.3038655996322632
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05310400128364563
    - config:
        BLOCK_SIZE_B: 2
      time: 0.059273600578308105
    - config:
        BLOCK_SIZE_B: 4
      time: 0.44917120933532717
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0325984001159668
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03319680094718933
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03327040076255798
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033792001008987424
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.035283198952674864
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04733439981937408
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09927039742469787
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.035641598701477054
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03630400002002716
    - config:
        BLOCK_SIZE_B: 512
      time: 0.036355200409889224
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.036627200245857236
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03770560026168823
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04800640046596527
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.10110399723052979
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.032671999931335446
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033276799321174624
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033452799916267394
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03412480056285858
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03426879942417145
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04300479888916016
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.035692799091339114
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0366239994764328
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03669120073318481
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03701440095901489
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03707840144634247
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04029119908809662
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03286080062389374
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03312320113182068
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0335072010755539
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03362559974193573
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03403519988059998
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03403519988059998
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03487679958343506
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036595198512077334
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036735999584198
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03681280016899109
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037196800112724304
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03799999952316284
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03808000087738037
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03823359906673431
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03311040103435516
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03313280045986176
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03346560001373291
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03391039967536926
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03400000035762787
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03470720052719116
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0443807989358902
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03704000115394592
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0376800000667572
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03771840035915375
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03782399892807007
    - config:
        BLOCK_SIZE_B: 512
      time: 0.038166400790214536
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03877759873867035
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03903360068798065
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09558719992637635
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7215231895446778
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.1350751996040344
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7742591857910156
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033395200967788696
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03340800106525421
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03342080116271973
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03345920145511627
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033923199772834776
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05380480289459229
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14666880369186402
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0355679988861084
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03656960129737854
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.036627200245857236
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.037212800979614255
    - config:
        BLOCK_SIZE_B: 256
      time: 0.038217601180076596
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05494719743728638
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.1509727954864502
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.033199998736381534
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03360320031642914
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0336544007062912
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03484480082988739
    - config:
        BLOCK_SIZE_B: 16
      time: 0.044972801208496095
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03588800132274628
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0367935985326767
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0369951993227005
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03706879913806915
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04623680114746094
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.032892799377441405
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03312320113182068
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03329919874668121
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0333407998085022
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03351680040359497
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03368639945983887
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03577280044555664
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03654080033302307
    - config:
        BLOCK_SIZE_B: 32
      time: 0.036646398901939395
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0368800014257431
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03696320056915283
    - config:
        BLOCK_SIZE_B: 2
      time: 0.037299200892448425
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03772160112857818
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03938240110874176
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.032502400875091556
    - config:
        BLOCK_SIZE_B: 64
      time: 0.032943999767303465
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03333120048046112
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03394240140914917
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033955198526382444
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03429119884967804
    - config:
        BLOCK_SIZE_B: 32
      time: 0.034380799531936644
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.035699200630187986
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03624640107154846
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0365664005279541
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036575999855995175
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03658879995346069
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03695360124111176
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03828479945659637
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.5729536056518555
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.2010656356811524
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03319360017776489
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03351039886474609
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0345984011888504
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03460800051689148
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03521600067615509
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06548159718513488
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17785919904708863
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.035894399881362914
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03700479865074158
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03702400028705597
    - config:
        BLOCK_SIZE_B: 512
      time: 0.037088000774383546
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037564799189567566
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0662335991859436
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.1781599998474121
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03469760119915009
    - config:
        BLOCK_SIZE_B: 1
      time: 0.035308799147605895
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03580160140991211
    - config:
        BLOCK_SIZE_B: 8
      time: 0.14331840276718139
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03738879859447479
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03805760145187378
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03828479945659637
    - config:
        BLOCK_SIZE_B: 8
      time: 0.1376960039138794
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03277440071105957
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.033542400598526
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03373439908027649
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03403519988059998
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03452160060405731
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.03699840009212494
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.06468160152435302
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03544960021972656
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03570240139961243
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.037334400415420535
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03777920007705689
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03819519877433777
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.044495999813079834
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.09395840167999267
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.031667199730873105
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03277440071105957
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03305279910564422
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03316799998283386
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03357760012149811
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03376320004463196
    - config:
        BLOCK_SIZE_B: 64
      time: 0.05111039876937866
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0361407995223999
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03647040128707886
    - config:
        BLOCK_SIZE_B: 32
      time: 0.036499199271202085
    - config:
        BLOCK_SIZE_B: 2
      time: 0.036508798599243164
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03659200072288513
    - config:
        BLOCK_SIZE_B: 1
      time: 0.036713600158691406
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03709119856357575
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.032732799649238586
    - config:
        BLOCK_SIZE_B: 128
      time: 0.033180800080299375
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033344000577926636
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033395200967788696
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033430400490760806
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03383359909057617
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04336000084877014
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03611840009689331
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03636159896850586
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03638719916343689
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03639360070228577
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03707840144634247
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03739520013332367
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043875199556350705
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.032646399736404416
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03329919874668121
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03335680067539215
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033523198962211606
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03374080061912536
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03483839929103851
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03697920143604279
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03610559999942779
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03615039885044098
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03727039992809296
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03766719996929169
    - config:
        BLOCK_SIZE_B: 64
      time: 0.038185599446296695
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.038726401329040525
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04166719913482666
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04764159917831421
    - config:
        BLOCK_SIZE_B: 2
      time: 0.050780802965164185
    - config:
        BLOCK_SIZE_B: 4
      time: 0.24833920001983642
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05440959930419922
    - config:
        BLOCK_SIZE_B: 2
      time: 0.057392001152038574
    - config:
        BLOCK_SIZE_B: 4
      time: 0.32730879783630373
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03278720080852508
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033744001388549806
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03423359990119934
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03470720052719116
    - config:
        BLOCK_SIZE_B: 512
      time: 0.035964798927307126
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04756160080432892
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09958080053329468
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.036348798871040346
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.036617600917816163
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03705599904060364
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0377344012260437
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03892160058021545
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04865919947624207
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.10121599435806275
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03285439908504486
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033225598931312564
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03342080116271973
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03344320058822632
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03389439880847931
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03431999981403351
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03555839955806732
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03629760146141052
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036380800604820254
    - config:
        BLOCK_SIZE_B: 1
      time: 0.036883199214935304
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03689279854297638
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03769600093364715
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.032252800464630124
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03227199912071228
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0328000009059906
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03299840092658997
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03342080116271973
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03399679958820343
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03419840037822723
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03596799969673157
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036294400691986084
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03641600012779236
    - config:
        BLOCK_SIZE_B: 32
      time: 0.036457601189613345
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0366784006357193
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037187200784683225
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03738879859447479
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033107200264930726
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03324800133705139
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033564800024032594
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03373120129108429
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03410240113735199
    - config:
        BLOCK_SIZE_B: 64
      time: 0.034694400429725644
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04160000085830688
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.035641598701477054
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03675200045108795
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0367680013179779
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037145599722862244
    - config:
        BLOCK_SIZE_B: 512
      time: 0.037945601344108584
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037990400195121767
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03889600038528442
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09569600224494934
    - config:
        BLOCK_SIZE_B: 2
      time: 0.4229856014251709
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.13170239925384522
    - config:
        BLOCK_SIZE_B: 2
      time: 0.6873151779174804
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03297280073165894
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03299199938774109
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03326080143451691
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033504000306129454
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03422400057315826
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.053718400001525876
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14696320295333862
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03624959886074066
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0362527996301651
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.037363201379776
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03789759874343872
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.037913599610328676
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05497599840164184
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.1510848045349121
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03331519961357117
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03373439908027649
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03444480001926422
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03460800051689148
    - config:
        BLOCK_SIZE_B: 16
      time: 0.051964801549911496
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03605439960956573
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03643839955329895
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03678719997406006
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03681600093841553
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04643200039863586
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03225919902324677
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03283199965953827
    - config:
        BLOCK_SIZE_B: 2
      time: 0.033036801218986514
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03353599905967712
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03398720026016235
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0341376006603241
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03472639918327332
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03537600040435791
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03590399920940399
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03640320003032684
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03653120100498199
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03665600121021271
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03727999925613403
    - config:
        BLOCK_SIZE_B: 128
      time: 0.038278400897979736
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.032969599962234496
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033004799485206605
    - config:
        BLOCK_SIZE_B: 128
      time: 0.033251199126243594
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033344000577926636
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03387520015239716
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03462400138378143
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04070720076560974
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03601599931716919
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03604159951210022
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03604159951210022
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03705280125141144
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03707520067691803
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03742400109767914
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.039683198928833006
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.578764820098877
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.3079584121704102
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.032969599962234496
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033542400598526
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03355199992656708
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033583998680114746
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03459199965000152
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06558079719543457
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.1777151942253113
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03647040128707886
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03695360124111176
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03731200098991394
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037363201379776
    - config:
        BLOCK_SIZE_B: 512
      time: 0.037401598691940305
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06618239879608154
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.1781440019607544
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.034332799911499026
    - config:
        BLOCK_SIZE_B: 1
      time: 0.034892800450325015
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03584319949150085
    - config:
        BLOCK_SIZE_B: 8
      time: 0.1096384048461914
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03786559998989105
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03790079951286316
    - config:
        BLOCK_SIZE_B: 1
      time: 0.038185599446296695
    - config:
        BLOCK_SIZE_B: 8
      time: 0.09751359820365905
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.032227200269699094
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03269439935684204
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03326399922370911
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.033958399295806886
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.035420799255371095
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.03969280123710632
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.08912640213966369
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.036313599348068236
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.036595198512077334
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.036847999691963194
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03705280125141144
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03773120045661926
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.039241600036621097
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.06298879981040954
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.031814399361610415
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03218240141868591
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03271999955177307
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03278079926967621
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03389120101928711
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03447360098361969
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07728319764137268
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03668479919433594
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03689599931240082
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03691520094871521
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03731519877910614
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037648001313209535
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03768639862537384
    - config:
        BLOCK_SIZE_B: 64
      time: 0.08892800211906433
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03221440017223358
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0326335996389389
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033241599798202515
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03340800106525421
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03356800079345703
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0338016003370285
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06479679942131042
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03550080060958862
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03606719970703125
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03619199991226196
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037001600861549376
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03710080087184906
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03712640106678009
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07049919962882996
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03312320113182068
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0331743985414505
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0333983987569809
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03364480137825012
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03412800133228302
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03485119938850403
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.05524160265922547
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03638400137424469
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.036847999691963194
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03704319894313812
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03806079924106598
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03841600120067597
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.039017599821090695
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.05241280198097229
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09354239702224731
    - config:
        BLOCK_SIZE_B: 2
      time: 0.10049279928207397
    - config:
        BLOCK_SIZE_B: 4
      time: 0.378767991065979
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.10108480453491211
    - config:
        BLOCK_SIZE_B: 4
      time: 0.4467936038970947
    - config:
        BLOCK_SIZE_B: 2
      time: 0.5224832057952881
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03285120129585266
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03313600122928619
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03456639945507049
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03457599878311157
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03460479974746704
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.049327999353408813
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09384639859199524
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.036329600214958194
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03707520067691803
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03720000088214874
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03723520040512085
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.039001598954200745
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.050627201795578
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09685760140419006
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03229439854621887
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03258239924907684
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03327040076255798
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03338240087032318
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03471679985523224
    - config:
        BLOCK_SIZE_B: 32
      time: 0.10304640531539917
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03646720051765442
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03648959994316101
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0365664005279541
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03676480054855347
    - config:
        BLOCK_SIZE_B: 2
      time: 0.037334400415420535
    - config:
        BLOCK_SIZE_B: 32
      time: 0.125491201877594
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03327040076255798
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033497598767280576
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03394879996776581
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03441280126571655
    - config:
        BLOCK_SIZE_B: 128
      time: 0.035996800661087035
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036847999691963194
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07279999852180481
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036294400691986084
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03643839955329895
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0369376003742218
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03807039856910706
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0381056010723114
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03890880048274994
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07661759853363037
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03297599852085113
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03339200019836426
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03352639973163605
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03384959995746613
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03394879996776581
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03612799942493439
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.05509759783744812
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0363103985786438
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03684160113334656
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037231999635696414
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03776319921016693
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03792319893836975
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03919360041618347
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0640447974205017
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.195632004737854
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7733344078063965
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 1.0763615608215331
    - config:
        BLOCK_SIZE_B: 1
      time: 1.0773183822631835
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03284479975700379
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0338016003370285
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0338591992855072
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03465920090675354
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03504959940910339
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.053439998626708986
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.10821759700775146
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.027244800329208375
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03694399893283844
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03694719970226288
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03720000088214874
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03738240003585815
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05356799960136414
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.1072543978691101
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03441919982433319
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03467839956283569
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03491199910640717
    - config:
        BLOCK_SIZE_B: 1
      time: 0.035071998834609985
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09846720099449158
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03771840035915375
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03777920007705689
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03792960047721863
    - config:
        BLOCK_SIZE_B: 1
      time: 0.038960000872612
    - config:
        BLOCK_SIZE_B: 16
      time: 0.15446399450302123
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03237119913101196
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03316160142421722
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033164799213409424
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03332479894161224
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03360320031642914
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03376320004463196
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07780159711837768
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03556160032749176
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0361407995223999
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03615680038928985
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036339199542999266
    - config:
        BLOCK_SIZE_B: 2
      time: 0.036687999963760376
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04074560105800629
    - config:
        BLOCK_SIZE_B: 128
      time: 0.05898879766464234
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0328575998544693
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03319360017776489
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03368639945983887
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033913600444793704
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0339711993932724
    - config:
        BLOCK_SIZE_B: 512
      time: 0.039792001247406006
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.064028799533844
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03592320084571839
    - config:
        BLOCK_SIZE_B: 16
      time: 0.035939198732376096
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03617280125617981
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03635840117931366
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03654080033302307
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03680959939956665
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06233279705047608
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.5986016273498536
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.0202688217163085
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03280639946460724
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03327040076255798
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03336640000343323
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03395200073719025
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03434560000896454
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06378560066223145
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17591359615325927
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03650560081005096
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.037011200189590455
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037462401390075686
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037571200728416444
    - config:
        BLOCK_SIZE_B: 128
      time: 0.038396799564361574
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06526399850845337
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.16701120138168335
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04739519953727722
    - config:
        BLOCK_SIZE_B: 2
      time: 0.048716801404953006
    - config:
        BLOCK_SIZE_B: 4
      time: 0.05229439735412598
    - config:
        BLOCK_SIZE_B: 8
      time: 0.18240000009536744
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04991680085659027
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0499455988407135
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06741759777069092
    - config:
        BLOCK_SIZE_B: 8
      time: 0.24465279579162597
  kernels/swiglu/backward.py->_backward:
    '''gate.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.28034560680389403
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.2815135955810547
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.2819391965866089
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.2820703983306885
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.28229761123657227
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.28230719566345214
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.28239998817443845
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.28255040645599366
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.2825952053070068
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.2827167987823486
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.282806396484375
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.28330240249633787
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.2897536039352417
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.28990399837493896
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.29589760303497314
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.30731520652770994
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.3075263977050781
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.36580801010131836
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.49738240242004395
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.5961599826812745
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9898655891418457
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 3.881999969482422
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 4.079804611206055
    '''gate.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.2787359952926636
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.2793247938156128
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.27949440479278564
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.2796992063522339
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.27978880405426027
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.27984640598297117
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.2800800085067749
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.28034238815307616
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.28051199913024905
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.28055360317230227
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.28073279857635497
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.28075199127197265
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.28738880157470703
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.28761279582977295
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2946367979049683
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.3064095973968506
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.30656321048736573
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.3159327983856201
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.4976223945617676
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.5331488132476807
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9897120475769043
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 3.5832801818847657
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 3.642268753051758
    '''gate.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.5529600143432617
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.5541632175445557
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.5542208194732666
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.5548448085784912
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.5549183845520019
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.5559743881225586
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.5561728000640869
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.558899211883545
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.5606048107147217
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.581008005142212
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.5815680027008057
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.5980031967163086
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.9185952186584473
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9912832260131836
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 1.2147135734558105
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 4.752572631835937
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 4.866841506958008
  kernels/swiglu/forward.py->_forward:
    '''gate.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14126399755477906
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.14133440256118773
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.14251840114593506
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.14309439659118653
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.14718400239944457
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.14977279901504517
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.2024384021759033
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.20252161026000975
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.20257279872894288
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.20263679027557374
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.202726411819458
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.2029184103012085
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.20469119548797607
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.20478720664978028
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 0.21323199272155763
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.2246623992919922
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.22550079822540284
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2503391981124878
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2529695987701416
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.25303359031677247
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.49630398750305177
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9896160125732422
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 1.1497568130493163
    '''gate.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14078400135040284
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.14167360067367554
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.14262720346450805
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.1465407967567444
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.14691840410232543
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.15683200359344482
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.19918400049209595
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.1992192029953003
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.1992799997329712
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.19935359954833984
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.1994879961013794
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.19971200227737426
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.201580810546875
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.20186879634857177
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 0.20824000835418702
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.22218561172485352
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.22260479927062987
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2505343914031982
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2531327962875366
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.2532416105270386
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.49661760330200194
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9898112297058106
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 1.1516863822937011
    '''gate.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.2779167890548706
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.27859199047088623
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.27876160144805906
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.2787775993347168
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.2816672086715698
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.2821408033370972
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.2841984033584595
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.28710079193115234
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.29342079162597656
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.30304000377655027
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.31179521083831785
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.34960958957672117
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.4966752052307129
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.4967679977416992
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9874752044677735
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 1.9832319259643554
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 2.0554943084716797
  kernels/swiglu_unchunked/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.561075210571289
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.0189535140991213
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 3.2409694671630858
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.517330932617188
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.648626708984374
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5323007583618165
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.7296928405761718
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.752761650085449
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.87407989501953
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.160185241699217
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.6104768753051757
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 3.2013534545898437
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 5.669740676879883
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.077183532714844
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.318392944335937
  kernels/swiglu_unchunked/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.955782413482666
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9560895919799804
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.049516773223877
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.3192735671997071
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 6.211980819702148
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9418335914611816
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9480511665344238
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.0424799919128418
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.2554783821105957
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 6.156911849975586
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5741567611694336
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.6337087631225586
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.8542976379394531
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 8.69925765991211
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 8.706393432617187
best_configs:
  kernels/add/add_scalar/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.141046404838562
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14085760116577148
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778496026992798
  kernels/add/add_tensor/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1410815954208374
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1406880021095276
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778559923171997
  kernels/embedding/backward.py->_backward:
    '''weight.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.250962829589843
    '''weight.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 3.520441436767578
    '''weight.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 9.787811279296875
  kernels/embedding/forward.py->_forward:
    '''weight.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6663392066955567
    '''weight.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6661375999450684
    '''weight.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.3731871604919434
  kernels/rmsnorm/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float32''':
      config:
        kernel_backend: triton
      time: 0
  kernels/rmsnorm/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float32''':
      config:
        kernel_backend: triton
      time: 0
  kernels/rmsnorm/triton_implementation/kernels_backward.py->rmsnorm_backward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16384
      time: 0.04222719967365265
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.06968320012092591
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.041808000206947325
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06932479739189149
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.04176000058650971
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06958400011062622
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.041417598724365234
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.07006400227546691
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.078847998380661
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 1.48372802734375
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.04129279851913452
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.06810560226440429
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04147520065307617
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06977279782295227
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.042710399627685545
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.06893119812011719
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04251520037651062
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.07067199945449829
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.1058015823364258
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 3.603667068481445
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04133439958095551
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.06880639791488648
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.042582398653030394
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.07095680236816407
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04182719886302948
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06887680292129517
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04103679955005646
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.07031679749488831
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.2166559219360353
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 10.403075408935546
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.042412799596786496
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.06907839775085449
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04464640021324158
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07262719869613647
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.041065600514411923
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.06951040029525757
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.041116800904273984
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.06926400065422059
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.04102079868316651
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.06922879815101624
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04213759899139404
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.07090240120887756
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07907519936561584
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.1145888328552247
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04303039908409119
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.071670401096344
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.041407999396324155
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.06929600238800049
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.041126400232315063
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.06865599751472473
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04200960099697113
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.06967039704322815
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.8838335990905761
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 2.9421823501586912
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.04227199852466583
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.07141759991645813
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04311360120773315
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07088320255279541
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04107199907302857
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.06903359889984131
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.04194880127906799
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.067958402633667
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.8113439559936524
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 8.28420181274414
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04241600036621094
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.06870399713516236
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04750399887561798
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07155200242996215
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.041945600509643556
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16384
      time: 0.0643775999546051
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.041177600622177124
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.061977601051330565
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.040940800309181215
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.061612802743911746
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.043075200915336606
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.06419839859008789
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.14540159702301025
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.6495328903198243
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.04359680116176605
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.06268799901008607
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.04208639860153198
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.06423680186271667
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04057919979095459
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.0611519992351532
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04222719967365265
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06279360055923462
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.7255071640014648
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 4.244457626342774
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.0418368011713028
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.06327040195465088
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.044156798720359804
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.06373760104179382
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.042742401361465454
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.06270400285720826
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04166719913482666
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.061868798732757566
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 7.5390625
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 10.192546844482422
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.042233601212501526
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.06380800008773804
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07259520292282104
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.08450880050659179
  kernels/rmsnorm/triton_implementation/kernels_forward.py->rmsnorm_forward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.03299199938774109
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03572799861431122
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03163520097732544
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03551360070705414
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03333120048046112
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03646720051765442
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03281919956207276
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03605439960956573
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04799680113792419
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.05310400128364563
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.0325984001159668
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.035641598701477054
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.032671999931335446
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.035692799091339114
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03286080062389374
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.036595198512077334
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03311040103435516
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03704000115394592
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09558719992637635
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.1350751996040344
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.033395200967788696
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.0355679988861084
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.033199998736381534
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03588800132274628
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.032892799377441405
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03654080033302307
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.032502400875091556
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.035699200630187986
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.5729536056518555
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.2010656356811524
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03319360017776489
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.035894399881362914
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03469760119915009
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.03738879859447479
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03277440071105957
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03544960021972656
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.031667199730873105
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.0361407995223999
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.032732799649238586
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03611840009689331
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.032646399736404416
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03610559999942779
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04764159917831421
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.05440959930419922
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03278720080852508
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.036348798871040346
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03285439908504486
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03555839955806732
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.032252800464630124
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03596799969673157
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.033107200264930726
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.035641598701477054
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09569600224494934
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.13170239925384522
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03297280073165894
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03624959886074066
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03331519961357117
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03605439960956573
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03225919902324677
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03537600040435791
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.032969599962234496
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03601599931716919
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.578764820098877
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.3079584121704102
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.032969599962234496
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03647040128707886
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.034332799911499026
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03786559998989105
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.032227200269699094
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.036313599348068236
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.031814399361610415
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03668479919433594
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03221440017223358
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03550080060958862
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03312320113182068
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03638400137424469
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09354239702224731
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.10108480453491211
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03285120129585266
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.036329600214958194
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03229439854621887
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03646720051765442
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03327040076255798
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.036294400691986084
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03297599852085113
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.0363103985786438
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.195632004737854
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 1.0763615608215331
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03284479975700379
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.027244800329208375
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03441919982433319
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03771840035915375
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03237119913101196
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03556160032749176
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.0328575998544693
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03592320084571839
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.5986016273498536
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.0202688217163085
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03280639946460724
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03650560081005096
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04739519953727722
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04991680085659027
  kernels/swiglu/backward.py->_backward:
    '''gate.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.28034560680389403
    '''gate.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.2787359952926636
    '''gate.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.5529600143432617
  kernels/swiglu/forward.py->_forward:
    '''gate.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14126399755477906
    '''gate.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14078400135040284
    '''gate.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.2779167890548706
  kernels/swiglu_unchunked/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.561075210571289
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5323007583618165
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.6104768753051757
  kernels/swiglu_unchunked/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.955782413482666
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9418335914611816
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5741567611694336
