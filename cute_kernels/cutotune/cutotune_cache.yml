all_configs:
  kernels/add/add_scalar/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14135680198669434
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14140160083770753
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14141759872436524
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14141759872436524
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14151999950408936
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14152319431304933
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1415328025817871
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1421663999557495
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14220160245895386
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14236799478530884
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14301760196685792
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.144377601146698
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1456063985824585
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1481279969215393
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14939199686050414
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15279680490493774
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15877439975738525
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18368639945983886
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20164480209350585
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.227728009223938
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.24975039958953857
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.24979519844055176
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.24983999729156495
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2504735946655273
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3036736011505127
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3338815927505493
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38177919387817383
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49536638259887694
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4955776214599609
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4957280158996582
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4957727909088135
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9877023696899414
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9878815650939942
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.988156795501709
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9729888916015625
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.140719997882843
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14084160327911377
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14085439443588257
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14097280502319337
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14101120233535766
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14113279581069946
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1411360025405884
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14228800535202027
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1424512028694153
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14270399808883666
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14326720237731932
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14390079975128173
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14549119472503663
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14742399454116822
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14787839651107787
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1522271990776062
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15862079858779907
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18360320329666138
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20188479423522948
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2277600049972534
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2500704050064087
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2502592086791992
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.25037760734558107
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2508575916290283
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3045439958572388
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3346143960952759
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38309440612792967
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4955167770385742
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4972479820251465
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4975071907043457
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4977695941925049
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9878047943115235
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9929023742675781
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9936479568481446
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9846431732177734
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2779968023300171
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2781536102294922
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2784543991088867
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2785088062286377
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27859840393066404
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2788991928100586
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27902400493621826
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28061439990997317
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28104960918426514
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28196799755096436
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28235199451446535
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28473920822143556
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2868000030517578
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.29133760929107666
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.29599039554595946
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3011199951171875
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.31245439052581786
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3576672077178955
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.39092800617218015
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4376063823699951
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4957568168640137
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49580798149108884
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49648318290710447
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49699840545654295
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9714143753051758
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9875455856323242
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9877408027648926
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9878080368041993
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9720800399780274
  kernels/add/add_tensor/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14080640077590942
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1409440040588379
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14103039503097534
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14107199907302856
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14122560024261474
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.141593599319458
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1416095972061157
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14172799587249757
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14196799993515014
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1420799970626831
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14218560457229615
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1444607973098755
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1460543990135193
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1481824040412903
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15277119874954223
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15901440382003784
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18363840579986573
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20176000595092775
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2276384115219116
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.24981119632720947
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2498624086380005
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.24996800422668458
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2503999948501587
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3061728000640869
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3378432035446167
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3871583938598633
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4956064224243164
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49567041397094724
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4956831932067871
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4957280158996582
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9629280090332031
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9876192092895508
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9878591537475586
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9880352020263672
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.972447967529297
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14049919843673705
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14069440364837646
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14090240001678467
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14098559617996215
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14104959964752198
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14127360582351683
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14145599603652953
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14145920276641846
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14187519550323485
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14214400053024293
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14292800426483154
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14426560401916505
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1456223964691162
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14829440116882325
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15253119468688964
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15869439840316774
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18359999656677245
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20201280117034912
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2278592109680176
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.24971520900726318
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.24982080459594727
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2500416040420532
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2503711938858032
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30692479610443113
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.33841280937194823
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38764801025390627
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49536957740783694
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4957695960998535
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49591360092163084
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49595842361450193
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9879520416259766
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9883296012878418
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9885663986206055
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 1.0381024360656739
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9736383438110352
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778239965438843
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2780224084854126
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27822399139404297
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2782655954360962
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27826879024505613
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2789599895477295
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2794431924819946
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2794816017150879
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2805248022079468
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28088319301605225
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28135359287261963
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.285155200958252
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2874144077301025
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.29199039936065674
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.30144319534301756
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3129215955734253
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.35951359272003175
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.393395209312439
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4397791862487793
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49567360877990724
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49590401649475097
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49641919136047363
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49692797660827637
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9875103950500488
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9877823829650879
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.987980842590332
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9725151062011719
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.001801681518555
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.092787170410156
  kernels/embedding/backward.py->_backward:
    '''weight.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.265776062011719
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 10.272370910644531
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.316073608398437
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 11.210108947753906
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 11.292249298095703
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 11.534563446044922
    '''weight.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 3.5257919311523436
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.24964485168457
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.265446472167969
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.613087844848633
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.633366394042969
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 5.810515213012695
    '''weight.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 9.810809326171874
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 9.846160125732421
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.038441467285157
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.219145965576171
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.524681854248048
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.883920288085937
  kernels/embedding/forward.py->_forward:
    '''weight.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6666336059570312
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6668735980987549
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.701036787033081
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7258624076843262
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.7811232089996338
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 0.8637184143066406
    '''weight.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6664063930511475
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6668543815612793
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7008255958557129
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.7264448165893554
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.7814976215362549
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 0.8645152091979981
    '''weight.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.3737183570861817
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.4242560386657714
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 1.7098304748535156
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 4.7767486572265625
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.027814483642578
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.2815807342529295
  kernels/rmsnorm/triton_implementation/__init__.py->rmsnorm_backward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.042947199940681455
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.043635201454162595
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.043942400813102724
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04395520091056824
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0445279985666275
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09103040099143982
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.22971839904785157
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06512640118598938
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06686080098152161
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06689280271530151
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06768959760665894
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06806399822235107
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09523839950561523
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.22481279373168944
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04362240135669708
    - config:
        BLOCK_SIZE_B: 4
      time: 0.043798398971557614
    - config:
        BLOCK_SIZE_B: 2
      time: 0.044223999977111815
    - config:
        BLOCK_SIZE_B: 8
      time: 0.044582399725914004
    - config:
        BLOCK_SIZE_B: 16
      time: 0.044950398802757266
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0769312024116516
    - config:
        BLOCK_SIZE_B: 64
      time: 0.18451199531555176
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06558719873428345
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0675104022026062
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06785600185394287
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06826239824295044
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06831679940223694
    - config:
        BLOCK_SIZE_B: 32
      time: 0.13692159652709962
    - config:
        BLOCK_SIZE_B: 64
      time: 0.4138656139373779
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04211840033531189
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04240959882736206
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04313279986381531
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04318400025367737
    - config:
        BLOCK_SIZE_B: 128
      time: 0.043593600392341614
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043724799156188966
    - config:
        BLOCK_SIZE_B: 512
      time: 0.05132799744606018
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06593599915504456
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06622719764709473
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06698560118675231
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06742720007896423
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06749119758605956
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06809279918670655
    - config:
        BLOCK_SIZE_B: 512
      time: 0.2007551908493042
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04192639887332916
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0427839994430542
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04392000138759613
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04399040043354034
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04400320053100586
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0444927990436554
    - config:
        BLOCK_SIZE_B: 128
      time: 0.046076801419258115
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06518080234527587
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06525120139122009
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06624320149421692
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06681920289993286
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0675167977809906
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07040640115737914
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.15930559635162353
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07920960187911988
    - config:
        BLOCK_SIZE_B: 2
      time: 0.5499872207641602
    - config:
        BLOCK_SIZE_B: 4
      time: 0.7074272155761718
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 1.543337631225586
    - config:
        BLOCK_SIZE_B: 1
      time: 1.6006559371948241
    - config:
        BLOCK_SIZE_B: 4
      time: 2.8061952590942383
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04151360094547272
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04219839870929718
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.042556801438331605
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04414080083370209
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04560000002384186
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.061715197563171384
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.19272639751434326
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06446080207824707
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06514559984207154
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06549760103225707
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06575999855995178
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06579840183258057
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.0938368022441864
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.1747007966041565
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04355199933052063
    - config:
        BLOCK_SIZE_B: 1
      time: 0.043884798884391785
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04403519928455353
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04439359903335571
    - config:
        BLOCK_SIZE_B: 16
      time: 0.1090399980545044
    - config:
        BLOCK_SIZE_B: 32
      time: 0.2668479919433594
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06755520105361938
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06800000071525573
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06936960220336914
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07754240036010743
    - config:
        BLOCK_SIZE_B: 16
      time: 0.21118080615997314
    - config:
        BLOCK_SIZE_B: 32
      time: 0.5243135929107666
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04167360067367554
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04179840087890625
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04191359877586365
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04264959990978241
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04307839870452881
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04311679899692535
    - config:
        BLOCK_SIZE_B: 256
      time: 0.05195519924163818
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06513599753379821
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06524800062179566
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06561920046806335
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06655359864234925
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06719679832458496
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06836159825325012
    - config:
        BLOCK_SIZE_B: 256
      time: 0.19778560400009154
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04201599955558777
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04303039908409119
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.043161600828170776
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04325760006904602
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0437855988740921
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04410560131072998
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.05132799744606018
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06455039978027344
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06504639983177185
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06616960167884826
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06662719845771789
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06679040193557739
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06754879951477051
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.16786880493164064
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.1104191780090331
    - config:
        BLOCK_SIZE_B: 2
      time: 1.8001440048217774
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 3.6815200805664063
    - config:
        BLOCK_SIZE_B: 1
      time: 4.224006271362304
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04296000003814697
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04354560077190399
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.043647998571395875
    - config:
        BLOCK_SIZE_B: 256
      time: 0.044336000084877016
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.044412800669670106
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.065583997964859
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.21151039600372315
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06480960249900818
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06511679887771607
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06546880006790161
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06782079935073852
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07470719814300537
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.10084160566329955
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.17383999824523927
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04576959908008575
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04610880017280579
    - config:
        BLOCK_SIZE_B: 4
      time: 0.046249601244926455
    - config:
        BLOCK_SIZE_B: 8
      time: 0.17851519584655762
    - config:
        BLOCK_SIZE_B: 16
      time: 0.26590399742126464
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06919040083885193
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06950079798698425
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06986879706382751
    - config:
        BLOCK_SIZE_B: 8
      time: 0.4684000015258789
    - config:
        BLOCK_SIZE_B: 16
      time: 0.8248096466064453
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04220480024814606
    - config:
        BLOCK_SIZE_B: 32
      time: 0.043007999658584595
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043638399243354796
    - config:
        BLOCK_SIZE_B: 16
      time: 0.043808001279830935
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0440064013004303
    - config:
        BLOCK_SIZE_B: 64
      time: 0.05107839703559876
    - config:
        BLOCK_SIZE_B: 128
      time: 0.13275840282440185
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06567360162734985
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06674879789352417
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0673471987247467
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06755200028419495
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0676576018333435
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10407040119171143
    - config:
        BLOCK_SIZE_B: 128
      time: 0.3384768009185791
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04195519983768463
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04294399917125702
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0434112012386322
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04345600008964538
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04368320107460022
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04493440091609955
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.05018240213394165
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06582720279693603
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06588799953460693
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06607360243797303
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06639999747276307
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06641280055046081
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06911680102348328
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.1691200017929077
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.220857620239258
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 10.36720962524414
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04271360039710999
    - config:
        BLOCK_SIZE_B: 128
      time: 0.042966398596763614
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04335359930992126
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04430400133132935
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.045398399233818054
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07696639895439147
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.21857280731201173
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06575359702110291
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06619840264320373
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0670144021511078
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06747199892997742
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06750720143318176
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.13738880157470704
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.3096640110015869
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.047366398572921756
    - config:
        BLOCK_SIZE_B: 1
      time: 0.054150402545928955
    - config:
        BLOCK_SIZE_B: 4
      time: 0.12866560220718384
    - config:
        BLOCK_SIZE_B: 8
      time: 0.6177023887634278
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09402559995651245
    - config:
        BLOCK_SIZE_B: 2
      time: 0.10679999589920045
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6718368053436279
    - config:
        BLOCK_SIZE_B: 8
      time: 1.590118408203125
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04194239974021911
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04196160137653351
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04220159947872162
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04246399998664856
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04269759953022003
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09112640023231507
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.24455039501190184
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06507520079612732
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06590719819068909
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06591039896011353
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06602879762649536
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06711999773979187
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.07483839988708496
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.1659168004989624
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04281600117683411
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04286080002784729
    - config:
        BLOCK_SIZE_B: 1
      time: 0.042921599745750424
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04307200014591217
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0432671993970871
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07069119811058044
    - config:
        BLOCK_SIZE_B: 64
      time: 0.1343135952949524
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0661184012889862
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06615679860115051
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06654080152511596
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06674559712409973
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06709439754486084
    - config:
        BLOCK_SIZE_B: 32
      time: 0.1146623969078064
    - config:
        BLOCK_SIZE_B: 64
      time: 0.31090879440307617
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.042735999822616576
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042771199345588685
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04320000112056732
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04337919950485229
    - config:
        BLOCK_SIZE_B: 64
      time: 0.043609601259231565
    - config:
        BLOCK_SIZE_B: 512
      time: 0.044572800397872925
    - config:
        BLOCK_SIZE_B: 128
      time: 0.044803199172019956
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06599680185317994
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06637120246887207
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06722880005836487
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06724799871444702
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06762880086898804
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06823679804801941
    - config:
        BLOCK_SIZE_B: 512
      time: 0.08069120049476623
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04229120016098022
    - config:
        BLOCK_SIZE_B: 128
      time: 0.043219199776649474
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0434112012386322
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0437855988740921
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0445279985666275
    - config:
        BLOCK_SIZE_B: 512
      time: 0.044784000515937804
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.048291200399398805
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06474879980087281
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06499840021133423
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06503360271453858
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06559680104255676
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06587520241737366
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06724799871444702
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0707264006137848
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07890239953994752
    - config:
        BLOCK_SIZE_B: 2
      time: 0.44905600547790525
    - config:
        BLOCK_SIZE_B: 4
      time: 0.5678751945495606
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.0547103881835938
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2076224327087401
    - config:
        BLOCK_SIZE_B: 4
      time: 2.033110427856445
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04225600063800812
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0426144003868103
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.042694398760795595
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04315840005874634
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04322560131549835
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06272640228271484
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.16270079612731933
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06504960060119629
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06599360108375549
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06621440052986145
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06621760129928589
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0664799988269806
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.1167904019355774
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.26534719467163087
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0426367998123169
    - config:
        BLOCK_SIZE_B: 2
      time: 0.043433600664138795
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04474560022354126
    - config:
        BLOCK_SIZE_B: 1
      time: 0.044819200038909913
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09659199714660645
    - config:
        BLOCK_SIZE_B: 32
      time: 0.17974720001220704
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06610559821128845
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06680960059165955
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06707519888877869
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06804800033569336
    - config:
        BLOCK_SIZE_B: 16
      time: 0.1609503984451294
    - config:
        BLOCK_SIZE_B: 32
      time: 0.36674559116363525
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04179840087890625
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04249280095100403
    - config:
        BLOCK_SIZE_B: 128
      time: 0.042905598878860474
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04337919950485229
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043619200587272644
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04426240026950836
    - config:
        BLOCK_SIZE_B: 256
      time: 0.046460801362991334
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06586560010910034
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06592320203781128
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06632639765739441
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06715520024299622
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06752960085868835
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06924480199813843
    - config:
        BLOCK_SIZE_B: 256
      time: 0.10337920188903808
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04276480078697205
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0432671993970871
    - config:
        BLOCK_SIZE_B: 256
      time: 0.043532800674438474
    - config:
        BLOCK_SIZE_B: 64
      time: 0.043561598658561705
    - config:
        BLOCK_SIZE_B: 128
      time: 0.043609601259231565
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04430400133132935
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04747839868068695
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06523200273513793
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0656000018119812
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06574400067329407
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06579840183258057
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06581760048866273
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06702079772949218
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07663360238075256
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.8830911636352539
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2076479911804199
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 3.0972831726074217
    - config:
        BLOCK_SIZE_B: 1
      time: 3.207900619506836
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04284160137176514
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.043593600392341614
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.043750399351119997
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0438400000333786
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04408319890499115
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.0654367983341217
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.1791200041770935
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06494399905204773
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06582720279693603
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06645439863204956
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06681600213050842
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06682559847831726
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.13820159435272217
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.301311993598938
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04317759871482849
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04516800045967102
    - config:
        BLOCK_SIZE_B: 1
      time: 0.045203199982643126
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07833600044250488
    - config:
        BLOCK_SIZE_B: 16
      time: 0.26519041061401366
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06775680184364319
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06822720170021057
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07003200054168701
    - config:
        BLOCK_SIZE_B: 16
      time: 0.3851680040359497
    - config:
        BLOCK_SIZE_B: 8
      time: 0.39040958881378174
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.042905598878860474
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04291839897632599
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0429504007101059
    - config:
        BLOCK_SIZE_B: 16
      time: 0.042972800135612485
    - config:
        BLOCK_SIZE_B: 2
      time: 0.043059200048446655
    - config:
        BLOCK_SIZE_B: 64
      time: 0.05020800232887268
    - config:
        BLOCK_SIZE_B: 128
      time: 0.10777599811553955
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0645695984363556
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06543999910354614
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0656544029712677
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06617599725723267
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06620479822158813
    - config:
        BLOCK_SIZE_B: 64
      time: 0.101254403591156
    - config:
        BLOCK_SIZE_B: 128
      time: 0.2023711919784546
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0419871985912323
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04240959882736206
    - config:
        BLOCK_SIZE_B: 128
      time: 0.042419201135635375
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04286719858646393
    - config:
        BLOCK_SIZE_B: 16
      time: 0.042991998791694644
    - config:
        BLOCK_SIZE_B: 64
      time: 0.043222400546073916
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04694080054759979
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06532480120658875
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06550719738006591
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06567999720573425
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06568319797515869
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06597440242767334
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06728320121765137
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07417600154876709
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.8167552947998047
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 8.155046081542968
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04232639968395233
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042668798565864564
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.042982399463653564
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04478079974651337
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04674879908561706
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07724159955978394
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.2185983896255493
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06592640280723572
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06625599861145019
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06628479957580566
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0663968026638031
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06690559983253479
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.11176639795303345
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.19601279497146606
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04842880070209503
    - config:
        BLOCK_SIZE_B: 1
      time: 0.053667199611663816
    - config:
        BLOCK_SIZE_B: 4
      time: 0.22859840393066405
    - config:
        BLOCK_SIZE_B: 8
      time: 0.45858240127563477
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09177280068397523
    - config:
        BLOCK_SIZE_B: 2
      time: 0.4620960235595703
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6096672058105469
    - config:
        BLOCK_SIZE_B: 8
      time: 0.902524757385254
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.042534399032592776
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.042921599745750424
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04375360012054443
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04402880072593689
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04455040097236633
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.07558079957962036
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.16365760564804077
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.057545602321624756
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.0582368016242981
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.058432000875473025
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.059824001789093015
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.060969597101211546
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.08194239735603333
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.23121280670166017
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04129599928855896
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0419295996427536
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04223040044307709
    - config:
        BLOCK_SIZE_B: 4
      time: 0.042847999930381776
    - config:
        BLOCK_SIZE_B: 16
      time: 0.05374720096588135
    - config:
        BLOCK_SIZE_B: 32
      time: 0.11040320396423339
    - config:
        BLOCK_SIZE_B: 64
      time: 0.2889247894287109
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.05786240100860596
    - config:
        BLOCK_SIZE_B: 4
      time: 0.05797119736671448
    - config:
        BLOCK_SIZE_B: 1
      time: 0.058710402250289916
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05920640230178833
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09290559887886048
    - config:
        BLOCK_SIZE_B: 32
      time: 0.14862719774246216
    - config:
        BLOCK_SIZE_B: 64
      time: 0.3330496072769165
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04106239974498749
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04126720130443573
    - config:
        BLOCK_SIZE_B: 16
      time: 0.041552001237869264
    - config:
        BLOCK_SIZE_B: 64
      time: 0.042153599858284
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04216319918632507
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04280000030994415
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0776639997959137
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.05807999968528747
    - config:
        BLOCK_SIZE_B: 8
      time: 0.05894399881362915
    - config:
        BLOCK_SIZE_B: 16
      time: 0.058963197469711306
    - config:
        BLOCK_SIZE_B: 64
      time: 0.05936319828033447
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06038399934768677
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06604160070419311
    - config:
        BLOCK_SIZE_B: 512
      time: 0.11663039922714233
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04072319865226746
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04129279851913452
    - config:
        BLOCK_SIZE_B: 64
      time: 0.041731199622154234
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04221439957618713
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04251520037651062
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04506880044937134
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.056822401285171506
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.05760319828987122
    - config:
        BLOCK_SIZE_B: 64
      time: 0.05780799984931946
    - config:
        BLOCK_SIZE_B: 256
      time: 0.05840319991111755
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.059087997674942015
    - config:
        BLOCK_SIZE_B: 128
      time: 0.05974079966545105
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06076800227165222
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.11553599834442138
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.14552320241928102
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2901727676391601
    - config:
        BLOCK_SIZE_B: 4
      time: 1.7277759552001952
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.6970399856567382
    - config:
        BLOCK_SIZE_B: 2
      time: 2.0040351867675783
    - config:
        BLOCK_SIZE_B: 4
      time: 3.38177604675293
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04138559997081757
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04141440093517303
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04159039855003357
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04178560078144074
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.043731200695037845
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04659520089626312
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.2671776056289673
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.057846397161483765
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.05934079885482788
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.05936639904975891
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06040639877319336
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06203839778900146
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.09104959964752198
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.3309184074401855
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04176959991455078
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04232639968395233
    - config:
        BLOCK_SIZE_B: 4
      time: 0.042505601048469545
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04275520145893097
    - config:
        BLOCK_SIZE_B: 16
      time: 0.16631679534912108
    - config:
        BLOCK_SIZE_B: 32
      time: 0.24946880340576172
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.05898560285568237
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05915200114250183
    - config:
        BLOCK_SIZE_B: 1
      time: 0.060096001625061034
    - config:
        BLOCK_SIZE_B: 8
      time: 0.21125440597534179
    - config:
        BLOCK_SIZE_B: 16
      time: 0.24379520416259765
    - config:
        BLOCK_SIZE_B: 32
      time: 0.4031775951385498
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04129599928855896
    - config:
        BLOCK_SIZE_B: 8
      time: 0.041443198919296265
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0419840008020401
    - config:
        BLOCK_SIZE_B: 4
      time: 0.042185598611831666
    - config:
        BLOCK_SIZE_B: 64
      time: 0.043270400166511534
    - config:
        BLOCK_SIZE_B: 128
      time: 0.05104320049285889
    - config:
        BLOCK_SIZE_B: 256
      time: 0.16015039682388305
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.056959998607635495
    - config:
        BLOCK_SIZE_B: 4
      time: 0.05851200222969055
    - config:
        BLOCK_SIZE_B: 8
      time: 0.05864319801330566
    - config:
        BLOCK_SIZE_B: 32
      time: 0.05952960252761841
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06115840077400207
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07358400225639343
    - config:
        BLOCK_SIZE_B: 256
      time: 0.24410240650177
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.041510400176048276
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04210880100727081
    - config:
        BLOCK_SIZE_B: 32
      time: 0.042268800735473636
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0424703985452652
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04262720048427582
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04293760061264038
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06677759885787964
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.05803520083427429
    - config:
        BLOCK_SIZE_B: 64
      time: 0.05815039873123169
    - config:
        BLOCK_SIZE_B: 256
      time: 0.05869119763374329
    - config:
        BLOCK_SIZE_B: 512
      time: 0.059308797121047974
    - config:
        BLOCK_SIZE_B: 32
      time: 0.059359997510910034
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06469759941101075
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.10486719608306885
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.7372768402099608
    - config:
        BLOCK_SIZE_B: 2
      time: 3.5326942443847655
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 4.369753646850586
    - config:
        BLOCK_SIZE_B: 2
      time: 5.231856155395508
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04092159867286682
    - config:
        BLOCK_SIZE_B: 256
      time: 0.041631999611854556
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04283199906349182
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04316799938678741
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04343039989471435
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.049091199040412904
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.3422080039978027
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.05900480151176453
    - config:
        BLOCK_SIZE_B: 256
      time: 0.059059202671051025
    - config:
        BLOCK_SIZE_B: 512
      time: 0.05906879901885986
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.059961599111557004
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.062028801441192626
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.09591680169105529
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.2641119956970215
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.043696001172065735
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04414080083370209
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04559360146522522
    - config:
        BLOCK_SIZE_B: 8
      time: 0.2699295997619629
    - config:
        BLOCK_SIZE_B: 16
      time: 0.3252768039703369
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06510400176048278
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06879680156707764
    - config:
        BLOCK_SIZE_B: 4
      time: 0.38542399406433103
    - config:
        BLOCK_SIZE_B: 8
      time: 0.5671679973602295
    - config:
        BLOCK_SIZE_B: 16
      time: 0.5911712169647216
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04111360013484955
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04222719967365265
    - config:
        BLOCK_SIZE_B: 16
      time: 0.042508798837661746
    - config:
        BLOCK_SIZE_B: 8
      time: 0.042659199237823485
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04888319969177246
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10985599756240845
    - config:
        BLOCK_SIZE_B: 128
      time: 0.18886079788208007
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.05706560015678406
    - config:
        BLOCK_SIZE_B: 4
      time: 0.05730239748954773
    - config:
        BLOCK_SIZE_B: 16
      time: 0.05809280276298523
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0586143970489502
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06916800141334534
    - config:
        BLOCK_SIZE_B: 64
      time: 0.11495039463043213
    - config:
        BLOCK_SIZE_B: 128
      time: 0.2286367893218994
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04093759953975677
    - config:
        BLOCK_SIZE_B: 64
      time: 0.041596800088882446
    - config:
        BLOCK_SIZE_B: 128
      time: 0.041875201463699344
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04189760088920593
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04194239974021911
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04379200041294098
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06902080178260803
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.05702080130577088
    - config:
        BLOCK_SIZE_B: 16
      time: 0.057785600423812866
    - config:
        BLOCK_SIZE_B: 64
      time: 0.05783039927482605
    - config:
        BLOCK_SIZE_B: 256
      time: 0.058316802978515624
    - config:
        BLOCK_SIZE_B: 128
      time: 0.05867519974708557
    - config:
        BLOCK_SIZE_B: 512
      time: 0.059945601224899295
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.10974080562591552
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 7.555574035644531
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 10.468736267089843
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04230400025844574
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04238399863243103
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04264959990978241
    - config:
        BLOCK_SIZE_B: 128
      time: 0.043350398540496826
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.044409599900245664
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06312639713287353
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.2712831974029541
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.05693119764328003
    - config:
        BLOCK_SIZE_B: 256
      time: 0.057545602321624756
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0581055998802185
    - config:
        BLOCK_SIZE_B: 512
      time: 0.058355200290679934
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.05994240045547485
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.10581120252609252
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.28752961158752444
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0723136007785797
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07516160011291503
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6298719882965088
    - config:
        BLOCK_SIZE_B: 8
      time: 0.7890719890594482
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.11259520053863525
    - config:
        BLOCK_SIZE_B: 2
      time: 0.6722591876983642
    - config:
        BLOCK_SIZE_B: 4
      time: 0.90098876953125
    - config:
        BLOCK_SIZE_B: 8
      time: 1.397715187072754
  kernels/rmsnorm/triton_implementation/__init__.py->rmsnorm_forward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.032918399572372435
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033846399188041686
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03422400057315826
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.034668800234794614
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03500480055809021
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04681600034236908
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.0952351987361908
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.036617600917816163
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03678399920463562
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03685120046138764
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.037238401174545285
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03754880130290985
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.05257279872894287
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.10920319557189942
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03331519961357117
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03418239951133728
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03424960076808929
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0344895988702774
    - config:
        BLOCK_SIZE_B: 16
      time: 0.034595200419425966
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03462719917297363
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04952319860458374
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0364767998456955
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03670719861984253
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03675839900970459
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03805440068244934
    - config:
        BLOCK_SIZE_B: 2
      time: 0.038115200400352475
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03850559890270233
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0395552009344101
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.033164799213409424
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033632001280784606
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03391680121421814
    - config:
        BLOCK_SIZE_B: 16
      time: 0.034006398916244504
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0343423992395401
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03451519906520843
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03452799916267395
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0361407995223999
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036550399661064145
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03660480082035065
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036883199214935304
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03695679903030395
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037001600861549376
    - config:
        BLOCK_SIZE_B: 512
      time: 0.038140800595283506
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03308799862861633
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03311040103435516
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033180800080299375
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03340159952640533
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03345920145511627
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03371520042419433
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04796159863471985
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03580479919910431
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03624320030212402
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0366784006357193
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03698239922523498
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03732799887657166
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0374752014875412
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03838399946689606
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05203199982643127
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05216320157051087
    - config:
        BLOCK_SIZE_B: 4
      time: 0.3043231964111328
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.055379199981689456
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05942720174789429
    - config:
        BLOCK_SIZE_B: 4
      time: 0.4497568130493164
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03301439881324768
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0334879994392395
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03366400003433227
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03463039994239807
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.035971200466156004
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.049065598845481874
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09916800260543823
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03763839900493622
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03799999952316284
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03799999952316284
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.038192000985145566
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03841919898986816
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.05058240294456482
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.10114560127258301
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03325439989566803
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03366400003433227
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03394879996776581
    - config:
        BLOCK_SIZE_B: 8
      time: 0.034067198634147644
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03412159979343414
    - config:
        BLOCK_SIZE_B: 32
      time: 0.047295999526977536
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03726080060005188
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037385600805282596
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03738879859447479
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03764159977436066
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03776960074901581
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03800640106201172
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03272959887981415
    - config:
        BLOCK_SIZE_B: 128
      time: 0.032915198802948
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033103999495506284
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03383040130138397
    - config:
        BLOCK_SIZE_B: 8
      time: 0.034134399890899655
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034179198741912845
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03469760119915009
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03628160059452057
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03630079925060272
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03635840117931366
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036847999691963194
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03724479973316193
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03785600066184998
    - config:
        BLOCK_SIZE_B: 32
      time: 0.038192000985145566
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.032579201459884646
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03333759903907776
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033980798721313474
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.034255999326705935
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0346560001373291
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03518719971179962
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04604479968547821
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.036601600050926206
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03692159950733185
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03708159923553467
    - config:
        BLOCK_SIZE_B: 128
      time: 0.037206399440765384
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03738879859447479
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.038201600313186646
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03836480081081391
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09559040069580078
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7214591979980469
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.1351423978805542
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7728159904479981
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.033129599690437314
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033164799213409424
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033327999711036685
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0343968003988266
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.035209599137306216
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05396159887313843
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.1465824007987976
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0364544004201889
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03682560026645661
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03691520094871521
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.037049600481987
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03760640025138855
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05966399908065796
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.15079360008239745
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.033215999603271484
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033404800295829776
    - config:
        BLOCK_SIZE_B: 1
      time: 0.033504000306129454
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0344895988702774
    - config:
        BLOCK_SIZE_B: 16
      time: 0.048259198665618896
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.037564799189567566
    - config:
        BLOCK_SIZE_B: 2
      time: 0.038252800703048706
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03840320110321045
    - config:
        BLOCK_SIZE_B: 1
      time: 0.038780799508094786
    - config:
        BLOCK_SIZE_B: 16
      time: 0.049439999461174014
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.032576000690460204
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033103999495506284
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033107200264930726
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033199998736381534
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03372800052165985
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033827200531959534
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036022400856018065
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03600960075855255
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03614400029182434
    - config:
        BLOCK_SIZE_B: 2
      time: 0.036575999855995175
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03681600093841553
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03776319921016693
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03783040046691895
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03909119963645935
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.032716798782348636
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0328031986951828
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03293440043926239
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033046400547027587
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033139199018478394
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033267199993133545
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03383359909057617
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03663040101528168
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036857599020004274
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03728959858417511
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03729279935359955
    - config:
        BLOCK_SIZE_B: 16
      time: 0.037859201431274414
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0379936009645462
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03824959993362427
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.5726047992706299
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.2017023086547853
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03289920091629028
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03373759984970093
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03386560082435608
    - config:
        BLOCK_SIZE_B: 512
      time: 0.034959998726844785
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03509120047092438
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06509439945220948
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17742400169372557
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03697279989719391
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03704639971256256
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03709439933300018
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03731519877910614
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03806079924106598
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06572160124778748
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.1781216025352478
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03588800132274628
    - config:
        BLOCK_SIZE_B: 1
      time: 0.035913598537445066
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036185601353645326
    - config:
        BLOCK_SIZE_B: 8
      time: 0.14315199851989746
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03896960020065308
    - config:
        BLOCK_SIZE_B: 2
      time: 0.039299198985099794
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03961600065231323
    - config:
        BLOCK_SIZE_B: 8
      time: 0.13864959478378297
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03301759958267212
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.033616000413894655
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0336896002292633
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03394559919834137
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.034179198741912845
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.038073599338531494
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.06450240015983581
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03652800023555756
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.036668801307678224
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0368800014257431
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03691200017929077
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.037462401390075686
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04535039961338043
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.09381440281867981
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03246079981327057
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03298879861831665
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033292800188064575
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033744001388549806
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03421759903430939
    - config:
        BLOCK_SIZE_B: 1
      time: 0.034560000896453856
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0520799994468689
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0361952006816864
    - config:
        BLOCK_SIZE_B: 1
      time: 0.036697599291801455
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03671039938926697
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03677760064601898
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03713279962539673
    - config:
        BLOCK_SIZE_B: 2
      time: 0.037302398681640626
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037894400954246524
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03272640109062195
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033580800890922545
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03394559919834137
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033990401029586795
    - config:
        BLOCK_SIZE_B: 16
      time: 0.034646400809288026
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03466239869594574
    - config:
        BLOCK_SIZE_B: 512
      time: 0.046348801255226134
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0366784006357193
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03675839900970459
    - config:
        BLOCK_SIZE_B: 128
      time: 0.037411201000213626
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03800320029258728
    - config:
        BLOCK_SIZE_B: 16
      time: 0.038038399815559384
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03973760008811951
    - config:
        BLOCK_SIZE_B: 512
      time: 0.045840001106262206
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03298240005970001
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03307519853115082
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033225598931312564
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033542400598526
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03362239897251129
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0336896002292633
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03840320110321045
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03660799860954285
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0367680013179779
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03711679875850678
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.037894400954246524
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03813759982585907
    - config:
        BLOCK_SIZE_B: 64
      time: 0.039324799180030824
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.042985600233078
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.048742398619651794
    - config:
        BLOCK_SIZE_B: 2
      time: 0.050780802965164185
    - config:
        BLOCK_SIZE_B: 4
      time: 0.24862079620361327
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.055088001489639285
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05732799768447876
    - config:
        BLOCK_SIZE_B: 4
      time: 0.3271199941635132
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03301759958267212
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03345920145511627
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.033983999490737916
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03400000035762787
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03473919928073883
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.05028480291366577
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09924160242080689
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03614720106124878
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03685120046138764
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03764159977436066
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.037859201431274414
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03915840089321136
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.05247359871864319
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.10117759704589843
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03259199857711792
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03301439881324768
    - config:
        BLOCK_SIZE_B: 1
      time: 0.034201601147651674
    - config:
        BLOCK_SIZE_B: 32
      time: 0.034822401404380796
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03484480082988739
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03518719971179962
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03698239922523498
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03738240003585815
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03740800023078918
    - config:
        BLOCK_SIZE_B: 2
      time: 0.037625598907470706
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0387935996055603
    - config:
        BLOCK_SIZE_B: 32
      time: 0.039392000436782836
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03252480030059814
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033190399408340454
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03329919874668121
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03346880078315735
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033667200803756715
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03391999900341034
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034620800614356996
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0364767998456955
    - config:
        BLOCK_SIZE_B: 32
      time: 0.036627200245857236
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03698880076408386
    - config:
        BLOCK_SIZE_B: 128
      time: 0.037350401282310486
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03742400109767914
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03745599985122681
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03795199990272522
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033078399300575254
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033107200264930726
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03359679877758026
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033792001008987424
    - config:
        BLOCK_SIZE_B: 128
      time: 0.033795198798179625
    - config:
        BLOCK_SIZE_B: 512
      time: 0.034041601419448855
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04315840005874634
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.035897600650787356
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036099201440811156
    - config:
        BLOCK_SIZE_B: 512
      time: 0.036323198676109315
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03648000061511993
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03740800023078918
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037750399112701415
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03939520120620728
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0952351987361908
    - config:
        BLOCK_SIZE_B: 2
      time: 0.422438383102417
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.1315392017364502
    - config:
        BLOCK_SIZE_B: 2
      time: 0.6874720096588135
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03347519934177399
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.033692800998687746
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033817601203918454
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03386879861354828
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03442879915237427
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.053711998462677005
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.1467360019683838
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03673279881477356
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03685440123081207
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.038166400790214536
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03823040127754211
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03862079977989197
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05570240020751953
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.15073599815368652
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03230080008506775
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033241599798202515
    - config:
        BLOCK_SIZE_B: 2
      time: 0.033897599577903746
    - config:
        BLOCK_SIZE_B: 1
      time: 0.034483200311660765
    - config:
        BLOCK_SIZE_B: 16
      time: 0.05251839756965637
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03659200072288513
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03682880103588104
    - config:
        BLOCK_SIZE_B: 4
      time: 0.037231999635696414
    - config:
        BLOCK_SIZE_B: 1
      time: 0.038211199641227725
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04913600087165833
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0321727991104126
    - config:
        BLOCK_SIZE_B: 64
      time: 0.032252800464630124
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03254719972610474
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03270399868488312
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03273600041866302
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033369600772857666
    - config:
        BLOCK_SIZE_B: 128
      time: 0.035436800122261046
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03561919927597046
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03614720106124878
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03617599904537201
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036329600214958194
    - config:
        BLOCK_SIZE_B: 2
      time: 0.037273600697517395
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03839359879493713
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03909760117530823
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03289600014686585
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03299840092658997
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03352000117301941
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033744001388549806
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03418880105018616
    - config:
        BLOCK_SIZE_B: 32
      time: 0.034220799803733826
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.041315200924873355
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03617599904537201
    - config:
        BLOCK_SIZE_B: 128
      time: 0.036233600974082944
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03665919899940491
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03673279881477356
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03706879913806915
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03768959939479828
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.039631998538970946
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.5786431789398193
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.3081151962280273
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03315840065479279
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03337279856204987
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03351039886474609
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03351680040359497
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03384959995746613
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06528639793395996
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17752000093460082
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03589119911193848
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03686720132827759
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03694080114364624
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03761920034885406
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03771199882030487
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06579840183258057
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17800320386886598
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03400959968566895
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03567039966583252
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03601279854774475
    - config:
        BLOCK_SIZE_B: 8
      time: 0.10977280139923096
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0377344012260437
    - config:
        BLOCK_SIZE_B: 1
      time: 0.038211199641227725
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03861759901046753
    - config:
        BLOCK_SIZE_B: 8
      time: 0.09781759977340698
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.033327999711036685
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03335039913654327
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033846399188041686
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03405439853668213
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03746559917926788
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.03917120099067688
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.08884159922599792
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03639039993286133
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03664959967136383
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03672960102558136
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03713279962539673
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.0379584014415741
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.03961920142173767
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.0630623996257782
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0323168009519577
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03297280073165894
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033020800352096556
    - config:
        BLOCK_SIZE_B: 1
      time: 0.033228799700737
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03324800133705139
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033327999711036685
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07775679826736451
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03554239869117737
    - config:
        BLOCK_SIZE_B: 1
      time: 0.036134400963783266
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036134400963783266
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03622080087661743
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03625600039958954
    - config:
        BLOCK_SIZE_B: 32
      time: 0.036646398901939395
    - config:
        BLOCK_SIZE_B: 64
      time: 0.08878719806671143
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.032543998956680295
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03283199965953827
    - config:
        BLOCK_SIZE_B: 128
      time: 0.032953599095344545
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03298240005970001
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03377600014209747
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03449600040912628
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06364480257034302
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03614720106124878
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03654719889163971
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03668160140514374
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03708159923553467
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037257599830627444
    - config:
        BLOCK_SIZE_B: 128
      time: 0.038441601395607
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0703328013420105
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.032528001070022586
    - config:
        BLOCK_SIZE_B: 64
      time: 0.032688000798225404
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033232000470161435
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03341760039329529
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03349440097808838
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03526400029659271
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.05485439896583557
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03634240031242371
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03687680065631867
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03700799942016601
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03717440068721771
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03758719861507416
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03894400000572205
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.05273280143737793
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09335039854049683
    - config:
        BLOCK_SIZE_B: 2
      time: 0.10062719583511352
    - config:
        BLOCK_SIZE_B: 4
      time: 0.3791327953338623
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.10156480073928834
    - config:
        BLOCK_SIZE_B: 4
      time: 0.4459231853485107
    - config:
        BLOCK_SIZE_B: 2
      time: 0.5226175785064697
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0325984001159668
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03282240033149719
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03307200074195862
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03343360126018524
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03433600068092346
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04924800097942352
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09376639723777772
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.036287999153137206
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0369951993227005
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03733760118484497
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03736959993839264
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03789120018482208
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.050780802965164185
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09679359793663025
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.032502400875091556
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03277119994163513
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03328959941864014
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03357439935207367
    - config:
        BLOCK_SIZE_B: 1
      time: 0.034415999054908754
    - config:
        BLOCK_SIZE_B: 32
      time: 0.10286719799041748
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03577280044555664
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0361631989479065
    - config:
        BLOCK_SIZE_B: 16
      time: 0.036976000666618346
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03698880076408386
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03715839982032776
    - config:
        BLOCK_SIZE_B: 32
      time: 0.12690880298614501
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.032332798838615416
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03287039995193482
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033504000306129454
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03380799889564514
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03405120074748993
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03572799861431122
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0725920021533966
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03612479865550995
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03647040128707886
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036617600917816163
    - config:
        BLOCK_SIZE_B: 16
      time: 0.036617600917816163
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036620798707008365
    - config:
        BLOCK_SIZE_B: 128
      time: 0.038822400569915774
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0766592025756836
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03224959969520569
    - config:
        BLOCK_SIZE_B: 512
      time: 0.032476800680160525
    - config:
        BLOCK_SIZE_B: 64
      time: 0.032543998956680295
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0333759993314743
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033881598711013795
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03617919981479645
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.05474240183830261
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.035708799958229065
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03595199882984161
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03606399893760681
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03637759983539581
    - config:
        BLOCK_SIZE_B: 32
      time: 0.036425599455833436
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03791680037975311
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06382079720497132
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.19552960395812988
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7724671840667725
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 1.0730912208557128
    - config:
        BLOCK_SIZE_B: 1
      time: 1.0786848068237305
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03201920092105866
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03229120075702667
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.033139199018478394
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033190399408340454
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03335039913654327
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05334399938583374
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.10831680297851562
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.02733759880065918
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.035939198732376096
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03594239950180054
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03601599931716919
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037513598799705505
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05342400074005127
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.10724159479141235
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033820798993110655
    - config:
        BLOCK_SIZE_B: 2
      time: 0.034307199716567996
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03446080088615418
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03459199965000152
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09849920272827148
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.037062400579452516
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03777920007705689
    - config:
        BLOCK_SIZE_B: 8
      time: 0.037833601236343384
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03790720105171204
    - config:
        BLOCK_SIZE_B: 16
      time: 0.15526080131530762
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03240639865398407
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03248319923877716
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03257279992103577
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03282879889011383
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03338559865951538
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033817601203918454
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0774944007396698
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03592639863491058
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03633599877357483
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03648959994316101
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03652800023555756
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03688639998435974
    - config:
        BLOCK_SIZE_B: 64
      time: 0.040252798795700075
    - config:
        BLOCK_SIZE_B: 128
      time: 0.05996479988098145
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.032543998956680295
    - config:
        BLOCK_SIZE_B: 64
      time: 0.032713600993156434
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033504000306129454
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03362880051136017
    - config:
        BLOCK_SIZE_B: 128
      time: 0.033718401193618776
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0387584000825882
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06365119814872741
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03641600012779236
    - config:
        BLOCK_SIZE_B: 512
      time: 0.036559998989105225
    - config:
        BLOCK_SIZE_B: 16
      time: 0.036585599184036255
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03670400083065033
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03672960102558136
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037283200025558474
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.061660802364349364
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.6005184173583984
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.0223520278930662
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.032579201459884646
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0331712007522583
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03319360017776489
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03412480056285858
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03418239951133728
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06398079991340637
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17551039457321166
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03603520095348358
    - config:
        BLOCK_SIZE_B: 256
      time: 0.036233600974082944
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03738879859447479
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037510401010513304
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.037625598907470706
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06509760022163391
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.16657919883728028
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04731520116329193
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04834559857845307
    - config:
        BLOCK_SIZE_B: 4
      time: 0.05233280062675476
    - config:
        BLOCK_SIZE_B: 8
      time: 0.1826207995414734
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.049584001302719116
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04979200065135956
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06731520295143127
    - config:
        BLOCK_SIZE_B: 8
      time: 0.2452159881591797
  kernels/swiglu/backward.py->_backward:
    '''gate.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.280182409286499
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.2814687967300415
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.2815776109695435
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.28198719024658203
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.2822655916213989
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.2822943925857544
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.2826240062713623
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.2827455997467041
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.29006400108337405
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2957535982131958
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.307587194442749
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.36557118892669677
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.49695358276367185
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.5978367805480957
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9880000114440918
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 3.8822048187255858
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 4.073737716674804
    '''gate.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.27863359451293945
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.27946879863739016
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.2795072078704834
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.27974400520324705
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.2798111915588379
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.2804192066192627
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.28048319816589357
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.2805824041366577
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.28748478889465334
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.29478399753570556
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.3065664052963257
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.3168895959854126
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.4970079898834229
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.5349760055541992
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9882752418518066
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 3.5821792602539064
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 3.6368991851806642
    '''gate.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.5528128147125244
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.5542143821716309
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.5542816162109375
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.5544767856597901
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.555017614364624
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.5557055950164795
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.5562719821929931
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.5587615966796875
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.5603328227996827
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.5810880184173584
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.5818528175354004
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.598364782333374
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.9206368446350097
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.99169921875
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 1.2163616180419923
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 4.7525184631347654
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 4.8697246551513675
  kernels/swiglu/forward.py->_forward:
    '''gate.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14096959829330444
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.14154560565948487
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.14244480133056642
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.1428320050239563
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.14685120582580566
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.1496384024620056
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.2023616075515747
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.2025984048843384
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.20293760299682617
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.20479040145874022
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 0.21462719440460204
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.22535359859466553
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.25013759136199953
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.25307838916778563
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.4954527854919434
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9876447677612304
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 1.1537343978881835
    '''gate.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14080959558486938
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.14137599468231202
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.14262720346450805
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.14652479887008668
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.14719680547714234
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.1569983959197998
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.19916160106658937
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.19940799474716187
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.1994207978248596
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.20157439708709718
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 0.20653440952301025
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.22195839881896973
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.2501471996307373
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.25290560722351074
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.4954080104827881
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.9880000114440918
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 1.1541279792785644
    '''gate.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.27783679962158203
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.2786175966262817
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
      time: 0.27880001068115234
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
      time: 0.27900478839874265
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
      time: 0.2814591884613037
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
      time: 0.28244481086730955
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
      time: 0.28445119857788087
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.28705921173095705
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
      time: 0.2935647964477539
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
      time: 0.3032576084136963
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
      time: 0.30900800228118896
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
      time: 0.3499423980712891
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
      time: 0.49666562080383303
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
      time: 0.49667840003967284
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
      time: 0.987446403503418
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
      time: 1.9815872192382813
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
      time: 2.0561471939086915
  kernels/swiglu_unchunked/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.561075210571289
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.019500732421875
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 3.2445472717285155
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.520179748535156
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.6565185546875
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5318240165710448
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.730169677734375
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.7504831314086915
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.876002502441406
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.17188415527344
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.6106592178344727
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 3.2027328491210936
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 5.672396850585938
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.08976593017578
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.337437438964844
  kernels/swiglu_unchunked/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9556544303894043
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9559167861938477
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.0468576431274415
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.3300895690917969
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 6.212371063232422
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9421216011047363
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9481856346130371
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.0431296348571777
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.252950382232666
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 6.156748962402344
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.574227237701416
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.6340255737304688
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.8550239562988282
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 8.698524475097656
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 8.71081314086914
best_configs:
  kernels/add/add_scalar/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14135680198669434
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.140719997882843
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2779968023300171
  kernels/add/add_tensor/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14080640077590942
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14049919843673705
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778239965438843
  kernels/embedding/backward.py->_backward:
    '''weight.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.265776062011719
    '''weight.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 3.5257919311523436
    '''weight.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 9.810809326171874
  kernels/embedding/forward.py->_forward:
    '''weight.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6666336059570312
    '''weight.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6664063930511475
    '''weight.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.3737183570861817
  kernels/rmsnorm/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float32''':
      config:
        kernel_backend: triton
      time: 0
  kernels/rmsnorm/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float32''':
      config:
        kernel_backend: triton
      time: 0
  kernels/rmsnorm/triton_implementation/__init__.py->rmsnorm_backward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.042947199940681455
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.06512640118598938
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04362240135669708
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.06558719873428345
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.04211840033531189
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06593599915504456
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04192639887332916
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.06518080234527587
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07920960187911988
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 1.543337631225586
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04151360094547272
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.06446080207824707
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04355199933052063
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.06755520105361938
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.04167360067367554
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.06513599753379821
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04201599955558777
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06455039978027344
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.1104191780090331
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 3.6815200805664063
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04296000003814697
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.06480960249900818
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04576959908008575
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06919040083885193
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04220480024814606
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06567360162734985
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.04195519983768463
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.06582720279693603
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.220857620239258
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 10.36720962524414
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.04271360039710999
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.06575359702110291
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.047366398572921756
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09402559995651245
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.04194239974021911
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.06507520079612732
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04281600117683411
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.0661184012889862
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.042735999822616576
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06599680185317994
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04229120016098022
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.06474879980087281
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07890239953994752
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.0547103881835938
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04225600063800812
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.06504960060119629
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.0426367998123169
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06610559821128845
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04179840087890625
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.06586560010910034
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04276480078697205
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.06523200273513793
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.8830911636352539
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 3.0972831726074217
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.04284160137176514
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.06494399905204773
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04317759871482849
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.06775680184364319
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.042905598878860474
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.0645695984363556
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.0419871985912323
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06532480120658875
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.8167552947998047
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 8.155046081542968
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.04232639968395233
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.06592640280723572
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04842880070209503
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09177280068397523
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.042534399032592776
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.057545602321624756
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04129599928855896
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.05786240100860596
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04106239974498749
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.05807999968528747
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04072319865226746
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.05760319828987122
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.14552320241928102
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.6970399856567382
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04138559997081757
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.057846397161483765
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04176959991455078
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.05898560285568237
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04129599928855896
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.056959998607635495
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.041510400176048276
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.05803520083427429
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.7372768402099608
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 4.369753646850586
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.04092159867286682
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.05900480151176453
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.043696001172065735
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06510400176048278
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04111360013484955
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.05706560015678406
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04093759953975677
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.05702080130577088
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 7.555574035644531
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 10.468736267089843
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04230400025844574
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.05693119764328003
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.0723136007785797
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.11259520053863525
  kernels/rmsnorm/triton_implementation/__init__.py->rmsnorm_forward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.032918399572372435
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.036617600917816163
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03331519961357117
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.0364767998456955
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.033164799213409424
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.0361407995223999
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03308799862861633
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03580479919910431
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.05203199982643127
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.055379199981689456
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03301439881324768
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03763839900493622
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03325439989566803
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03726080060005188
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03272959887981415
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03628160059452057
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.032579201459884646
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.036601600050926206
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09559040069580078
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.1351423978805542
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.033129599690437314
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.0364544004201889
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.033215999603271484
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.037564799189567566
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.032576000690460204
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03600960075855255
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.032716798782348636
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03663040101528168
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.5726047992706299
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.2017023086547853
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03289920091629028
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03697279989719391
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03588800132274628
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.03896960020065308
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.03301759958267212
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.03652800023555756
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03246079981327057
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.0361952006816864
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03272640109062195
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.0366784006357193
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03298240005970001
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03660799860954285
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.048742398619651794
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.055088001489639285
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03301759958267212
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03614720106124878
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03259199857711792
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03698239922523498
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03252480030059814
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.0364767998456955
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.033078399300575254
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.035897600650787356
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.0952351987361908
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.1315392017364502
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03347519934177399
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03673279881477356
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03230080008506775
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03659200072288513
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.0321727991104126
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03561919927597046
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03289600014686585
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03617599904537201
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.5786431789398193
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.3081151962280273
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03315840065479279
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03589119911193848
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03400959968566895
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.0377344012260437
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.033327999711036685
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03639039993286133
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.0323168009519577
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03554239869117737
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.032543998956680295
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03614720106124878
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.032528001070022586
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03634240031242371
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09335039854049683
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.10156480073928834
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.0325984001159668
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.036287999153137206
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.032502400875091556
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03577280044555664
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.032332798838615416
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03612479865550995
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03224959969520569
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.035708799958229065
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.19552960395812988
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 1.0730912208557128
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03201920092105866
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.02733759880065918
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.033820798993110655
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.037062400579452516
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03240639865398407
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03592639863491058
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.032543998956680295
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03641600012779236
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.6005184173583984
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.0223520278930662
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.032579201459884646
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03603520095348358
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04731520116329193
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.049584001302719116
  kernels/swiglu/backward.py->_backward:
    '''gate.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.280182409286499
    '''gate.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.27863359451293945
    '''gate.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 256
        kernel_backend: triton
      time: 0.5528128147125244
  kernels/swiglu/forward.py->_forward:
    '''gate.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14096959829330444
    '''gate.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
      time: 0.14080959558486938
    '''gate.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: triton
      time: 0.27783679962158203
  kernels/swiglu_unchunked/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.561075210571289
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5318240165710448
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.6106592178344727
  kernels/swiglu_unchunked/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9556544303894043
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9421216011047363
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.574227237701416
