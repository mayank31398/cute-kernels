all_configs:
  kernels/add/add_scalar/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14110080003738404
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1412927985191345
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14132800102233886
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1413472056388855
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14135040044784547
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14149760007858275
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14152640104293823
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.141702401638031
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1419648051261902
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14207040071487426
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14264320135116576
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14424959421157837
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14583359956741332
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14797120094299315
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14909759759902955
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1527392029762268
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15885759592056276
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.1839967966079712
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20202879905700682
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.22961599826812745
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.24980480670928956
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2498944044113159
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.24996480941772461
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.25056641101837157
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.303273606300354
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.33339519500732423
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38121919631958007
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49619197845458984
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49657278060913085
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4965856075286865
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49669442176818845
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9899616241455078
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9901632308959961
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9904607772827149
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9779647827148437
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14096319675445557
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14128639698028564
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1414240002632141
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1415071964263916
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14156160354614258
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14157119989395142
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1419584035873413
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14233280420303346
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1424512028694153
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1427135944366455
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1432255983352661
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14446719884872436
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1459712028503418
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14704960584640503
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.148198401927948
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15247039794921874
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15863679647445678
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.1838912010192871
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20211520195007324
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.22968640327453613
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2499743938446045
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2500256061553955
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.25036799907684326
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2505023956298828
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30375359058380125
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.33351359367370603
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3810080051422119
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49633278846740725
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49640641212463377
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49661760330200194
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4968832015991211
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9901311874389649
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.990550422668457
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9906144142150879
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9785215377807617
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27802879810333253
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2783071994781494
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27832319736480715
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27850239276885985
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2787359952926636
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2788064002990723
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2790015935897827
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28042240142822267
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28128321170806886
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28173439502716063
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28240959644317626
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28455679416656493
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2870016098022461
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2915328025817871
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2954303979873657
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3012415885925293
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3129791975021362
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.35760960578918455
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.39092800617218015
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.43757119178771975
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49564480781555176
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49568638801574705
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4962656021118164
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49689598083496095
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9715871810913086
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9872991561889648
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.987548828125
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9877599716186524
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9717344284057616
  kernels/add/add_tensor/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14098880290985108
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14103360176086427
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14107199907302856
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14122560024261474
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14128960371017457
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14166079759597777
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14185600280761718
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14191999435424804
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14192960262298585
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14207359552383422
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14231679439544678
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1445919990539551
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14612159729003907
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1480031967163086
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15276479721069336
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15911359786987306
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18374719619750976
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20214080810546875
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.22938239574432373
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2498944044113159
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.25005760192871096
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.25013439655303954
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.25057599544525144
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.30585920810699463
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.33730878829956057
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38615999221801756
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4962399959564209
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49643521308898925
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4964735984802246
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49657278060913085
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9721664428710938
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9897791862487793
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9901535987854004
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9903167724609375
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.977712059020996
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1411296010017395
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1411903977394104
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1412575960159302
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14137279987335205
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.1413983941078186
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14143680334091185
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14152319431304933
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1421504020690918
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14241600036621094
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.14261120557785034
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1428895950317383
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1447424054145813
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.14632320404052734
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.1486240029335022
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15274879932403565
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.15864640474319458
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.18382400274276733
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.20247039794921876
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2299328088760376
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.24992640018463136
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.24993600845336914
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.25018560886383057
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2505631923675537
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3064768075942993
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3374079942703247
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.38586881160736086
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.496127986907959
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49655680656433104
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49669442176818845
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4967040061950684
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9900447845458984
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9902144432067871
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9906240463256836
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 1.0400095939636231
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9782751083374024
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27750720977783205
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2777024030685425
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2778879880905151
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2783744096755981
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2786272048950195
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2788127899169922
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27920639514923096
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27927680015563966
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28046720027923583
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2805344104766846
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28142719268798827
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28527040481567384
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2873471975326538
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.29215359687805176
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3014656066894531
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.31347200870513914
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3593983888626099
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.39324159622192384
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.43980798721313474
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4956064224243164
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4957024097442627
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4968575954437256
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4991136074066162
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9876128196716308
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9881983757019043
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9937472343444824
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.97576961517334
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.00467529296875
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.095788764953613
  kernels/embedding/backward.py->_backward:
    '''weight.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 10.2829345703125
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.291311645507813
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.356940460205077
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 11.231552124023438
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 11.304656219482421
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 11.554825592041016
    '''weight.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 3.5262847900390626
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.249020767211914
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.265212631225586
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.618073654174805
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.640486526489258
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 5.816291046142578
    '''weight.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 9.841529846191406
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 9.845574188232423
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.061414337158203
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.230134582519531
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 10.540303802490234
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 10.901094055175781
  kernels/embedding/forward.py->_forward:
    '''weight.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6687424182891846
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6687551975250244
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.6955008029937744
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.719862413406372
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.7806719779968262
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 0.8584447860717773
    '''weight.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6691808223724365
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6696063995361328
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.6947968006134033
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 0.719974422454834
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.7836832046508789
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 0.8594143867492676
    '''weight.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.376540756225586
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.4239775657653808
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 1.7085952758789062
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 4.786601638793945
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 256
        kernel_backend: triton
      time: 5.033430480957032
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 5.285673522949219
  kernels/rmsnorm/triton_implementation/kernels_backward.py->rmsnorm_backward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04248639941215515
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.042998400330543515
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04308800101280212
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04498240053653717
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.045286399126052854
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09077119827270508
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.22998399734497071
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0695680022239685
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07106239795684814
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.07163199782371521
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07210879921913146
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.07388799786567687
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09523839950561523
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.22487359046936034
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0419840008020401
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04254080057144165
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0426144003868103
    - config:
        BLOCK_SIZE_B: 4
      time: 0.042761600017547606
    - config:
        BLOCK_SIZE_B: 2
      time: 0.042895999550819394
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07695040106773376
    - config:
        BLOCK_SIZE_B: 64
      time: 0.17807040214538575
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07088000178337098
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07144320011138916
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07163199782371521
    - config:
        BLOCK_SIZE_B: 8
      time: 0.072326397895813
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07271999716758729
    - config:
        BLOCK_SIZE_B: 32
      time: 0.1399135947227478
    - config:
        BLOCK_SIZE_B: 64
      time: 0.42033920288085935
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.041657599806785586
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04190399944782257
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04195519983768463
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0419871985912323
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043049600720405576
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04359039962291718
    - config:
        BLOCK_SIZE_B: 512
      time: 0.049439999461174014
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07094399929046631
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07099840044975281
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07152959704399109
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07247679829597473
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07272639870643616
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07550719976425171
    - config:
        BLOCK_SIZE_B: 512
      time: 0.20509440898895265
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.041967999935150144
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04288319945335388
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04324159920215607
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04346559941768646
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.043699198961257936
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.044614401459693906
    - config:
        BLOCK_SIZE_B: 128
      time: 0.045151999592781066
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0705407977104187
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0710591971874237
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07154560089111328
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07189120054244995
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07203519940376282
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07228800058364868
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.15906879901885987
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07863039970397949
    - config:
        BLOCK_SIZE_B: 2
      time: 0.5484479904174805
    - config:
        BLOCK_SIZE_B: 4
      time: 0.7122367858886719
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 1.501699161529541
    - config:
        BLOCK_SIZE_B: 1
      time: 1.5629695892333983
    - config:
        BLOCK_SIZE_B: 4
      time: 2.773814392089844
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04237439930438995
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04242559969425201
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04331839978694916
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04352959990501404
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.043705600500106814
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.062326401472091675
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.19139519929885865
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.07073280215263367
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07128959894180298
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07177280187606812
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07189440131187438
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07282879948616028
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.09538879990577698
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.17541760206222534
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04251840114593506
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04343999922275543
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043628799915313723
    - config:
        BLOCK_SIZE_B: 1
      time: 0.044012799859046936
    - config:
        BLOCK_SIZE_B: 16
      time: 0.10929280519485474
    - config:
        BLOCK_SIZE_B: 32
      time: 0.25867199897766113
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07059199810028076
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07086719870567322
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07158079743385315
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0716480016708374
    - config:
        BLOCK_SIZE_B: 16
      time: 0.21090240478515626
    - config:
        BLOCK_SIZE_B: 32
      time: 0.5254687786102294
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04215039908885956
    - config:
        BLOCK_SIZE_B: 64
      time: 0.042217600345611575
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04244160056114197
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04283199906349182
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043119999766349795
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04345600008964538
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04920639991760254
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07092800140380859
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07102400064468384
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07133439779281617
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07208319902420043
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0726144015789032
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07392320036888123
    - config:
        BLOCK_SIZE_B: 256
      time: 0.20137600898742675
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04167360067367554
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04229120016098022
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04238399863243103
    - config:
        BLOCK_SIZE_B: 256
      time: 0.043808001279830935
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04384320080280304
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04450879991054535
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0500544011592865
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07011200189590454
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07107200026512146
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07160000205039978
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0728223979473114
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07284160256385804
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07336639761924743
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.1675040006637573
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.1099840164184571
    - config:
        BLOCK_SIZE_B: 2
      time: 1.8112607955932618
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 3.619484710693359
    - config:
        BLOCK_SIZE_B: 1
      time: 4.283750534057617
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042716801166534424
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04309119880199432
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.043609601259231565
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043849599361419675
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04490880072116852
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06499199867248535
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.21086080074310304
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07003840208053588
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07139520049095154
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07204480171203613
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07301120162010193
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07331519722938537
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.10174399614334106
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.17915199995040892
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04308159947395325
    - config:
        BLOCK_SIZE_B: 1
      time: 0.043612799048423766
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0437855988740921
    - config:
        BLOCK_SIZE_B: 8
      time: 0.17925440073013305
    - config:
        BLOCK_SIZE_B: 16
      time: 0.2645888090133667
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07221440076828003
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07274559736251832
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07409600019454957
    - config:
        BLOCK_SIZE_B: 8
      time: 0.4627744197845459
    - config:
        BLOCK_SIZE_B: 16
      time: 0.8258367538452148
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04184960126876831
    - config:
        BLOCK_SIZE_B: 4
      time: 0.042080000042915344
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04216319918632507
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04255039989948273
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04316799938678741
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04901759922504425
    - config:
        BLOCK_SIZE_B: 128
      time: 0.134879994392395
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07080960273742676
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07087680101394653
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07190399765968322
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07236160039901733
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07258880138397217
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10659840106964111
    - config:
        BLOCK_SIZE_B: 128
      time: 0.3379519939422607
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04166400134563446
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0417248010635376
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04290240108966827
    - config:
        BLOCK_SIZE_B: 512
      time: 0.043331199884414674
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0440416008234024
    - config:
        BLOCK_SIZE_B: 256
      time: 0.044207999110221864
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04786880016326904
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07094079852104188
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07129279971122741
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07140160202980042
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07158079743385315
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07231680154800416
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07551360130310059
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.17195839881896974
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.2312223434448244
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 10.419478607177734
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04193280041217804
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04199680089950562
    - config:
        BLOCK_SIZE_B: 512
      time: 0.042182400822639465
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04316799938678741
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.044310399889945985
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07694079875946044
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.21747519969940185
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07045440077781677
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07096959948539734
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07163839936256408
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07171840071678162
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07257279753684998
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.1380511999130249
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.3085472106933594
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.044870400428771974
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05083199739456177
    - config:
        BLOCK_SIZE_B: 4
      time: 0.1292415976524353
    - config:
        BLOCK_SIZE_B: 8
      time: 0.6184864044189453
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07503679990768433
    - config:
        BLOCK_SIZE_B: 2
      time: 0.08233919739723206
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6571839809417724
    - config:
        BLOCK_SIZE_B: 8
      time: 1.5726911544799804
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.042508798837661746
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04255039989948273
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04258880019187927
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04267520010471344
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04289920032024384
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09104959964752198
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.24504320621490477
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07063999772071838
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0719327986240387
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07245759963989258
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.07249280214309692
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.07287039756774902
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.07531200051307678
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.16812800168991088
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04232639968395233
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04232960045337677
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04270400106906891
    - config:
        BLOCK_SIZE_B: 8
      time: 0.042921599745750424
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04332799911499023
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06995199918746949
    - config:
        BLOCK_SIZE_B: 64
      time: 0.13562239408493043
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07208319902420043
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07236160039901733
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07351040244102477
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07400959730148315
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07432000041007995
    - config:
        BLOCK_SIZE_B: 32
      time: 0.11442240476608276
    - config:
        BLOCK_SIZE_B: 64
      time: 0.3418720006942749
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04208320081233978
    - config:
        BLOCK_SIZE_B: 128
      time: 0.042966398596763614
    - config:
        BLOCK_SIZE_B: 16
      time: 0.043110400438308716
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04344640076160431
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04371519982814789
    - config:
        BLOCK_SIZE_B: 8
      time: 0.043884798884391785
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04488320052623749
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07094720005989075
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07132160067558288
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07152000069618225
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07183359861373902
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07186560034751892
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07252479791641235
    - config:
        BLOCK_SIZE_B: 512
      time: 0.08292800188064575
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04285120069980621
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04287999868392944
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04332480132579804
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04332799911499023
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04376319944858551
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04439359903335571
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04468800127506256
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0710752010345459
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07130240201950074
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07162879705429077
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07169920206069946
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07260800004005433
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07520959973335266
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07592960000038147
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07854080200195312
    - config:
        BLOCK_SIZE_B: 2
      time: 0.44804158210754397
    - config:
        BLOCK_SIZE_B: 4
      time: 0.570147180557251
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.124345588684082
    - config:
        BLOCK_SIZE_B: 2
      time: 1.1558719635009767
    - config:
        BLOCK_SIZE_B: 4
      time: 1.978326416015625
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04222080111503601
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.042387199401855466
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04244160056114197
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.042735999822616576
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04310399889945984
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06212800145149231
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.16240639686584474
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.07003200054168701
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07152320146560669
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07161920070648194
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07180799841880799
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0723743975162506
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.11707520484924316
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.26369600296020507
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.042294400930404666
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04239040017127991
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04336000084877014
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04362240135669708
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09664959907531738
    - config:
        BLOCK_SIZE_B: 32
      time: 0.17919360399246215
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0700160026550293
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0719327986240387
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07203199863433837
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07255679965019227
    - config:
        BLOCK_SIZE_B: 16
      time: 0.1611807942390442
    - config:
        BLOCK_SIZE_B: 32
      time: 0.36174399852752687
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04305280148983002
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0430976003408432
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04327360093593598
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04333760142326355
    - config:
        BLOCK_SIZE_B: 4
      time: 0.043507200479507444
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04402880072593689
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0450111985206604
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07041919827461243
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07189120054244995
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0719648003578186
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07227200269699097
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07370880246162415
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0737280011177063
    - config:
        BLOCK_SIZE_B: 256
      time: 0.10645439624786376
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.042089599370956424
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04227199852466583
    - config:
        BLOCK_SIZE_B: 128
      time: 0.042310398817062375
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04249599874019623
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04274879992008209
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04317440092563629
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04660159945487976
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07020480036735535
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07085440158843995
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07146880030632019
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0716863989830017
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07198079824447631
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07248319983482361
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07689279913902283
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.885200023651123
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2132960319519044
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 2.96059513092041
    - config:
        BLOCK_SIZE_B: 1
      time: 3.0960128784179686
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.042054399847984314
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.042342400550842284
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04283519983291626
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04327360093593598
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04368320107460022
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06475520133972168
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.17852480411529542
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07120000123977661
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07185279726982116
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0729312002658844
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0731935977935791
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07335360050201416
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.13791359663009645
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.3034271955490112
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04332480132579804
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04431360065937042
    - config:
        BLOCK_SIZE_B: 1
      time: 0.044819200038909913
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0776639997959137
    - config:
        BLOCK_SIZE_B: 16
      time: 0.26547839641571047
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07225919961929321
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07255039811134338
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07256640195846557
    - config:
        BLOCK_SIZE_B: 16
      time: 0.37440640926361085
    - config:
        BLOCK_SIZE_B: 8
      time: 0.38318400382995604
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04132159948348999
    - config:
        BLOCK_SIZE_B: 32
      time: 0.041631999611854556
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04182400107383728
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04259839951992035
    - config:
        BLOCK_SIZE_B: 2
      time: 0.043510401248931886
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04951040148735046
    - config:
        BLOCK_SIZE_B: 128
      time: 0.10991040468215943
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.07055040001869202
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07125440239906311
    - config:
        BLOCK_SIZE_B: 8
      time: 0.07201600074768066
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07210559844970703
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07232319712638854
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10185600519180298
    - config:
        BLOCK_SIZE_B: 128
      time: 0.19911999702453614
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04148800075054169
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04162879884243011
    - config:
        BLOCK_SIZE_B: 256
      time: 0.042422398924827576
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04332480132579804
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04371519982814789
    - config:
        BLOCK_SIZE_B: 128
      time: 0.043798398971557614
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04609920084476471
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.07082560062408447
    - config:
        BLOCK_SIZE_B: 16
      time: 0.07139520049095154
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07219840288162231
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07232000231742859
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0725823998451233
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07296000123023987
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07516800165176392
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.8170400619506837
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 8.332038116455077
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04260160028934479
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04290879964828491
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.043219199776649474
    - config:
        BLOCK_SIZE_B: 256
      time: 0.043782401084899905
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04571839869022369
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.07681599855422974
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.21762559413909913
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07044479846954346
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07122560143470764
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.07123519778251648
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.07281919717788696
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07283200025558471
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.11286720037460327
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.19387840032577514
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04709439873695374
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04997439980506897
    - config:
        BLOCK_SIZE_B: 4
      time: 0.22825279235839843
    - config:
        BLOCK_SIZE_B: 8
      time: 0.46041278839111327
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07285439968109131
    - config:
        BLOCK_SIZE_B: 2
      time: 0.45298237800598146
    - config:
        BLOCK_SIZE_B: 4
      time: 0.5849503993988037
    - config:
        BLOCK_SIZE_B: 8
      time: 0.8801440238952637
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04291200041770935
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.042972800135612485
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04312320053577423
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.044998401403427125
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.046972799301147464
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.0738655984401703
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.16359039545059204
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06521919965744019
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06542080044746398
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06593599915504456
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.06600639820098878
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06877120137214661
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.08238720297813415
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.23183679580688477
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04200319945812225
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04312959909439087
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04327360093593598
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04373759925365448
    - config:
        BLOCK_SIZE_B: 16
      time: 0.054681599140167236
    - config:
        BLOCK_SIZE_B: 32
      time: 0.11050560474395751
    - config:
        BLOCK_SIZE_B: 64
      time: 0.2887104034423828
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0633567988872528
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06436160206794739
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06464639902114869
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06481919884681701
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09562240242958069
    - config:
        BLOCK_SIZE_B: 32
      time: 0.14871360063552858
    - config:
        BLOCK_SIZE_B: 64
      time: 0.34511680603027345
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04232639968395233
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04259839951992035
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0432671993970871
    - config:
        BLOCK_SIZE_B: 16
      time: 0.043372800946235655
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04355199933052063
    - config:
        BLOCK_SIZE_B: 256
      time: 0.045686399936676024
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0787392020225525
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06403200030326843
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06570240259170532
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06607679724693298
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0662335991859436
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06625919938087463
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07066879868507385
    - config:
        BLOCK_SIZE_B: 512
      time: 0.11885119676589966
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04249599874019623
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04265280067920685
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04386560022830963
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04487360119819641
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04502080082893371
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04650560021400452
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.056428802013397214
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0641759991645813
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06562880277633668
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06602240204811097
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06605439782142639
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06629120111465454
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06716480255126953
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.11624640226364136
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.14507520198822021
    - config:
        BLOCK_SIZE_B: 2
      time: 1.2961983680725098
    - config:
        BLOCK_SIZE_B: 4
      time: 1.732316780090332
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.66430721282959
    - config:
        BLOCK_SIZE_B: 2
      time: 1.9718080520629884
    - config:
        BLOCK_SIZE_B: 4
      time: 3.3102783203125
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0430976003408432
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04314239919185638
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04336000084877014
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04339199960231781
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04445439875125885
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.047295999526977536
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.2676160097122192
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06357439756393432
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06381120085716248
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06439359784126282
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06478400230407715
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.06579520106315613
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.09133120179176331
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.33119680881500246
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04341759979724884
    - config:
        BLOCK_SIZE_B: 8
      time: 0.044537600874900815
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04470399916172028
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04491840004920959
    - config:
        BLOCK_SIZE_B: 16
      time: 0.1673472046852112
    - config:
        BLOCK_SIZE_B: 32
      time: 0.24908161163330078
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06499840021133423
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0658527970314026
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0658847987651825
    - config:
        BLOCK_SIZE_B: 8
      time: 0.21068799495697021
    - config:
        BLOCK_SIZE_B: 16
      time: 0.24103360176086425
    - config:
        BLOCK_SIZE_B: 32
      time: 0.4020415782928467
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04242559969425201
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04256319999694824
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04366720020771027
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04371840059757233
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04607360064983368
    - config:
        BLOCK_SIZE_B: 128
      time: 0.051641601324081424
    - config:
        BLOCK_SIZE_B: 256
      time: 0.161843204498291
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06353279948234558
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06436799764633179
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06473280191421509
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06537920236587524
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06577600240707397
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07550719976425171
    - config:
        BLOCK_SIZE_B: 256
      time: 0.25151360034942627
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.041894400119781496
    - config:
        BLOCK_SIZE_B: 64
      time: 0.043049600720405576
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04337919950485229
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04347519874572754
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04395520091056824
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04471360146999359
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06639360189437866
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06473280191421509
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06476799845695495
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06490560173988343
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06509119868278504
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06715199947357178
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06865280270576476
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.1058303952217102
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.739776039123535
    - config:
        BLOCK_SIZE_B: 2
      time: 3.515513610839844
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 4.280019378662109
    - config:
        BLOCK_SIZE_B: 2
      time: 5.129929733276367
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.042089599370956424
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.04326080083847046
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04339520037174225
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04385600090026855
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04413439929485321
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.04912959933280945
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.3422368049621582
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04794560074806213
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0642304003238678
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06536639928817749
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06691840291023254
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06730239987373351
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.09745600223541259
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.26467199325561525
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04513919949531555
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04545600116252899
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04567680060863495
    - config:
        BLOCK_SIZE_B: 8
      time: 0.26752960681915283
    - config:
        BLOCK_SIZE_B: 16
      time: 0.32623679637908937
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06528000235557556
    - config:
        BLOCK_SIZE_B: 1
      time: 0.06610559821128845
    - config:
        BLOCK_SIZE_B: 4
      time: 0.37953600883483884
    - config:
        BLOCK_SIZE_B: 8
      time: 0.5599679946899414
    - config:
        BLOCK_SIZE_B: 16
      time: 0.5852320194244385
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.04154880046844482
    - config:
        BLOCK_SIZE_B: 8
      time: 0.04219520092010498
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04325439929962158
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04363200068473816
    - config:
        BLOCK_SIZE_B: 32
      time: 0.050076800584793094
    - config:
        BLOCK_SIZE_B: 64
      time: 0.10817279815673828
    - config:
        BLOCK_SIZE_B: 128
      time: 0.18432960510253907
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.06453440189361573
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06485440135002137
    - config:
        BLOCK_SIZE_B: 8
      time: 0.06491519808769226
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06547840237617493
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0664031982421875
    - config:
        BLOCK_SIZE_B: 64
      time: 0.11084799766540528
    - config:
        BLOCK_SIZE_B: 128
      time: 0.2510591983795166
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04169279932975769
    - config:
        BLOCK_SIZE_B: 16
      time: 0.0428384006023407
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0428384006023407
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04299519956111908
    - config:
        BLOCK_SIZE_B: 256
      time: 0.04340159893035889
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04410240054130554
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06964160203933716
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.06355839967727661
    - config:
        BLOCK_SIZE_B: 16
      time: 0.06395519971847534
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06402239799499512
    - config:
        BLOCK_SIZE_B: 32
      time: 0.06477760076522827
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0652351975440979
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06622080206871032
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.11308480501174926
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 7.592185974121094
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 10.245442962646484
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04336639940738678
    - config:
        BLOCK_SIZE_B: 256
      time: 0.043644800782203674
    - config:
        BLOCK_SIZE_B: 128
      time: 0.04410879909992218
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.044470399618148804
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.04643200039863586
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.062249600887298584
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.2697472095489502
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.06539199948310852
    - config:
        BLOCK_SIZE_B: 512
      time: 0.06547840237617493
    - config:
        BLOCK_SIZE_B: 128
      time: 0.06550719738006591
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06615679860115051
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06705920100212097
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.10561599731445312
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.2887200117111206
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.07192320227622986
    - config:
        BLOCK_SIZE_B: 2
      time: 0.07516160011291503
    - config:
        BLOCK_SIZE_B: 4
      time: 0.6320127964019775
    - config:
        BLOCK_SIZE_B: 8
      time: 0.7884607791900635
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.08505920171737671
    - config:
        BLOCK_SIZE_B: 2
      time: 0.6504992008209228
    - config:
        BLOCK_SIZE_B: 4
      time: 0.8800031661987304
    - config:
        BLOCK_SIZE_B: 8
      time: 1.377830410003662
  kernels/rmsnorm/triton_implementation/kernels_forward.py->rmsnorm_forward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.0341376006603241
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03437120020389557
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03449920117855072
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.034668800234794614
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.035385599732398985
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04578559994697571
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.09430720210075379
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.036025598645210266
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03619840145111084
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0363072007894516
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.037324801087379456
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03781439960002899
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04950079917907715
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.10803200006484985
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033478400111198424
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03370240032672882
    - config:
        BLOCK_SIZE_B: 2
      time: 0.033904001116752625
    - config:
        BLOCK_SIZE_B: 8
      time: 0.034006398916244504
    - config:
        BLOCK_SIZE_B: 16
      time: 0.034016001224517825
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03479360044002533
    - config:
        BLOCK_SIZE_B: 64
      time: 0.047337600588798524
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037273600697517395
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03763200044631958
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03771199882030487
    - config:
        BLOCK_SIZE_B: 4
      time: 0.037859201431274414
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03825919926166534
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03843519985675812
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03958080112934113
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03334720134735107
    - config:
        BLOCK_SIZE_B: 8
      time: 0.034143999218940735
    - config:
        BLOCK_SIZE_B: 128
      time: 0.034185600280761716
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03432640135288238
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03437120020389557
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03477759957313538
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03506560027599335
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03648639917373657
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03649600148200989
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03680959939956665
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037145599722862244
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03761279881000519
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03791680037975311
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0385919988155365
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03356800079345703
    - config:
        BLOCK_SIZE_B: 128
      time: 0.033632001280784606
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03420799970626831
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03434880077838898
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03455359935760498
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03533119857311249
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04628480076789856
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03711360096931458
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03727039992809296
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03752320110797882
    - config:
        BLOCK_SIZE_B: 512
      time: 0.037536001205444335
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037555199861526486
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03845439851284027
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03851839900016785
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04779199957847595
    - config:
        BLOCK_SIZE_B: 2
      time: 0.050444799661636355
    - config:
        BLOCK_SIZE_B: 4
      time: 0.3068543910980225
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05288000106811523
    - config:
        BLOCK_SIZE_B: 2
      time: 0.059462398290634155
    - config:
        BLOCK_SIZE_B: 4
      time: 0.4482816219329834
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03335680067539215
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03411200046539307
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03436799943447113
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03452799916267395
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03472320139408112
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04704639911651611
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09848319888114929
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03689599931240082
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03707199990749359
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03727039992809296
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037363201379776
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.038159999251365664
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04755519926548004
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.10021120309829712
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033215999603271484
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03411200046539307
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03421759903430939
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03438720107078552
    - config:
        BLOCK_SIZE_B: 1
      time: 0.034643200039863584
    - config:
        BLOCK_SIZE_B: 32
      time: 0.04311360120773315
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03627200126647949
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036950400471687316
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03702079951763153
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037539198994636536
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03797119855880737
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03936960101127625
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033504000306129454
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03377600014209747
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033939200639724734
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03421759903430939
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034281599521636966
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03451519906520843
    - config:
        BLOCK_SIZE_B: 16
      time: 0.034534400701522826
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03672960102558136
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03715839982032776
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03728640079498291
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03759360015392303
    - config:
        BLOCK_SIZE_B: 128
      time: 0.038764798641204835
    - config:
        BLOCK_SIZE_B: 64
      time: 0.038966399431228635
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03924480080604553
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033155199885368344
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033251199126243594
    - config:
        BLOCK_SIZE_B: 128
      time: 0.033667200803756715
    - config:
        BLOCK_SIZE_B: 256
      time: 0.033964800834655764
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0340256005525589
    - config:
        BLOCK_SIZE_B: 32
      time: 0.035462400317192076
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0438944011926651
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03739840090274811
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03758719861507416
    - config:
        BLOCK_SIZE_B: 512
      time: 0.038099199533462524
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.038252800703048706
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03837119936943054
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.038431999087333676
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03850240111351013
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09584320187568665
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7328479766845704
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.1359776020050049
    - config:
        BLOCK_SIZE_B: 2
      time: 0.7863103866577148
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.033379200100898745
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034092798829078674
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.034185600280761716
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03419840037822723
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03442879915237427
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05308799743652344
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14530240297317504
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03650240004062653
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03719359934329987
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03763200044631958
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03786559998989105
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03814400136470795
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.0546239972114563
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14948480129241942
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.033308801054954526
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03376320004463196
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03410240113735199
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03450239896774292
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04570240080356598
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03697920143604279
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03776960074901581
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037894400954246524
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03824959993362427
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04708159863948822
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033199998736381534
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03346239924430847
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033497598767280576
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03362239897251129
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03391039967536926
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03467839956283569
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03557440042495728
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03641600012779236
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036457601189613345
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03655360043048859
    - config:
        BLOCK_SIZE_B: 16
      time: 0.036739200353622437
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0367680013179779
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03696320056915283
    - config:
        BLOCK_SIZE_B: 128
      time: 0.038492798805236816
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0343423992395401
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03437120020389557
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03440960049629212
    - config:
        BLOCK_SIZE_B: 128
      time: 0.034467199444770814
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03480960130691528
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03492160141468048
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03710399866104126
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0365119993686676
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03674559891223907
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03750079870223999
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03752639889717102
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03774400055408478
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03798399865627289
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03856639862060547
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.5856480121612548
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.203923225402832
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03303360044956207
    - config:
        BLOCK_SIZE_B: 128
      time: 0.033846399188041686
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034297600388526917
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03455039858818054
    - config:
        BLOCK_SIZE_B: 512
      time: 0.034668800234794614
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06427199840545654
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17610880136489868
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03705599904060364
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03705599904060364
    - config:
        BLOCK_SIZE_B: 128
      time: 0.037084800004959104
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03773120045661926
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03832319974899292
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06505280137062072
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.1765247941017151
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.035087999701499936
    - config:
        BLOCK_SIZE_B: 1
      time: 0.035417601466178894
    - config:
        BLOCK_SIZE_B: 2
      time: 0.035462400317192076
    - config:
        BLOCK_SIZE_B: 8
      time: 0.14224319458007811
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03776960074901581
    - config:
        BLOCK_SIZE_B: 1
      time: 0.038211199641227725
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03854719996452331
    - config:
        BLOCK_SIZE_B: 8
      time: 0.13743360042572023
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.033766400814056394
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03407999873161316
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.034201601147651674
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03469760119915009
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03472320139408112
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.03710080087184906
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.06349120140075684
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03612160086631775
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03660480082035065
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.036924800276756285
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03734079897403717
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03773120045661926
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.04359680116176605
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.09273920059204102
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.033881598711013795
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0339711993932724
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03412159979343414
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03412800133228302
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03427839875221252
    - config:
        BLOCK_SIZE_B: 32
      time: 0.034355199337005614
    - config:
        BLOCK_SIZE_B: 64
      time: 0.046742400527000426
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.036924800276756285
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03701440095901489
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037363201379776
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03778879940509796
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03794240057468414
    - config:
        BLOCK_SIZE_B: 32
      time: 0.038166400790214536
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03859519958496094
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03340800106525421
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03370240032672882
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03377279937267304
    - config:
        BLOCK_SIZE_B: 8
      time: 0.034016001224517825
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03422400057315826
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03431360125541687
    - config:
        BLOCK_SIZE_B: 512
      time: 0.04429759979248047
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.036287999153137206
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03670719861984253
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03709760010242462
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03720960021018982
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03749119937419891
    - config:
        BLOCK_SIZE_B: 32
      time: 0.037567999958992
    - config:
        BLOCK_SIZE_B: 512
      time: 0.044047999382019046
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03323839902877808
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03326080143451691
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03368639945983887
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03406400084495544
    - config:
        BLOCK_SIZE_B: 128
      time: 0.034332799911499026
    - config:
        BLOCK_SIZE_B: 64
      time: 0.034985598921775815
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03682880103588104
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037231999635696414
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03738240003585815
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03750079870223999
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037513598799705505
    - config:
        BLOCK_SIZE_B: 128
      time: 0.0378495991230011
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.038815999031066896
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.04085119962692261
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0482367992401123
    - config:
        BLOCK_SIZE_B: 2
      time: 0.050518399477005003
    - config:
        BLOCK_SIZE_B: 4
      time: 0.25160000324249265
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.05418559908866882
    - config:
        BLOCK_SIZE_B: 2
      time: 0.05752320289611816
    - config:
        BLOCK_SIZE_B: 4
      time: 0.32919039726257326
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.0333983987569809
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033795198798179625
    - config:
        BLOCK_SIZE_B: 512
      time: 0.033932799100875856
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.034483200311660765
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03489600121974945
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.0471807986497879
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09867839813232422
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03612479865550995
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03733760118484497
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.037350401282310486
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03776960074901581
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03811840116977692
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04785279929637909
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.10006400346755981
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.032671999931335446
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03338559865951538
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0335999995470047
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03373759984970093
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03416639864444733
    - config:
        BLOCK_SIZE_B: 32
      time: 0.035257598757743834
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03661440014839172
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03686400055885315
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03707520067691803
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03772160112857818
    - config:
        BLOCK_SIZE_B: 4
      time: 0.0378495991230011
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03830080032348633
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03224639892578125
    - config:
        BLOCK_SIZE_B: 64
      time: 0.032655999064445496
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03330560028553009
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03332160115242004
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033456000685691836
    - config:
        BLOCK_SIZE_B: 16
      time: 0.034329599142074584
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0353983998298645
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03653759956359863
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0372191995382309
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03768639862537384
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03776319921016693
    - config:
        BLOCK_SIZE_B: 4
      time: 0.037785598635673524
    - config:
        BLOCK_SIZE_B: 64
      time: 0.038150399923324585
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03823359906673431
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033232000470161435
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03409920036792755
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03427520096302032
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03446080088615418
    - config:
        BLOCK_SIZE_B: 512
      time: 0.034534400701522826
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034796801209449765
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.041126400232315063
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03661440014839172
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.036697599291801455
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03720960021018982
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03734399974346161
    - config:
        BLOCK_SIZE_B: 256
      time: 0.037625598907470706
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03809280097484589
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03871999979019165
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09572479724884034
    - config:
        BLOCK_SIZE_B: 2
      time: 0.43518719673156736
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.13231680393218995
    - config:
        BLOCK_SIZE_B: 2
      time: 0.6987584114074707
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033180800080299375
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03333759903907776
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03343999981880188
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03403519988059998
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03429119884967804
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05324800014495849
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14549119472503663
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03703039884567261
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03755199909210205
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03757759928703308
    - config:
        BLOCK_SIZE_B: 512
      time: 0.037852799892425536
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.038396799564361574
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.054553598165512085
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.14950400590896606
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03378880023956299
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03424000144004822
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03434560000896454
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03460479974746704
    - config:
        BLOCK_SIZE_B: 16
      time: 0.052179199457168576
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03691839873790741
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03732160031795502
    - config:
        BLOCK_SIZE_B: 4
      time: 0.037401598691940305
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03797439932823181
    - config:
        BLOCK_SIZE_B: 16
      time: 0.04624319970607758
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.0333759993314743
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03372800052165985
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03390080034732819
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03452480137348175
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03460479974746704
    - config:
        BLOCK_SIZE_B: 4
      time: 0.034646400809288026
    - config:
        BLOCK_SIZE_B: 128
      time: 0.034729599952697754
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03622719943523407
    - config:
        BLOCK_SIZE_B: 4
      time: 0.036483201384544375
    - config:
        BLOCK_SIZE_B: 16
      time: 0.037011200189590455
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03727680146694183
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03760960102081299
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03772160112857818
    - config:
        BLOCK_SIZE_B: 128
      time: 0.038729599118232726
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03346560001373291
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033964800834655764
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03411200046539307
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03424000144004822
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03463680148124695
    - config:
        BLOCK_SIZE_B: 16
      time: 0.034822401404380796
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03966079950332642
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03677760064601898
    - config:
        BLOCK_SIZE_B: 16
      time: 0.037011200189590455
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0376800000667572
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03790079951286316
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03813759982585907
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0392767995595932
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.039875200390815733
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.5884223937988281
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.3147040367126466
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03328959941864014
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03358719944953918
    - config:
        BLOCK_SIZE_B: 256
      time: 0.0343968003988266
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03478719890117645
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03540160059928894
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06427839994430543
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17593920230865479
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03666560053825378
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03696320056915283
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03743360042572021
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03752639889717102
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037862399220466615
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06500800251960755
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17640639543533326
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.034585601091384886
    - config:
        BLOCK_SIZE_B: 2
      time: 0.035104000568389894
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03521600067615509
    - config:
        BLOCK_SIZE_B: 8
      time: 0.10988800525665283
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0377375990152359
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03809280097484589
    - config:
        BLOCK_SIZE_B: 1
      time: 0.038396799564361574
    - config:
        BLOCK_SIZE_B: 8
      time: 0.09800320267677307
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03346239924430847
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03394240140914917
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03448640108108521
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.034518399834632875
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03694080114364624
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.03882560133934021
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.08880959749221802
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03664000034332275
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03729279935359955
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03765439987182617
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.03803200125694275
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.038889598846435544
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.03930560052394867
    - config:
        BLOCK_SIZE_B: 65536
      time: 0.06286720037460328
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03269760012626648
    - config:
        BLOCK_SIZE_B: 16
      time: 0.032739201188087465
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033199998736381534
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033334401249885556
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0336896002292633
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03369919955730438
    - config:
        BLOCK_SIZE_B: 64
      time: 0.07559040188789368
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03678719997406006
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03686079978942871
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03689599931240082
    - config:
        BLOCK_SIZE_B: 2
      time: 0.037248000502586365
    - config:
        BLOCK_SIZE_B: 1
      time: 0.037862399220466615
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03857919871807099
    - config:
        BLOCK_SIZE_B: 64
      time: 0.0881056010723114
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03349440097808838
    - config:
        BLOCK_SIZE_B: 64
      time: 0.033667200803756715
    - config:
        BLOCK_SIZE_B: 16
      time: 0.034281599521636966
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03437759876251221
    - config:
        BLOCK_SIZE_B: 128
      time: 0.034380799531936644
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03444480001926422
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0642848014831543
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03674240112304687
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03691200017929077
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03707840144634247
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03714239895343781
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03771840035915375
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03774079978466034
    - config:
        BLOCK_SIZE_B: 512
      time: 0.07111679911613464
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03403840065002441
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03415040075778961
    - config:
        BLOCK_SIZE_B: 512
      time: 0.034431999921798705
    - config:
        BLOCK_SIZE_B: 128
      time: 0.034457600116729735
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03446080088615418
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03555200099945068
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.054473602771759035
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03726719915866852
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03740800023078918
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03797119855880737
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03812159895896912
    - config:
        BLOCK_SIZE_B: 64
      time: 0.038201600313186646
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03983359932899475
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.051820802688598636
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.09322879910469055
    - config:
        BLOCK_SIZE_B: 2
      time: 0.09963840246200562
    - config:
        BLOCK_SIZE_B: 4
      time: 0.3794464111328125
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.10107519626617431
    - config:
        BLOCK_SIZE_B: 4
      time: 0.44553279876708984
    - config:
        BLOCK_SIZE_B: 2
      time: 0.5306943893432617
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.032604798674583435
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.033548799157142636
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.033583998680114746
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03399359881877899
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.034236800670623777
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.04889279901981354
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09300479888916016
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03657920062541962
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03759360015392303
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03766080141067505
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.03784320056438446
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.03892160058021545
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.050361597537994386
    - config:
        BLOCK_SIZE_B: 32768
      time: 0.09596800208091735
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.032979199290275575
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03328959941864014
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03357760012149811
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03372800052165985
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03379839956760407
    - config:
        BLOCK_SIZE_B: 32
      time: 0.10270400047302246
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03669439852237701
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03670400083065033
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03697920143604279
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03705919981002807
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03770560026168823
    - config:
        BLOCK_SIZE_B: 32
      time: 0.1259328007698059
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03341119885444641
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03356159925460815
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03387520015239716
    - config:
        BLOCK_SIZE_B: 4
      time: 0.033881598711013795
    - config:
        BLOCK_SIZE_B: 32
      time: 0.0340256005525589
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03617280125617981
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07315840125083924
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03656960129737854
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03667519986629486
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03744319975376129
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03779520094394684
    - config:
        BLOCK_SIZE_B: 128
      time: 0.038499200344085695
    - config:
        BLOCK_SIZE_B: 4
      time: 0.038761600852012634
    - config:
        BLOCK_SIZE_B: 256
      time: 0.07675520181655884
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03353599905967712
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03419199883937836
    - config:
        BLOCK_SIZE_B: 128
      time: 0.034201601147651674
    - config:
        BLOCK_SIZE_B: 64
      time: 0.034771201014518735
    - config:
        BLOCK_SIZE_B: 512
      time: 0.0350847989320755
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03703359961509704
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.05460799932479858
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03723520040512085
    - config:
        BLOCK_SIZE_B: 128
      time: 0.037299200892448425
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03735679984092712
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037775999307632445
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03806079924106598
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.040454399585723874
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.06343680024147033
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.1945248007774353
    - config:
        BLOCK_SIZE_B: 2
      time: 0.784768009185791
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 1.082755184173584
    - config:
        BLOCK_SIZE_B: 1
      time: 1.0856703758239745
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03341119885444641
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.033529600501060484
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03389120101928711
    - config:
        BLOCK_SIZE_B: 256
      time: 0.034281599521636966
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.035571199655532834
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05280960202217102
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.10726720094680786
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.026767998933792114
    - config:
        BLOCK_SIZE_B: 256
      time: 0.036627200245857236
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.036713600158691406
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03680959939956665
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.0368800014257431
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.05263040065765381
    - config:
        BLOCK_SIZE_B: 16384
      time: 0.10693440437316895
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 4
      time: 0.034067198634147644
    - config:
        BLOCK_SIZE_B: 2
      time: 0.0346015989780426
    - config:
        BLOCK_SIZE_B: 1
      time: 0.035417601466178894
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03680320084095001
    - config:
        BLOCK_SIZE_B: 16
      time: 0.09889919757843017
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.03755840063095093
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03804160058498383
    - config:
        BLOCK_SIZE_B: 4
      time: 0.038550400733947755
    - config:
        BLOCK_SIZE_B: 8
      time: 0.03859519958496094
    - config:
        BLOCK_SIZE_B: 16
      time: 0.15538879632949829
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 32
      time: 0.033478400111198424
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03367680013179779
    - config:
        BLOCK_SIZE_B: 8
      time: 0.033827200531959534
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03394559919834137
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03440000116825104
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03472639918327332
    - config:
        BLOCK_SIZE_B: 128
      time: 0.07577279806137086
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03621439933776856
    - config:
        BLOCK_SIZE_B: 8
      time: 0.036822399497032164
    - config:
        BLOCK_SIZE_B: 4
      time: 0.03696640133857727
    - config:
        BLOCK_SIZE_B: 2
      time: 0.03701440095901489
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03727039992809296
    - config:
        BLOCK_SIZE_B: 64
      time: 0.04040960073471069
    - config:
        BLOCK_SIZE_B: 128
      time: 0.060070401430130003
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 64
      time: 0.03345920145511627
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03386879861354828
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03406400084495544
    - config:
        BLOCK_SIZE_B: 16
      time: 0.03407680094242096
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03437759876251221
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03872320055961609
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06351360082626342
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 256
      time: 0.036057600378990175
    - config:
        BLOCK_SIZE_B: 32
      time: 0.03619199991226196
    - config:
        BLOCK_SIZE_B: 16
      time: 0.036364799737930296
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03677760064601898
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03717440068721771
    - config:
        BLOCK_SIZE_B: 64
      time: 0.037699198722839354
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.06220800280570984
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 1.6089056015014649
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 1
      time: 2.025644874572754
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03274880051612854
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.03334720134735107
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.03378239870071411
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03420799970626831
    - config:
        BLOCK_SIZE_B: 256
      time: 0.03428800106048584
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06312959790229797
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.17601280212402343
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 512
      time: 0.03729600012302399
    - config:
        BLOCK_SIZE_B: 2048
      time: 0.037801599502563475
    - config:
        BLOCK_SIZE_B: 128
      time: 0.03787519931793213
    - config:
        BLOCK_SIZE_B: 256
      time: 0.038073599338531494
    - config:
        BLOCK_SIZE_B: 1024
      time: 0.038176000118255615
    - config:
        BLOCK_SIZE_B: 4096
      time: 0.06457279920578003
    - config:
        BLOCK_SIZE_B: 8192
      time: 0.16732159852981568
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
    - config:
        BLOCK_SIZE_B: 1
      time: 0.04730879962444305
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04824320077896118
    - config:
        BLOCK_SIZE_B: 4
      time: 0.05224000215530396
    - config:
        BLOCK_SIZE_B: 8
      time: 0.1811519980430603
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
    - config:
        BLOCK_SIZE_B: 2
      time: 0.04964799880981445
    - config:
        BLOCK_SIZE_B: 1
      time: 0.0497759997844696
    - config:
        BLOCK_SIZE_B: 4
      time: 0.06743360161781312
    - config:
        BLOCK_SIZE_B: 8
      time: 0.24364800453186036
  kernels/swiglu/backward.py->_backward:
    '''gate.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27978880405426027
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2800735950469971
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2805279970169067
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2809760093688965
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2811552047729492
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2811903953552246
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.28121280670166016
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2819839954376221
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.28797121047973634
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2882272005081177
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2886528015136719
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.29325759410858154
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2983551979064941
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.30195519924163816
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.30687038898468016
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.311625599861145
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3303328037261963
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.33942399024963377
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3537823915481567
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.3662208080291748
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3806368112564087
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4960480213165283
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4965216159820557
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4975135803222656
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.5673088073730469
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.5936063766479492
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.5941535949707031
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.6365119934082031
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.6961408138275147
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.987996768951416
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9881792068481445
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9885984420776367
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9728031158447266
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 3.882649612426758
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 4.10338249206543
    '''gate.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2790816068649292
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27908480167388916
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2792543888092041
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27927360534667967
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.27979838848114014
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28022398948669436
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.28057920932769775
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.28057920932769775
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2848448038101196
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2851648092269897
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2859328031539917
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.29079360961914064
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.29701120853424073
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.3002592086791992
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.30615360736846925
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.31004159450531005
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.31686720848083494
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3266207933425903
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3364000082015991
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3506943941116333
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3774879932403564
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.4966752052307129
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49675521850585935
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49741759300231936
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.5335552215576171
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.5657120227813721
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.5918367862701416
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.6343776226043701
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.6940767765045166
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9899935722351074
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9901215553283691
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9901439666748046
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9773664474487305
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 3.584076690673828
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 3.6675392150878907
    '''gate.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.5548384189605713
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.5550015926361084
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.5555295944213867
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.5557663917541504
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.556601619720459
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.558457612991333
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.558681583404541
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.5588511943817138
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.5601439952850342
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.573305606842041
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.5745920181274414
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.5796959877014161
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.5825247764587402
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.5862368106842041
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.5971871852874756
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.6003967761993408
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.6142560005187988
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.6724544048309327
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.6956448078155517
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.7390143871307373
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.7972928047180176
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9187583923339844
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9891488075256347
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9891551971435547
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 1.0012543678283692
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 1.2153696060180663
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9759424209594727
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 4.747212982177734
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 4.8714752197265625
  kernels/swiglu/forward.py->_forward:
    '''gate.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14087040424346925
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14124159812927245
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14234880208969117
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1429311990737915
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14715199470520018
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14897600412368775
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2008415937423706
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.20093441009521484
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.20107519626617432
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.20321600437164306
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.21388161182403564
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.21986238956451415
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.22269759178161622
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.22376959323883056
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.23296639919281006
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.24997758865356445
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.25074880123138427
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.25290560722351074
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.25501439571380613
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.27405760288238523
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2803328037261963
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2946432113647461
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3408479928970337
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3881504058837891
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4170271873474121
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4752511978149414
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4952095985412598
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.49699840545654295
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49700160026550294
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.4972032070159912
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9880352020263672
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9903743743896485
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9904159545898438
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 1.1553119659423827
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.977791976928711
    '''gate.dtype = torch.float16''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1411296010017395
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14158079624176026
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14387199878692628
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14649280309677123
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1468000054359436
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.15679680109024047
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.19760960340499878
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.19771519899368287
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.19806079864501952
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2001471996307373
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.20741119384765624
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.21755199432373046
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2201695919036865
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.2202303886413574
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2312864065170288
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2503551959991455
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2510688066482544
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.25223360061645506
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 8
      time: 0.25292799472808836
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.27256639003753663
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.2785856008529663
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.29159040451049806
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3374592065811157
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.3871488094329834
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4160799980163574
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4744448184967041
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.49629759788513184
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.49683837890625
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4968480110168457
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49723200798034667
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9897600173950195
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9905632019042969
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9906208038330078
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 1.1560704231262207
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9783327102661132
    '''gate.dtype = torch.float32''':
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27870399951934816
    - config:
        BLOCK_SIZE: 512
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27883200645446776
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27992639541625974
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2799328088760376
    - config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2810944080352783
    - config:
        BLOCK_SIZE: 4096
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.28140480518341066
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.2852191925048828
    - config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2878432035446167
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.29373760223388673
    - config:
        BLOCK_SIZE: 8192
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2939232110977173
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.3029632091522217
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.306550407409668
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.3147552013397217
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.32968959808349607
    - config:
        BLOCK_SIZE: 16384
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.3494623899459839
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.36495680809020997
    - config:
        BLOCK_SIZE: 256
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4216127872467041
    - config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.45632319450378417
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.496124792098999
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.49647040367126466
    - config:
        BLOCK_SIZE: 128
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.4979392051696777
    - config:
        BLOCK_SIZE: 128
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.4997568130493164
    - config:
        BLOCK_SIZE: 1024
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.5127647876739502
    - config:
        BLOCK_SIZE: 64
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 0.9878751754760742
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 2
      time: 0.9879167556762696
    - config:
        BLOCK_SIZE: 64
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.9939231872558594
    - config:
        BLOCK_SIZE: 32
        kernel_backend: cuda
        vector_instruction_width: 1
      time: 1.9764415740966796
    - config:
        BLOCK_SIZE: 32768
        kernel_backend: triton
        vector_instruction_width: null
      time: 1.9821184158325196
    - config:
        BLOCK_SIZE: 65536
        kernel_backend: triton
        vector_instruction_width: null
      time: 2.057184028625488
  kernels/swiglu_unchunked/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5710720062255858
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.017283248901367
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 3.2580928802490234
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.52394256591797
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.73621368408203
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5502976417541503
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.7354047775268555
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.7645919799804686
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 23.882354736328125
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.23418273925781
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.607369613647461
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 3.1999263763427734
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 5.643612670898437
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.078536987304688
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 24.34514923095703
  kernels/swiglu_unchunked/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9784031867980957
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9789567947387695
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.0695648193359375
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.3091360092163087
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 6.2301025390625
    '''x.dtype = torch.float16''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9641983985900879
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9665887832641602
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.0620160102844238
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.248793601989746
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 6.17408332824707
    '''x.dtype = torch.float32''':
    - config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5731200218200683
    - config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.6239967346191406
    - config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.8471391677856446
    - config:
        BLOCK_SIZE_B: 1024
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 8.712438201904297
    - config:
        BLOCK_SIZE_B: 512
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 8.731273651123047
best_configs:
  kernels/add/add_scalar/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14110080003738404
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14096319675445557
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27802879810333253
  kernels/add/add_tensor/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14098880290985108
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1411296010017395
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 512
        kernel_backend: cuda
        vector_instruction_width: 4
      time: 0.27750720977783205
  kernels/embedding/backward.py->_backward:
    '''weight.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 512
        kernel_backend: triton
      time: 10.2829345703125
    '''weight.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 3.5262847900390626
    '''weight.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 9.841529846191406
  kernels/embedding/forward.py->_forward:
    '''weight.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 256
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6687424182891846
    '''weight.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 0.6691808223724365
    '''weight.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 128
        BLOCK_SIZE_H: 128
        kernel_backend: triton
      time: 1.376540756225586
  kernels/rmsnorm/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float32''':
      config:
        kernel_backend: triton
      time: 0
  kernels/rmsnorm/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float16''':
      config:
        kernel_backend: triton
      time: 0
    '''x.dtype = torch.float32''':
      config:
        kernel_backend: triton
      time: 0
  kernels/rmsnorm/triton_implementation/kernels_backward.py->rmsnorm_backward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.04248639941215515
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.0695680022239685
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.0419840008020401
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.07088000178337098
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.041657599806785586
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.07094399929046631
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.041967999935150144
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.0705407977104187
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07863039970397949
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 1.501699161529541
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.04237439930438995
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.07073280215263367
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04251840114593506
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07059199810028076
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.04215039908885956
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.07092800140380859
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04167360067367554
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.07011200189590454
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.1099840164184571
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 3.619484710693359
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.042716801166534424
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.07003840208053588
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04308159947395325
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07221440076828003
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.04184960126876831
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.07080960273742676
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.04166400134563446
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.07094079852104188
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.2312223434448244
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 10.419478607177734
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.04193280041217804
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.07045440077781677
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.044870400428771974
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07503679990768433
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.042508798837661746
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.07063999772071838
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04232639968395233
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07208319902420043
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.04208320081233978
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.07094720005989075
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04285120069980621
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.0710752010345459
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07854080200195312
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.124345588684082
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04222080111503601
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.07003200054168701
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.042294400930404666
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.0700160026550293
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.04305280148983002
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.07041919827461243
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.042089599370956424
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.07020480036735535
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.885200023651123
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 2.96059513092041
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.042054399847984314
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.07120000123977661
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04332480132579804
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07225919961929321
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.04132159948348999
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.07055040001869202
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04148800075054169
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.07082560062408447
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.8170400619506837
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 8.332038116455077
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.04260160028934479
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.07044479846954346
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04709439873695374
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07285439968109131
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.04291200041770935
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.06521919965744019
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.04200319945812225
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.0633567988872528
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.04232639968395233
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.06403200030326843
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.04249599874019623
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.0641759991645813
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.14507520198822021
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.66430721282959
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.0430976003408432
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.06357439756393432
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04341759979724884
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06499840021133423
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04242559969425201
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.06353279948234558
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.041894400119781496
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.06473280191421509
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.739776039123535
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 4.280019378662109
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.042089599370956424
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.04794560074806213
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04513919949531555
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06528000235557556
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.04154880046844482
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.06453440189361573
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.04169279932975769
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.06355839967727661
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 7.592185974121094
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 10.245442962646484
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.04336639940738678
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.06539199948310852
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.07192320227622986
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.08505920171737671
  kernels/rmsnorm/triton_implementation/kernels_forward.py->rmsnorm_forward_triton:
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.0341376006603241
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.036025598645210266
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.033478400111198424
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.037273600697517395
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03334720134735107
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.03648639917373657
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03356800079345703
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03711360096931458
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04779199957847595
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.05288000106811523
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03335680067539215
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03689599931240082
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.033215999603271484
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03627200126647949
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.033504000306129454
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03672960102558136
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.033155199885368344
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03739840090274811
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09584320187568665
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.1359776020050049
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.033379200100898745
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03650240004062653
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.033308801054954526
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03697920143604279
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.033199998736381534
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03641600012779236
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.0343423992395401
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.0365119993686676
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.5856480121612548
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.203923225402832
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03303360044956207
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03705599904060364
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.035087999701499936
    '''x.dtype = torch.bfloat16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03776960074901581
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.033766400814056394
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03612160086631775
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.033881598711013795
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.036924800276756285
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03340800106525421
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.036287999153137206
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03323839902877808
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.037231999635696414
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.0482367992401123
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.05418559908866882
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.0333983987569809
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03612479865550995
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.032671999931335446
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03661440014839172
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03224639892578125
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03653759956359863
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.033232000470161435
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03661440014839172
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09572479724884034
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.13231680393218995
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.033180800080299375
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.03703039884567261
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03378880023956299
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03691839873790741
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.0333759993314743
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03622719943523407
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 128
      time: 0.03346560001373291
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03677760064601898
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.5884223937988281
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.3147040367126466
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03328959941864014
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03666560053825378
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.034585601091384886
    '''x.dtype = torch.float16'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.0377375990152359
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 16384
      time: 0.03346239924430847
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 8192
      time: 0.03664000034332275
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03269760012626648
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 1024'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.03678719997406006
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03349440097808838
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 128'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03674240112304687
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1024
      time: 0.03403840065002441
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03726719915866852
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.09322879910469055
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 16384'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.10107519626617431
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.032604798674583435
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2048
      time: 0.03657920062541962
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.032979199290275575
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 2048'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.03669439852237701
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 8
      time: 0.03341119885444641
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 256'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03656960129737854
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.03353599905967712
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03723520040512085
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.1945248007774353
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 32768'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 1.082755184173584
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03341119885444641
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 4096
      time: 0.026767998933792114
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 4
      time: 0.034067198634147644
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 4096'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.03755840063095093
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 32
      time: 0.033478400111198424
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 512'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 16
      time: 0.03621439933776856
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 64
      time: 0.03345920145511627
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 64'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 256
      time: 0.036057600378990175
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 1.6089056015014649
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 65536'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 1
      time: 2.025644874572754
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03274880051612854
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 512
      time: 0.03729600012302399
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = False''':
      config:
        BLOCK_SIZE_B: 1
      time: 0.04730879962444305
    '''x.dtype = torch.float32'', ''BLOCK_SIZE_H = 8192'', ''has_weight = True''':
      config:
        BLOCK_SIZE_B: 2
      time: 0.04964799880981445
  kernels/swiglu/backward.py->_backward:
    '''gate.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27978880405426027
    '''gate.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 2048
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.2790816068649292
    '''gate.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 256
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.5548384189605713
  kernels/swiglu/forward.py->_forward:
    '''gate.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.14087040424346925
    '''gate.dtype = torch.float16''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.1411296010017395
    '''gate.dtype = torch.float32''':
      config:
        BLOCK_SIZE: 1024
        kernel_backend: triton
        vector_instruction_width: null
      time: 0.27870399951934816
  kernels/swiglu_unchunked/backward.py->_backward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5710720062255858
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5502976417541503
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 2.607369613647461
  kernels/swiglu_unchunked/forward.py->_forward:
    '''x.dtype = torch.bfloat16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9784031867980957
    '''x.dtype = torch.float16''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 0.9641983985900879
    '''x.dtype = torch.float32''':
      config:
        BLOCK_SIZE_B: 64
        BLOCK_SIZE_H: 64
        kernel_backend: triton
      time: 1.5731200218200683
